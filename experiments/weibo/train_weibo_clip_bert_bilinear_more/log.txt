2023-06-01 11:20:48,524:INFO: Effective parameters:
2023-06-01 11:20:48,524:INFO:   <<< CUDA_VISIBLE_DEVICES: 6
2023-06-01 11:20:48,524:INFO:   <<< attention_model: bilinear
2023-06-01 11:20:48,524:INFO:   <<< batch_size: 64
2023-06-01 11:20:48,524:INFO:   <<< batch_size_val: 128
2023-06-01 11:20:48,524:INFO:   <<< dataset: weibo
2023-06-01 11:20:48,524:INFO:   <<< debug: False
2023-06-01 11:20:48,524:INFO:   <<< do_train: True
2023-06-01 11:20:48,524:INFO:   <<< exchange: False
2023-06-01 11:20:48,524:INFO:   <<< exchange_early: False
2023-06-01 11:20:48,524:INFO:   <<< expand_image: True
2023-06-01 11:20:48,525:INFO:   <<< expand_language: True
2023-06-01 11:20:48,525:INFO:   <<< freeze_image: True
2023-06-01 11:20:48,525:INFO:   <<< freeze_language: True
2023-06-01 11:20:48,525:INFO:   <<< image_model_type: clip
2023-06-01 11:20:48,525:INFO:   <<< image_size: 224
2023-06-01 11:20:48,525:INFO:   <<< init_model: 
2023-06-01 11:20:48,525:INFO:   <<< l1_lamda: 0.0002
2023-06-01 11:20:48,525:INFO:   <<< language_model_type: bert
2023-06-01 11:20:48,525:INFO:   <<< local_rank: 0
2023-06-01 11:20:48,525:INFO:   <<< loss_weight: 1,2
2023-06-01 11:20:48,525:INFO:   <<< lr: 0.00015
2023-06-01 11:20:48,525:INFO:   <<< max_text_len: 50
2023-06-01 11:20:48,525:INFO:   <<< more_layer: True
2023-06-01 11:20:48,525:INFO:   <<< n_epochs: 30
2023-06-01 11:20:48,525:INFO:   <<< num_workers: 8
2023-06-01 11:20:48,526:INFO:   <<< output_dir: experiments/weibo/train_weibo_clip_bert_bilinear_more
2023-06-01 11:20:48,526:INFO:   <<< pin_memory: False
2023-06-01 11:20:48,526:INFO:   <<< pretrained_image: True
2023-06-01 11:20:48,526:INFO:   <<< pretrained_language: True
2023-06-01 11:20:48,526:INFO:   <<< rank: 0
2023-06-01 11:20:48,526:INFO:   <<< seed: 42
2023-06-01 11:20:48,526:INFO:   <<< weight_decay: 2e-05
2023-06-01 11:20:48,526:INFO:   <<< world_size: 1
2023-06-01 11:20:48,526:INFO: device: cuda:0 n_gpu: 1
2023-06-01 11:21:15,730:INFO: ***** Running training *****
2023-06-01 11:21:15,730:INFO:   Num examples = 1026
2023-06-01 11:21:15,730:INFO:   Batch size = 64
2023-06-01 11:21:15,730:INFO: ***** Running validation  *****
2023-06-01 11:21:15,730:INFO:   Num examples = 146
2023-06-01 11:21:15,731:INFO:   Batch size = 128
2023-06-01 11:21:17,528:INFO: Epoch: 1/30, Step: 1/16, Lr: 0.000150000, Loss: 1.670889, Step Loss: 1.670889, Time: 1.795522
2023-06-01 11:21:17,631:INFO: Epoch: 1/30, Step: 2/16, Lr: 0.000150000, Loss: 5.782659, Step Loss: 5.782659, Time: 0.102130
2023-06-01 11:21:17,727:INFO: Epoch: 1/30, Step: 3/16, Lr: 0.000150000, Loss: 4.180971, Step Loss: 4.180971, Time: 0.095870
2023-06-01 11:21:17,837:INFO: Epoch: 1/30, Step: 4/16, Lr: 0.000150000, Loss: 1.298347, Step Loss: 1.298347, Time: 0.110121
2023-06-01 11:21:17,931:INFO: Epoch: 1/30, Step: 5/16, Lr: 0.000150000, Loss: 1.524711, Step Loss: 1.524711, Time: 0.092331
2023-06-01 11:21:18,024:INFO: Epoch: 1/30, Step: 6/16, Lr: 0.000150000, Loss: 2.810365, Step Loss: 2.810365, Time: 0.092428
2023-06-01 11:21:18,113:INFO: Epoch: 1/30, Step: 7/16, Lr: 0.000150000, Loss: 2.785058, Step Loss: 2.785058, Time: 0.088748
2023-06-01 11:21:18,203:INFO: Epoch: 1/30, Step: 8/16, Lr: 0.000150000, Loss: 0.757431, Step Loss: 0.757431, Time: 0.089654
2023-06-01 11:21:18,402:INFO: Epoch: 1/30, Step: 9/16, Lr: 0.000150000, Loss: 0.660633, Step Loss: 0.660633, Time: 0.198529
2023-06-01 11:21:18,508:INFO: Epoch: 1/30, Step: 10/16, Lr: 0.000150000, Loss: 1.454271, Step Loss: 1.454271, Time: 0.105619
2023-06-01 11:21:18,617:INFO: Epoch: 1/30, Step: 11/16, Lr: 0.000150000, Loss: 1.933518, Step Loss: 1.933518, Time: 0.108498
2023-06-01 11:21:18,715:INFO: Epoch: 1/30, Step: 12/16, Lr: 0.000150000, Loss: 0.812299, Step Loss: 0.812299, Time: 0.097872
2023-06-01 11:21:18,810:INFO: Epoch: 1/30, Step: 13/16, Lr: 0.000150000, Loss: 0.664084, Step Loss: 0.664084, Time: 0.094333
2023-06-01 11:21:18,906:INFO: Epoch: 1/30, Step: 14/16, Lr: 0.000150000, Loss: 0.821824, Step Loss: 0.821824, Time: 0.095392
2023-06-01 11:21:19,000:INFO: Epoch: 1/30, Step: 15/16, Lr: 0.000150000, Loss: 1.102532, Step Loss: 1.102532, Time: 0.093602
2023-06-01 11:21:19,095:INFO: Epoch: 1/30, Step: 16/16, Lr: 0.000150000, Loss: 1.116692, Step Loss: 1.116692, Time: 0.095023
2023-06-01 11:21:19,307:INFO: Epoch 1/30 Finished, Train Loss: 1.836018
2023-06-01 11:21:20,875:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0
2023-06-01 11:21:24,368:INFO: Classfication Metrics:
2023-06-01 11:21:24,369:INFO: f1 score: 0.7477 - precision score: 0.7830 - recall score: 0.7155 - accuracy score: 0.810169
2023-06-01 11:21:24,369:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0, the F1 is: 0.7477
2023-06-01 11:21:26,732:INFO: Epoch: 2/30, Step: 1/16, Lr: 0.000420000, Loss: 0.695743, Step Loss: 0.695743, Time: 2.352470
2023-06-01 11:21:26,835:INFO: Epoch: 2/30, Step: 2/16, Lr: 0.000420000, Loss: 0.931054, Step Loss: 0.931054, Time: 0.103198
2023-06-01 11:21:26,941:INFO: Epoch: 2/30, Step: 3/16, Lr: 0.000420000, Loss: 2.714201, Step Loss: 2.714201, Time: 0.105143
2023-06-01 11:21:27,033:INFO: Epoch: 2/30, Step: 4/16, Lr: 0.000420000, Loss: 0.899557, Step Loss: 0.899557, Time: 0.091185
2023-06-01 11:21:27,130:INFO: Epoch: 2/30, Step: 5/16, Lr: 0.000420000, Loss: 0.607242, Step Loss: 0.607242, Time: 0.096385
2023-06-01 11:21:27,218:INFO: Epoch: 2/30, Step: 6/16, Lr: 0.000420000, Loss: 1.262229, Step Loss: 1.262229, Time: 0.086698
2023-06-01 11:21:27,305:INFO: Epoch: 2/30, Step: 7/16, Lr: 0.000420000, Loss: 0.597652, Step Loss: 0.597652, Time: 0.086649
2023-06-01 11:21:27,400:INFO: Epoch: 2/30, Step: 8/16, Lr: 0.000420000, Loss: 0.302812, Step Loss: 0.302812, Time: 0.094329
2023-06-01 11:21:27,505:INFO: Epoch: 2/30, Step: 9/16, Lr: 0.000420000, Loss: 1.099039, Step Loss: 1.099039, Time: 0.105202
2023-06-01 11:21:27,606:INFO: Epoch: 2/30, Step: 10/16, Lr: 0.000420000, Loss: 0.744814, Step Loss: 0.744814, Time: 0.099629
2023-06-01 11:21:27,710:INFO: Epoch: 2/30, Step: 11/16, Lr: 0.000420000, Loss: 0.424772, Step Loss: 0.424772, Time: 0.103235
2023-06-01 11:21:27,803:INFO: Epoch: 2/30, Step: 12/16, Lr: 0.000420000, Loss: 0.667926, Step Loss: 0.667926, Time: 0.092386
2023-06-01 11:21:27,895:INFO: Epoch: 2/30, Step: 13/16, Lr: 0.000420000, Loss: 0.557938, Step Loss: 0.557938, Time: 0.091619
2023-06-01 11:21:27,995:INFO: Epoch: 2/30, Step: 14/16, Lr: 0.000420000, Loss: 0.410089, Step Loss: 0.410089, Time: 0.099818
2023-06-01 11:21:28,090:INFO: Epoch: 2/30, Step: 15/16, Lr: 0.000420000, Loss: 0.137509, Step Loss: 0.137509, Time: 0.094543
2023-06-01 11:21:28,186:INFO: Epoch: 2/30, Step: 16/16, Lr: 0.000420000, Loss: 0.638288, Step Loss: 0.638288, Time: 0.095796
2023-06-01 11:21:28,460:INFO: Epoch 2/30 Finished, Train Loss: 0.793179
2023-06-01 11:21:30,031:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1
2023-06-01 11:21:33,608:INFO: Classfication Metrics:
2023-06-01 11:21:33,608:INFO: f1 score: 0.7942 - precision score: 0.6832 - recall score: 0.9483 - accuracy score: 0.806780
2023-06-01 11:21:33,609:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.7942
2023-06-01 11:21:35,571:INFO: Epoch: 3/30, Step: 1/16, Lr: 0.000690000, Loss: 0.510650, Step Loss: 0.510650, Time: 1.953571
2023-06-01 11:21:35,797:INFO: Epoch: 3/30, Step: 2/16, Lr: 0.000690000, Loss: 0.589049, Step Loss: 0.589049, Time: 0.225374
2023-06-01 11:21:35,899:INFO: Epoch: 3/30, Step: 3/16, Lr: 0.000690000, Loss: 0.441423, Step Loss: 0.441423, Time: 0.101372
2023-06-01 11:21:35,996:INFO: Epoch: 3/30, Step: 4/16, Lr: 0.000690000, Loss: 0.482074, Step Loss: 0.482074, Time: 0.096001
2023-06-01 11:21:36,103:INFO: Epoch: 3/30, Step: 5/16, Lr: 0.000690000, Loss: 0.353603, Step Loss: 0.353603, Time: 0.105899
2023-06-01 11:21:36,195:INFO: Epoch: 3/30, Step: 6/16, Lr: 0.000690000, Loss: 0.221544, Step Loss: 0.221544, Time: 0.092378
2023-06-01 11:21:36,285:INFO: Epoch: 3/30, Step: 7/16, Lr: 0.000690000, Loss: 0.344116, Step Loss: 0.344116, Time: 0.089341
2023-06-01 11:21:36,375:INFO: Epoch: 3/30, Step: 8/16, Lr: 0.000690000, Loss: 0.688020, Step Loss: 0.688020, Time: 0.088601
2023-06-01 11:21:36,464:INFO: Epoch: 3/30, Step: 9/16, Lr: 0.000690000, Loss: 0.450736, Step Loss: 0.450736, Time: 0.088217
2023-06-01 11:21:36,747:INFO: Epoch: 3/30, Step: 10/16, Lr: 0.000690000, Loss: 0.381172, Step Loss: 0.381172, Time: 0.283428
2023-06-01 11:21:36,839:INFO: Epoch: 3/30, Step: 11/16, Lr: 0.000690000, Loss: 0.340268, Step Loss: 0.340268, Time: 0.090932
2023-06-01 11:21:36,931:INFO: Epoch: 3/30, Step: 12/16, Lr: 0.000690000, Loss: 0.407374, Step Loss: 0.407374, Time: 0.091639
2023-06-01 11:21:37,023:INFO: Epoch: 3/30, Step: 13/16, Lr: 0.000690000, Loss: 0.291209, Step Loss: 0.291209, Time: 0.091718
2023-06-01 11:21:37,119:INFO: Epoch: 3/30, Step: 14/16, Lr: 0.000690000, Loss: 0.368639, Step Loss: 0.368639, Time: 0.095385
2023-06-01 11:21:37,218:INFO: Epoch: 3/30, Step: 15/16, Lr: 0.000690000, Loss: 0.284507, Step Loss: 0.284507, Time: 0.098727
2023-06-01 11:21:37,309:INFO: Epoch: 3/30, Step: 16/16, Lr: 0.000690000, Loss: 0.817179, Step Loss: 0.817179, Time: 0.090338
2023-06-01 11:21:37,588:INFO: Epoch 3/30 Finished, Train Loss: 0.435723
2023-06-01 11:21:39,152:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2
2023-06-01 11:21:42,810:INFO: Classfication Metrics:
2023-06-01 11:21:42,810:INFO: f1 score: 0.7625 - precision score: 0.6230 - recall score: 0.9828 - accuracy score: 0.759322
2023-06-01 11:21:42,811:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.7942
2023-06-01 11:21:45,099:INFO: Epoch: 4/30, Step: 1/16, Lr: 0.001230000, Loss: 0.190072, Step Loss: 0.190072, Time: 2.276569
2023-06-01 11:21:45,199:INFO: Epoch: 4/30, Step: 2/16, Lr: 0.001230000, Loss: 0.548442, Step Loss: 0.548442, Time: 0.099561
2023-06-01 11:21:45,300:INFO: Epoch: 4/30, Step: 3/16, Lr: 0.001230000, Loss: 0.950620, Step Loss: 0.950620, Time: 0.100377
2023-06-01 11:21:45,416:INFO: Epoch: 4/30, Step: 4/16, Lr: 0.001230000, Loss: 0.416069, Step Loss: 0.416069, Time: 0.115399
2023-06-01 11:21:45,512:INFO: Epoch: 4/30, Step: 5/16, Lr: 0.001230000, Loss: 0.075579, Step Loss: 0.075579, Time: 0.095133
2023-06-01 11:21:45,606:INFO: Epoch: 4/30, Step: 6/16, Lr: 0.001230000, Loss: 0.267038, Step Loss: 0.267038, Time: 0.094260
2023-06-01 11:21:45,700:INFO: Epoch: 4/30, Step: 7/16, Lr: 0.001230000, Loss: 0.381503, Step Loss: 0.381503, Time: 0.093014
2023-06-01 11:21:45,794:INFO: Epoch: 4/30, Step: 8/16, Lr: 0.001230000, Loss: 0.349423, Step Loss: 0.349423, Time: 0.093770
2023-06-01 11:21:46,271:INFO: Epoch: 4/30, Step: 9/16, Lr: 0.001230000, Loss: 0.339455, Step Loss: 0.339455, Time: 0.476684
2023-06-01 11:21:46,365:INFO: Epoch: 4/30, Step: 10/16, Lr: 0.001230000, Loss: 0.253235, Step Loss: 0.253235, Time: 0.093401
2023-06-01 11:21:46,461:INFO: Epoch: 4/30, Step: 11/16, Lr: 0.001230000, Loss: 0.198794, Step Loss: 0.198794, Time: 0.095657
2023-06-01 11:21:46,555:INFO: Epoch: 4/30, Step: 12/16, Lr: 0.001230000, Loss: 0.955851, Step Loss: 0.955851, Time: 0.093575
2023-06-01 11:21:46,649:INFO: Epoch: 4/30, Step: 13/16, Lr: 0.001230000, Loss: 1.196132, Step Loss: 1.196132, Time: 0.093396
2023-06-01 11:21:46,754:INFO: Epoch: 4/30, Step: 14/16, Lr: 0.001230000, Loss: 0.264370, Step Loss: 0.264370, Time: 0.104019
2023-06-01 11:21:46,853:INFO: Epoch: 4/30, Step: 15/16, Lr: 0.001230000, Loss: 1.393497, Step Loss: 1.393497, Time: 0.098426
2023-06-01 11:21:46,949:INFO: Epoch: 4/30, Step: 16/16, Lr: 0.001230000, Loss: 0.546404, Step Loss: 0.546404, Time: 0.095236
2023-06-01 11:21:47,246:INFO: Epoch 4/30 Finished, Train Loss: 0.520405
2023-06-01 11:21:49,022:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.3
2023-06-01 11:21:52,527:INFO: Classfication Metrics:
2023-06-01 11:21:52,527:INFO: f1 score: 0.8327 - precision score: 0.7320 - recall score: 0.9655 - accuracy score: 0.847458
2023-06-01 11:21:52,527:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.3, the F1 is: 0.8327
2023-06-01 11:21:54,632:INFO: Epoch: 5/30, Step: 1/16, Lr: 0.001500000, Loss: 0.369597, Step Loss: 0.369597, Time: 2.073771
2023-06-01 11:21:54,787:INFO: Epoch: 5/30, Step: 2/16, Lr: 0.001500000, Loss: 0.286849, Step Loss: 0.286849, Time: 0.154284
2023-06-01 11:21:54,879:INFO: Epoch: 5/30, Step: 3/16, Lr: 0.001500000, Loss: 0.818594, Step Loss: 0.818594, Time: 0.091580
2023-06-01 11:21:54,977:INFO: Epoch: 5/30, Step: 4/16, Lr: 0.001500000, Loss: 0.533521, Step Loss: 0.533521, Time: 0.096903
2023-06-01 11:21:55,072:INFO: Epoch: 5/30, Step: 5/16, Lr: 0.001500000, Loss: 0.909584, Step Loss: 0.909584, Time: 0.094214
2023-06-01 11:21:55,165:INFO: Epoch: 5/30, Step: 6/16, Lr: 0.001500000, Loss: 0.295412, Step Loss: 0.295412, Time: 0.092404
2023-06-01 11:21:55,258:INFO: Epoch: 5/30, Step: 7/16, Lr: 0.001500000, Loss: 2.805334, Step Loss: 2.805334, Time: 0.093020
2023-06-01 11:21:55,355:INFO: Epoch: 5/30, Step: 8/16, Lr: 0.001500000, Loss: 2.213946, Step Loss: 2.213946, Time: 0.096393
2023-06-01 11:21:55,497:INFO: Epoch: 5/30, Step: 9/16, Lr: 0.001500000, Loss: 1.480629, Step Loss: 1.480629, Time: 0.141506
2023-06-01 11:21:55,602:INFO: Epoch: 5/30, Step: 10/16, Lr: 0.001500000, Loss: 0.944669, Step Loss: 0.944669, Time: 0.104372
2023-06-01 11:21:55,700:INFO: Epoch: 5/30, Step: 11/16, Lr: 0.001500000, Loss: 0.985920, Step Loss: 0.985920, Time: 0.097289
2023-06-01 11:21:55,799:INFO: Epoch: 5/30, Step: 12/16, Lr: 0.001500000, Loss: 0.366296, Step Loss: 0.366296, Time: 0.098550
2023-06-01 11:21:55,899:INFO: Epoch: 5/30, Step: 13/16, Lr: 0.001500000, Loss: 0.717928, Step Loss: 0.717928, Time: 0.099344
2023-06-01 11:21:56,000:INFO: Epoch: 5/30, Step: 14/16, Lr: 0.001500000, Loss: 1.879607, Step Loss: 1.879607, Time: 0.099964
2023-06-01 11:21:56,094:INFO: Epoch: 5/30, Step: 15/16, Lr: 0.001500000, Loss: 0.174452, Step Loss: 0.174452, Time: 0.093804
2023-06-01 11:21:56,189:INFO: Epoch: 5/30, Step: 16/16, Lr: 0.001500000, Loss: 1.150528, Step Loss: 1.150528, Time: 0.094674
2023-06-01 11:21:56,485:INFO: Epoch 5/30 Finished, Train Loss: 0.995804
2023-06-01 11:21:58,103:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4
2023-06-01 11:22:01,587:INFO: Classfication Metrics:
2023-06-01 11:22:01,588:INFO: f1 score: 0.8376 - precision score: 0.8305 - recall score: 0.8448 - accuracy score: 0.871186
2023-06-01 11:22:01,588:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8376
2023-06-01 11:22:03,711:INFO: Epoch: 6/30, Step: 1/16, Lr: 0.001500000, Loss: 0.215737, Step Loss: 0.215737, Time: 2.092597
2023-06-01 11:22:03,806:INFO: Epoch: 6/30, Step: 2/16, Lr: 0.001500000, Loss: 0.477371, Step Loss: 0.477371, Time: 0.094042
2023-06-01 11:22:03,892:INFO: Epoch: 6/30, Step: 3/16, Lr: 0.001500000, Loss: 0.267187, Step Loss: 0.267187, Time: 0.086036
2023-06-01 11:22:03,984:INFO: Epoch: 6/30, Step: 4/16, Lr: 0.001500000, Loss: 0.534276, Step Loss: 0.534276, Time: 0.091000
2023-06-01 11:22:04,073:INFO: Epoch: 6/30, Step: 5/16, Lr: 0.001500000, Loss: 0.833570, Step Loss: 0.833570, Time: 0.088681
2023-06-01 11:22:04,167:INFO: Epoch: 6/30, Step: 6/16, Lr: 0.001500000, Loss: 0.225485, Step Loss: 0.225485, Time: 0.093810
2023-06-01 11:22:04,274:INFO: Epoch: 6/30, Step: 7/16, Lr: 0.001500000, Loss: 0.309555, Step Loss: 0.309555, Time: 0.106045
2023-06-01 11:22:04,362:INFO: Epoch: 6/30, Step: 8/16, Lr: 0.001500000, Loss: 0.568140, Step Loss: 0.568140, Time: 0.088096
2023-06-01 11:22:04,523:INFO: Epoch: 6/30, Step: 9/16, Lr: 0.001500000, Loss: 0.399350, Step Loss: 0.399350, Time: 0.160885
2023-06-01 11:22:04,611:INFO: Epoch: 6/30, Step: 10/16, Lr: 0.001500000, Loss: 0.864405, Step Loss: 0.864405, Time: 0.087057
2023-06-01 11:22:04,703:INFO: Epoch: 6/30, Step: 11/16, Lr: 0.001500000, Loss: 0.400297, Step Loss: 0.400297, Time: 0.091244
2023-06-01 11:22:04,801:INFO: Epoch: 6/30, Step: 12/16, Lr: 0.001500000, Loss: 0.388762, Step Loss: 0.388762, Time: 0.098346
2023-06-01 11:22:04,896:INFO: Epoch: 6/30, Step: 13/16, Lr: 0.001500000, Loss: 0.512750, Step Loss: 0.512750, Time: 0.093732
2023-06-01 11:22:04,994:INFO: Epoch: 6/30, Step: 14/16, Lr: 0.001500000, Loss: 0.373469, Step Loss: 0.373469, Time: 0.098378
2023-06-01 11:22:05,091:INFO: Epoch: 6/30, Step: 15/16, Lr: 0.001500000, Loss: 0.393852, Step Loss: 0.393852, Time: 0.095799
2023-06-01 11:22:05,183:INFO: Epoch: 6/30, Step: 16/16, Lr: 0.001500000, Loss: 0.214173, Step Loss: 0.214173, Time: 0.091996
2023-06-01 11:22:05,472:INFO: Epoch 6/30 Finished, Train Loss: 0.436149
2023-06-01 11:22:07,031:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5
2023-06-01 11:22:10,341:INFO: Classfication Metrics:
2023-06-01 11:22:10,341:INFO: f1 score: 0.7234 - precision score: 0.9444 - recall score: 0.5862 - accuracy score: 0.823729
2023-06-01 11:22:10,341:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8376
2023-06-01 11:22:12,274:INFO: Epoch: 7/30, Step: 1/16, Lr: 0.001494086, Loss: 1.372856, Step Loss: 1.372856, Time: 1.921186
2023-06-01 11:22:12,369:INFO: Epoch: 7/30, Step: 2/16, Lr: 0.001494086, Loss: 0.194205, Step Loss: 0.194205, Time: 0.095178
2023-06-01 11:22:12,459:INFO: Epoch: 7/30, Step: 3/16, Lr: 0.001494086, Loss: 1.829986, Step Loss: 1.829986, Time: 0.089829
2023-06-01 11:22:12,550:INFO: Epoch: 7/30, Step: 4/16, Lr: 0.001494086, Loss: 0.629583, Step Loss: 0.629583, Time: 0.090254
2023-06-01 11:22:12,644:INFO: Epoch: 7/30, Step: 5/16, Lr: 0.001494086, Loss: 0.329415, Step Loss: 0.329415, Time: 0.093986
2023-06-01 11:22:12,734:INFO: Epoch: 7/30, Step: 6/16, Lr: 0.001494086, Loss: 0.441879, Step Loss: 0.441879, Time: 0.088953
2023-06-01 11:22:12,824:INFO: Epoch: 7/30, Step: 7/16, Lr: 0.001494086, Loss: 0.290790, Step Loss: 0.290790, Time: 0.089473
2023-06-01 11:22:12,912:INFO: Epoch: 7/30, Step: 8/16, Lr: 0.001494086, Loss: 0.247686, Step Loss: 0.247686, Time: 0.088291
2023-06-01 11:22:13,223:INFO: Epoch: 7/30, Step: 9/16, Lr: 0.001494086, Loss: 0.743871, Step Loss: 0.743871, Time: 0.298903
2023-06-01 11:22:13,317:INFO: Epoch: 7/30, Step: 10/16, Lr: 0.001494086, Loss: 0.243107, Step Loss: 0.243107, Time: 0.093353
2023-06-01 11:22:13,408:INFO: Epoch: 7/30, Step: 11/16, Lr: 0.001494086, Loss: 0.278214, Step Loss: 0.278214, Time: 0.090799
2023-06-01 11:22:13,499:INFO: Epoch: 7/30, Step: 12/16, Lr: 0.001494086, Loss: 0.059155, Step Loss: 0.059155, Time: 0.090098
2023-06-01 11:22:13,643:INFO: Epoch: 7/30, Step: 13/16, Lr: 0.001494086, Loss: 1.643028, Step Loss: 1.643028, Time: 0.143594
2023-06-01 11:22:13,742:INFO: Epoch: 7/30, Step: 14/16, Lr: 0.001494086, Loss: 0.267589, Step Loss: 0.267589, Time: 0.099039
2023-06-01 11:22:13,841:INFO: Epoch: 7/30, Step: 15/16, Lr: 0.001494086, Loss: 0.213161, Step Loss: 0.213161, Time: 0.098444
2023-06-01 11:22:13,931:INFO: Epoch: 7/30, Step: 16/16, Lr: 0.001494086, Loss: 0.547828, Step Loss: 0.547828, Time: 0.089979
2023-06-01 11:22:14,205:INFO: Epoch 7/30 Finished, Train Loss: 0.583272
2023-06-01 11:22:15,741:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6
2023-06-01 11:22:19,065:INFO: Classfication Metrics:
2023-06-01 11:22:19,066:INFO: f1 score: 0.8129 - precision score: 0.6975 - recall score: 0.9741 - accuracy score: 0.823729
2023-06-01 11:22:19,066:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8376
2023-06-01 11:22:21,211:INFO: Epoch: 8/30, Step: 1/16, Lr: 0.001476437, Loss: 0.149379, Step Loss: 0.149379, Time: 2.135554
2023-06-01 11:22:21,308:INFO: Epoch: 8/30, Step: 2/16, Lr: 0.001476437, Loss: 0.250345, Step Loss: 0.250345, Time: 0.096438
2023-06-01 11:22:21,414:INFO: Epoch: 8/30, Step: 3/16, Lr: 0.001476437, Loss: 0.001717, Step Loss: 0.001717, Time: 0.105652
2023-06-01 11:22:21,506:INFO: Epoch: 8/30, Step: 4/16, Lr: 0.001476437, Loss: 0.038657, Step Loss: 0.038657, Time: 0.091591
2023-06-01 11:22:21,598:INFO: Epoch: 8/30, Step: 5/16, Lr: 0.001476437, Loss: 0.086884, Step Loss: 0.086884, Time: 0.091130
2023-06-01 11:22:21,688:INFO: Epoch: 8/30, Step: 6/16, Lr: 0.001476437, Loss: 0.012630, Step Loss: 0.012630, Time: 0.089603
2023-06-01 11:22:21,779:INFO: Epoch: 8/30, Step: 7/16, Lr: 0.001476437, Loss: 0.454858, Step Loss: 0.454858, Time: 0.090536
2023-06-01 11:22:21,870:INFO: Epoch: 8/30, Step: 8/16, Lr: 0.001476437, Loss: 0.000339, Step Loss: 0.000339, Time: 0.091047
2023-06-01 11:22:22,535:INFO: Epoch: 8/30, Step: 9/16, Lr: 0.001476437, Loss: 0.051744, Step Loss: 0.051744, Time: 0.664464
2023-06-01 11:22:22,636:INFO: Epoch: 8/30, Step: 10/16, Lr: 0.001476437, Loss: 0.145436, Step Loss: 0.145436, Time: 0.100367
2023-06-01 11:22:22,739:INFO: Epoch: 8/30, Step: 11/16, Lr: 0.001476437, Loss: 0.211204, Step Loss: 0.211204, Time: 0.102146
2023-06-01 11:22:22,831:INFO: Epoch: 8/30, Step: 12/16, Lr: 0.001476437, Loss: 0.063958, Step Loss: 0.063958, Time: 0.092097
2023-06-01 11:22:22,926:INFO: Epoch: 8/30, Step: 13/16, Lr: 0.001476437, Loss: 0.033132, Step Loss: 0.033132, Time: 0.094454
2023-06-01 11:22:23,017:INFO: Epoch: 8/30, Step: 14/16, Lr: 0.001476437, Loss: 0.023472, Step Loss: 0.023472, Time: 0.091121
2023-06-01 11:22:23,110:INFO: Epoch: 8/30, Step: 15/16, Lr: 0.001476437, Loss: 0.017290, Step Loss: 0.017290, Time: 0.092012
2023-06-01 11:22:23,203:INFO: Epoch: 8/30, Step: 16/16, Lr: 0.001476437, Loss: 0.134144, Step Loss: 0.134144, Time: 0.092857
2023-06-01 11:22:23,471:INFO: Epoch 8/30 Finished, Train Loss: 0.104699
2023-06-01 11:22:24,996:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.7
2023-06-01 11:22:28,312:INFO: Classfication Metrics:
2023-06-01 11:22:28,313:INFO: f1 score: 0.8224 - precision score: 0.8980 - recall score: 0.7586 - accuracy score: 0.871186
2023-06-01 11:22:28,313:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8376
2023-06-01 11:22:30,255:INFO: Epoch: 9/30, Step: 1/16, Lr: 0.001447332, Loss: 0.028982, Step Loss: 0.028982, Time: 1.931515
2023-06-01 11:22:30,351:INFO: Epoch: 9/30, Step: 2/16, Lr: 0.001447332, Loss: 0.004049, Step Loss: 0.004049, Time: 0.096089
2023-06-01 11:22:30,448:INFO: Epoch: 9/30, Step: 3/16, Lr: 0.001447332, Loss: 0.005878, Step Loss: 0.005878, Time: 0.095963
2023-06-01 11:22:30,545:INFO: Epoch: 9/30, Step: 4/16, Lr: 0.001447332, Loss: 0.002403, Step Loss: 0.002403, Time: 0.096598
2023-06-01 11:22:30,640:INFO: Epoch: 9/30, Step: 5/16, Lr: 0.001447332, Loss: 0.007391, Step Loss: 0.007391, Time: 0.094902
2023-06-01 11:22:30,738:INFO: Epoch: 9/30, Step: 6/16, Lr: 0.001447332, Loss: 0.001494, Step Loss: 0.001494, Time: 0.097253
2023-06-01 11:22:30,838:INFO: Epoch: 9/30, Step: 7/16, Lr: 0.001447332, Loss: 0.001277, Step Loss: 0.001277, Time: 0.099823
2023-06-01 11:22:30,935:INFO: Epoch: 9/30, Step: 8/16, Lr: 0.001447332, Loss: 0.030693, Step Loss: 0.030693, Time: 0.096927
2023-06-01 11:22:31,143:INFO: Epoch: 9/30, Step: 9/16, Lr: 0.001447332, Loss: 0.007691, Step Loss: 0.007691, Time: 0.207032
2023-06-01 11:22:31,239:INFO: Epoch: 9/30, Step: 10/16, Lr: 0.001447332, Loss: 0.048586, Step Loss: 0.048586, Time: 0.095508
2023-06-01 11:22:31,331:INFO: Epoch: 9/30, Step: 11/16, Lr: 0.001447332, Loss: 0.004582, Step Loss: 0.004582, Time: 0.092102
2023-06-01 11:22:31,427:INFO: Epoch: 9/30, Step: 12/16, Lr: 0.001447332, Loss: 0.021961, Step Loss: 0.021961, Time: 0.094940
2023-06-01 11:22:31,523:INFO: Epoch: 9/30, Step: 13/16, Lr: 0.001447332, Loss: 0.002669, Step Loss: 0.002669, Time: 0.095714
2023-06-01 11:22:31,616:INFO: Epoch: 9/30, Step: 14/16, Lr: 0.001447332, Loss: 0.040002, Step Loss: 0.040002, Time: 0.092495
2023-06-01 11:22:31,712:INFO: Epoch: 9/30, Step: 15/16, Lr: 0.001447332, Loss: 0.040977, Step Loss: 0.040977, Time: 0.095070
2023-06-01 11:22:31,806:INFO: Epoch: 9/30, Step: 16/16, Lr: 0.001447332, Loss: 0.001873, Step Loss: 0.001873, Time: 0.094260
2023-06-01 11:22:32,034:INFO: Epoch 9/30 Finished, Train Loss: 0.015657
2023-06-01 11:22:33,604:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.8
2023-06-01 11:22:36,927:INFO: Classfication Metrics:
2023-06-01 11:22:36,928:INFO: f1 score: 0.8479 - precision score: 0.9109 - recall score: 0.7931 - accuracy score: 0.888136
2023-06-01 11:22:36,928:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.8, the F1 is: 0.8479
2023-06-01 11:22:38,900:INFO: Epoch: 10/30, Step: 1/16, Lr: 0.001407230, Loss: 0.054212, Step Loss: 0.054212, Time: 1.962043
2023-06-01 11:22:38,997:INFO: Epoch: 10/30, Step: 2/16, Lr: 0.001407230, Loss: 0.005443, Step Loss: 0.005443, Time: 0.095804
2023-06-01 11:22:39,087:INFO: Epoch: 10/30, Step: 3/16, Lr: 0.001407230, Loss: 0.001849, Step Loss: 0.001849, Time: 0.090128
2023-06-01 11:22:39,181:INFO: Epoch: 10/30, Step: 4/16, Lr: 0.001407230, Loss: 0.020667, Step Loss: 0.020667, Time: 0.093523
2023-06-01 11:22:39,282:INFO: Epoch: 10/30, Step: 5/16, Lr: 0.001407230, Loss: 0.006771, Step Loss: 0.006771, Time: 0.100724
2023-06-01 11:22:39,372:INFO: Epoch: 10/30, Step: 6/16, Lr: 0.001407230, Loss: 0.002996, Step Loss: 0.002996, Time: 0.088786
2023-06-01 11:22:39,462:INFO: Epoch: 10/30, Step: 7/16, Lr: 0.001407230, Loss: 0.001739, Step Loss: 0.001739, Time: 0.089985
2023-06-01 11:22:39,558:INFO: Epoch: 10/30, Step: 8/16, Lr: 0.001407230, Loss: 0.023329, Step Loss: 0.023329, Time: 0.095428
2023-06-01 11:22:39,653:INFO: Epoch: 10/30, Step: 9/16, Lr: 0.001407230, Loss: 0.005620, Step Loss: 0.005620, Time: 0.094430
2023-06-01 11:22:39,747:INFO: Epoch: 10/30, Step: 10/16, Lr: 0.001407230, Loss: 0.002856, Step Loss: 0.002856, Time: 0.093901
2023-06-01 11:22:39,842:INFO: Epoch: 10/30, Step: 11/16, Lr: 0.001407230, Loss: 0.020843, Step Loss: 0.020843, Time: 0.095000
2023-06-01 11:22:39,934:INFO: Epoch: 10/30, Step: 12/16, Lr: 0.001407230, Loss: 0.005611, Step Loss: 0.005611, Time: 0.091647
2023-06-01 11:22:40,099:INFO: Epoch: 10/30, Step: 13/16, Lr: 0.001407230, Loss: 0.002349, Step Loss: 0.002349, Time: 0.164494
2023-06-01 11:22:40,190:INFO: Epoch: 10/30, Step: 14/16, Lr: 0.001407230, Loss: 0.012123, Step Loss: 0.012123, Time: 0.090420
2023-06-01 11:22:40,286:INFO: Epoch: 10/30, Step: 15/16, Lr: 0.001407230, Loss: 0.015681, Step Loss: 0.015681, Time: 0.095294
2023-06-01 11:22:40,379:INFO: Epoch: 10/30, Step: 16/16, Lr: 0.001407230, Loss: 0.001681, Step Loss: 0.001681, Time: 0.092165
2023-06-01 11:22:40,597:INFO: Epoch 10/30 Finished, Train Loss: 0.011486
2023-06-01 11:22:42,167:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.9
2023-06-01 11:22:45,414:INFO: Classfication Metrics:
2023-06-01 11:22:45,415:INFO: f1 score: 0.8621 - precision score: 0.8621 - recall score: 0.8621 - accuracy score: 0.891525
2023-06-01 11:22:45,415:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.9, the F1 is: 0.8621
2023-06-01 11:22:47,267:INFO: Epoch: 11/30, Step: 1/16, Lr: 0.001356763, Loss: 0.003087, Step Loss: 0.003087, Time: 1.822850
2023-06-01 11:22:47,360:INFO: Epoch: 11/30, Step: 2/16, Lr: 0.001356763, Loss: 0.000494, Step Loss: 0.000494, Time: 0.092314
2023-06-01 11:22:47,452:INFO: Epoch: 11/30, Step: 3/16, Lr: 0.001356763, Loss: 0.001044, Step Loss: 0.001044, Time: 0.091063
2023-06-01 11:22:47,764:INFO: Epoch: 11/30, Step: 4/16, Lr: 0.001356763, Loss: 0.018076, Step Loss: 0.018076, Time: 0.311641
2023-06-01 11:22:47,852:INFO: Epoch: 11/30, Step: 5/16, Lr: 0.001356763, Loss: 0.002170, Step Loss: 0.002170, Time: 0.087300
2023-06-01 11:22:47,944:INFO: Epoch: 11/30, Step: 6/16, Lr: 0.001356763, Loss: 0.000100, Step Loss: 0.000100, Time: 0.091542
2023-06-01 11:22:48,036:INFO: Epoch: 11/30, Step: 7/16, Lr: 0.001356763, Loss: 0.002968, Step Loss: 0.002968, Time: 0.091212
2023-06-01 11:22:48,123:INFO: Epoch: 11/30, Step: 8/16, Lr: 0.001356763, Loss: 0.001882, Step Loss: 0.001882, Time: 0.086695
2023-06-01 11:22:48,305:INFO: Epoch: 11/30, Step: 9/16, Lr: 0.001356763, Loss: 0.001538, Step Loss: 0.001538, Time: 0.169310
2023-06-01 11:22:48,394:INFO: Epoch: 11/30, Step: 10/16, Lr: 0.001356763, Loss: 0.006435, Step Loss: 0.006435, Time: 0.088364
2023-06-01 11:22:48,486:INFO: Epoch: 11/30, Step: 11/16, Lr: 0.001356763, Loss: 0.000667, Step Loss: 0.000667, Time: 0.091552
2023-06-01 11:22:48,583:INFO: Epoch: 11/30, Step: 12/16, Lr: 0.001356763, Loss: 0.021343, Step Loss: 0.021343, Time: 0.095992
2023-06-01 11:22:48,675:INFO: Epoch: 11/30, Step: 13/16, Lr: 0.001356763, Loss: 0.000178, Step Loss: 0.000178, Time: 0.092305
2023-06-01 11:22:48,770:INFO: Epoch: 11/30, Step: 14/16, Lr: 0.001356763, Loss: 0.000157, Step Loss: 0.000157, Time: 0.094765
2023-06-01 11:22:48,857:INFO: Epoch: 11/30, Step: 15/16, Lr: 0.001356763, Loss: 0.004372, Step Loss: 0.004372, Time: 0.086683
2023-06-01 11:22:48,950:INFO: Epoch: 11/30, Step: 16/16, Lr: 0.001356763, Loss: 0.000404, Step Loss: 0.000404, Time: 0.091914
2023-06-01 11:22:49,171:INFO: Epoch 11/30 Finished, Train Loss: 0.004057
2023-06-01 11:22:50,699:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10
2023-06-01 11:22:53,894:INFO: Classfication Metrics:
2023-06-01 11:22:53,894:INFO: f1 score: 0.8934 - precision score: 0.8516 - recall score: 0.9397 - accuracy score: 0.911864
2023-06-01 11:22:53,895:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:22:55,965:INFO: Epoch: 12/30, Step: 1/16, Lr: 0.001296726, Loss: 0.001669, Step Loss: 0.001669, Time: 2.055864
2023-06-01 11:22:56,068:INFO: Epoch: 12/30, Step: 2/16, Lr: 0.001296726, Loss: 0.000681, Step Loss: 0.000681, Time: 0.102143
2023-06-01 11:22:56,170:INFO: Epoch: 12/30, Step: 3/16, Lr: 0.001296726, Loss: 0.008680, Step Loss: 0.008680, Time: 0.101999
2023-06-01 11:22:56,271:INFO: Epoch: 12/30, Step: 4/16, Lr: 0.001296726, Loss: 0.001834, Step Loss: 0.001834, Time: 0.100279
2023-06-01 11:22:56,362:INFO: Epoch: 12/30, Step: 5/16, Lr: 0.001296726, Loss: 0.052090, Step Loss: 0.052090, Time: 0.089935
2023-06-01 11:22:56,459:INFO: Epoch: 12/30, Step: 6/16, Lr: 0.001296726, Loss: 0.003701, Step Loss: 0.003701, Time: 0.096452
2023-06-01 11:22:56,555:INFO: Epoch: 12/30, Step: 7/16, Lr: 0.001296726, Loss: 0.004899, Step Loss: 0.004899, Time: 0.095974
2023-06-01 11:22:56,650:INFO: Epoch: 12/30, Step: 8/16, Lr: 0.001296726, Loss: 0.010350, Step Loss: 0.010350, Time: 0.094450
2023-06-01 11:22:56,871:INFO: Epoch: 12/30, Step: 9/16, Lr: 0.001296726, Loss: 0.000074, Step Loss: 0.000074, Time: 0.220726
2023-06-01 11:22:56,969:INFO: Epoch: 12/30, Step: 10/16, Lr: 0.001296726, Loss: 0.000183, Step Loss: 0.000183, Time: 0.097611
2023-06-01 11:22:57,063:INFO: Epoch: 12/30, Step: 11/16, Lr: 0.001296726, Loss: 0.016994, Step Loss: 0.016994, Time: 0.093471
2023-06-01 11:22:57,159:INFO: Epoch: 12/30, Step: 12/16, Lr: 0.001296726, Loss: 0.000034, Step Loss: 0.000034, Time: 0.095243
2023-06-01 11:22:57,250:INFO: Epoch: 12/30, Step: 13/16, Lr: 0.001296726, Loss: 0.000240, Step Loss: 0.000240, Time: 0.090935
2023-06-01 11:22:57,344:INFO: Epoch: 12/30, Step: 14/16, Lr: 0.001296726, Loss: 0.000013, Step Loss: 0.000013, Time: 0.092723
2023-06-01 11:22:57,440:INFO: Epoch: 12/30, Step: 15/16, Lr: 0.001296726, Loss: 0.000160, Step Loss: 0.000160, Time: 0.096143
2023-06-01 11:22:57,535:INFO: Epoch: 12/30, Step: 16/16, Lr: 0.001296726, Loss: 0.000014, Step Loss: 0.000014, Time: 0.094033
2023-06-01 11:22:57,750:INFO: Epoch 12/30 Finished, Train Loss: 0.006351
2023-06-01 11:22:59,258:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.11
2023-06-01 11:23:02,568:INFO: Classfication Metrics:
2023-06-01 11:23:02,568:INFO: f1 score: 0.8766 - precision score: 0.8655 - recall score: 0.8879 - accuracy score: 0.901695
2023-06-01 11:23:02,568:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:04,283:INFO: Epoch: 13/30, Step: 1/16, Lr: 0.001228068, Loss: 0.000332, Step Loss: 0.000332, Time: 1.705296
2023-06-01 11:23:04,715:INFO: Epoch: 13/30, Step: 2/16, Lr: 0.001228068, Loss: 0.000093, Step Loss: 0.000093, Time: 0.431667
2023-06-01 11:23:04,811:INFO: Epoch: 13/30, Step: 3/16, Lr: 0.001228068, Loss: 0.000110, Step Loss: 0.000110, Time: 0.094888
2023-06-01 11:23:04,898:INFO: Epoch: 13/30, Step: 4/16, Lr: 0.001228068, Loss: 0.028849, Step Loss: 0.028849, Time: 0.087272
2023-06-01 11:23:04,987:INFO: Epoch: 13/30, Step: 5/16, Lr: 0.001228068, Loss: 0.000007, Step Loss: 0.000007, Time: 0.088655
2023-06-01 11:23:05,077:INFO: Epoch: 13/30, Step: 6/16, Lr: 0.001228068, Loss: 0.000646, Step Loss: 0.000646, Time: 0.089124
2023-06-01 11:23:05,171:INFO: Epoch: 13/30, Step: 7/16, Lr: 0.001228068, Loss: 0.000987, Step Loss: 0.000987, Time: 0.093517
2023-06-01 11:23:05,273:INFO: Epoch: 13/30, Step: 8/16, Lr: 0.001228068, Loss: 0.001334, Step Loss: 0.001334, Time: 0.101899
2023-06-01 11:23:05,384:INFO: Epoch: 13/30, Step: 9/16, Lr: 0.001228068, Loss: 0.000035, Step Loss: 0.000035, Time: 0.110968
2023-06-01 11:23:05,494:INFO: Epoch: 13/30, Step: 10/16, Lr: 0.001228068, Loss: 0.000308, Step Loss: 0.000308, Time: 0.108654
2023-06-01 11:23:05,583:INFO: Epoch: 13/30, Step: 11/16, Lr: 0.001228068, Loss: 0.001545, Step Loss: 0.001545, Time: 0.088709
2023-06-01 11:23:05,682:INFO: Epoch: 13/30, Step: 12/16, Lr: 0.001228068, Loss: 0.007138, Step Loss: 0.007138, Time: 0.099100
2023-06-01 11:23:05,772:INFO: Epoch: 13/30, Step: 13/16, Lr: 0.001228068, Loss: 0.002704, Step Loss: 0.002704, Time: 0.089754
2023-06-01 11:23:05,865:INFO: Epoch: 13/30, Step: 14/16, Lr: 0.001228068, Loss: 0.000063, Step Loss: 0.000063, Time: 0.092407
2023-06-01 11:23:05,960:INFO: Epoch: 13/30, Step: 15/16, Lr: 0.001228068, Loss: 0.000494, Step Loss: 0.000494, Time: 0.094702
2023-06-01 11:23:06,051:INFO: Epoch: 13/30, Step: 16/16, Lr: 0.001228068, Loss: 0.001872, Step Loss: 0.001872, Time: 0.090345
2023-06-01 11:23:06,275:INFO: Epoch 13/30 Finished, Train Loss: 0.002907
2023-06-01 11:23:07,761:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.12
2023-06-01 11:23:11,095:INFO: Classfication Metrics:
2023-06-01 11:23:11,095:INFO: f1 score: 0.8784 - precision score: 0.8058 - recall score: 0.9655 - accuracy score: 0.894915
2023-06-01 11:23:11,095:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:12,961:INFO: Epoch: 14/30, Step: 1/16, Lr: 0.001151870, Loss: 0.000019, Step Loss: 0.000019, Time: 1.855595
2023-06-01 11:23:13,179:INFO: Epoch: 14/30, Step: 2/16, Lr: 0.001151870, Loss: 0.084526, Step Loss: 0.084526, Time: 0.218142
2023-06-01 11:23:13,272:INFO: Epoch: 14/30, Step: 3/16, Lr: 0.001151870, Loss: 0.000271, Step Loss: 0.000271, Time: 0.092224
2023-06-01 11:23:13,365:INFO: Epoch: 14/30, Step: 4/16, Lr: 0.001151870, Loss: 0.000098, Step Loss: 0.000098, Time: 0.092663
2023-06-01 11:23:13,455:INFO: Epoch: 14/30, Step: 5/16, Lr: 0.001151870, Loss: 0.000152, Step Loss: 0.000152, Time: 0.089876
2023-06-01 11:23:13,548:INFO: Epoch: 14/30, Step: 6/16, Lr: 0.001151870, Loss: 0.000265, Step Loss: 0.000265, Time: 0.092139
2023-06-01 11:23:13,642:INFO: Epoch: 14/30, Step: 7/16, Lr: 0.001151870, Loss: 0.000019, Step Loss: 0.000019, Time: 0.093675
2023-06-01 11:23:13,735:INFO: Epoch: 14/30, Step: 8/16, Lr: 0.001151870, Loss: 0.000168, Step Loss: 0.000168, Time: 0.092391
2023-06-01 11:23:13,845:INFO: Epoch: 14/30, Step: 9/16, Lr: 0.001151870, Loss: 0.000177, Step Loss: 0.000177, Time: 0.109541
2023-06-01 11:23:14,160:INFO: Epoch: 14/30, Step: 10/16, Lr: 0.001151870, Loss: 0.033985, Step Loss: 0.033985, Time: 0.314590
2023-06-01 11:23:14,255:INFO: Epoch: 14/30, Step: 11/16, Lr: 0.001151870, Loss: 0.000613, Step Loss: 0.000613, Time: 0.094172
2023-06-01 11:23:14,352:INFO: Epoch: 14/30, Step: 12/16, Lr: 0.001151870, Loss: 0.000011, Step Loss: 0.000011, Time: 0.096060
2023-06-01 11:23:14,444:INFO: Epoch: 14/30, Step: 13/16, Lr: 0.001151870, Loss: 0.000030, Step Loss: 0.000030, Time: 0.092090
2023-06-01 11:23:14,544:INFO: Epoch: 14/30, Step: 14/16, Lr: 0.001151870, Loss: 0.002186, Step Loss: 0.002186, Time: 0.099674
2023-06-01 11:23:14,636:INFO: Epoch: 14/30, Step: 15/16, Lr: 0.001151870, Loss: 0.000050, Step Loss: 0.000050, Time: 0.091318
2023-06-01 11:23:14,731:INFO: Epoch: 14/30, Step: 16/16, Lr: 0.001151870, Loss: 0.000082, Step Loss: 0.000082, Time: 0.093976
2023-06-01 11:23:15,028:INFO: Epoch 14/30 Finished, Train Loss: 0.007666
2023-06-01 11:23:16,547:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.13
2023-06-01 11:23:20,044:INFO: Classfication Metrics:
2023-06-01 11:23:20,044:INFO: f1 score: 0.8729 - precision score: 0.8583 - recall score: 0.8879 - accuracy score: 0.898305
2023-06-01 11:23:20,044:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:22,009:INFO: Epoch: 15/30, Step: 1/16, Lr: 0.001069334, Loss: 0.000016, Step Loss: 0.000016, Time: 1.947381
2023-06-01 11:23:22,106:INFO: Epoch: 15/30, Step: 2/16, Lr: 0.001069334, Loss: 0.000038, Step Loss: 0.000038, Time: 0.096399
2023-06-01 11:23:22,209:INFO: Epoch: 15/30, Step: 3/16, Lr: 0.001069334, Loss: 0.000162, Step Loss: 0.000162, Time: 0.102629
2023-06-01 11:23:22,307:INFO: Epoch: 15/30, Step: 4/16, Lr: 0.001069334, Loss: 0.000065, Step Loss: 0.000065, Time: 0.097131
2023-06-01 11:23:22,402:INFO: Epoch: 15/30, Step: 5/16, Lr: 0.001069334, Loss: 0.000018, Step Loss: 0.000018, Time: 0.094565
2023-06-01 11:23:22,499:INFO: Epoch: 15/30, Step: 6/16, Lr: 0.001069334, Loss: 0.000070, Step Loss: 0.000070, Time: 0.095910
2023-06-01 11:23:22,596:INFO: Epoch: 15/30, Step: 7/16, Lr: 0.001069334, Loss: 0.013906, Step Loss: 0.013906, Time: 0.096870
2023-06-01 11:23:22,686:INFO: Epoch: 15/30, Step: 8/16, Lr: 0.001069334, Loss: 0.000021, Step Loss: 0.000021, Time: 0.090237
2023-06-01 11:23:23,086:INFO: Epoch: 15/30, Step: 9/16, Lr: 0.001069334, Loss: 0.003877, Step Loss: 0.003877, Time: 0.399529
2023-06-01 11:23:23,182:INFO: Epoch: 15/30, Step: 10/16, Lr: 0.001069334, Loss: 0.000515, Step Loss: 0.000515, Time: 0.095756
2023-06-01 11:23:23,282:INFO: Epoch: 15/30, Step: 11/16, Lr: 0.001069334, Loss: 0.000078, Step Loss: 0.000078, Time: 0.098955
2023-06-01 11:23:23,384:INFO: Epoch: 15/30, Step: 12/16, Lr: 0.001069334, Loss: 0.000016, Step Loss: 0.000016, Time: 0.101501
2023-06-01 11:23:23,474:INFO: Epoch: 15/30, Step: 13/16, Lr: 0.001069334, Loss: 0.000231, Step Loss: 0.000231, Time: 0.090098
2023-06-01 11:23:23,571:INFO: Epoch: 15/30, Step: 14/16, Lr: 0.001069334, Loss: 0.006261, Step Loss: 0.006261, Time: 0.096358
2023-06-01 11:23:23,668:INFO: Epoch: 15/30, Step: 15/16, Lr: 0.001069334, Loss: 0.000872, Step Loss: 0.000872, Time: 0.096634
2023-06-01 11:23:23,760:INFO: Epoch: 15/30, Step: 16/16, Lr: 0.001069334, Loss: 0.000035, Step Loss: 0.000035, Time: 0.091325
2023-06-01 11:23:23,974:INFO: Epoch 15/30 Finished, Train Loss: 0.001636
2023-06-01 11:23:25,502:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.14
2023-06-01 11:23:28,814:INFO: Classfication Metrics:
2023-06-01 11:23:28,815:INFO: f1 score: 0.8852 - precision score: 0.8438 - recall score: 0.9310 - accuracy score: 0.905085
2023-06-01 11:23:28,815:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:30,840:INFO: Epoch: 16/30, Step: 1/16, Lr: 0.000981763, Loss: 0.000442, Step Loss: 0.000442, Time: 1.995829
2023-06-01 11:23:30,938:INFO: Epoch: 16/30, Step: 2/16, Lr: 0.000981763, Loss: 0.000216, Step Loss: 0.000216, Time: 0.095586
2023-06-01 11:23:31,039:INFO: Epoch: 16/30, Step: 3/16, Lr: 0.000981763, Loss: 0.000104, Step Loss: 0.000104, Time: 0.100047
2023-06-01 11:23:31,142:INFO: Epoch: 16/30, Step: 4/16, Lr: 0.000981763, Loss: 0.000331, Step Loss: 0.000331, Time: 0.102782
2023-06-01 11:23:31,244:INFO: Epoch: 16/30, Step: 5/16, Lr: 0.000981763, Loss: 0.000359, Step Loss: 0.000359, Time: 0.101577
2023-06-01 11:23:31,339:INFO: Epoch: 16/30, Step: 6/16, Lr: 0.000981763, Loss: 0.002959, Step Loss: 0.002959, Time: 0.095138
2023-06-01 11:23:31,435:INFO: Epoch: 16/30, Step: 7/16, Lr: 0.000981763, Loss: 0.000014, Step Loss: 0.000014, Time: 0.095731
2023-06-01 11:23:31,539:INFO: Epoch: 16/30, Step: 8/16, Lr: 0.000981763, Loss: 0.001239, Step Loss: 0.001239, Time: 0.103504
2023-06-01 11:23:31,751:INFO: Epoch: 16/30, Step: 9/16, Lr: 0.000981763, Loss: 0.001600, Step Loss: 0.001600, Time: 0.211258
2023-06-01 11:23:31,842:INFO: Epoch: 16/30, Step: 10/16, Lr: 0.000981763, Loss: 0.000341, Step Loss: 0.000341, Time: 0.090635
2023-06-01 11:23:31,939:INFO: Epoch: 16/30, Step: 11/16, Lr: 0.000981763, Loss: 0.000063, Step Loss: 0.000063, Time: 0.096486
2023-06-01 11:23:32,043:INFO: Epoch: 16/30, Step: 12/16, Lr: 0.000981763, Loss: 0.000350, Step Loss: 0.000350, Time: 0.103039
2023-06-01 11:23:32,136:INFO: Epoch: 16/30, Step: 13/16, Lr: 0.000981763, Loss: 0.000881, Step Loss: 0.000881, Time: 0.092632
2023-06-01 11:23:32,236:INFO: Epoch: 16/30, Step: 14/16, Lr: 0.000981763, Loss: 0.000039, Step Loss: 0.000039, Time: 0.099155
2023-06-01 11:23:32,332:INFO: Epoch: 16/30, Step: 15/16, Lr: 0.000981763, Loss: 0.000499, Step Loss: 0.000499, Time: 0.095438
2023-06-01 11:23:32,440:INFO: Epoch: 16/30, Step: 16/16, Lr: 0.000981763, Loss: 0.000044, Step Loss: 0.000044, Time: 0.107297
2023-06-01 11:23:32,745:INFO: Epoch 16/30 Finished, Train Loss: 0.000592
2023-06-01 11:23:34,320:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15
2023-06-01 11:23:37,945:INFO: Classfication Metrics:
2023-06-01 11:23:37,945:INFO: f1 score: 0.8807 - precision score: 0.8425 - recall score: 0.9224 - accuracy score: 0.901695
2023-06-01 11:23:37,945:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:39,990:INFO: Epoch: 17/30, Step: 1/16, Lr: 0.000890536, Loss: 0.000012, Step Loss: 0.000012, Time: 2.014494
2023-06-01 11:23:40,087:INFO: Epoch: 17/30, Step: 2/16, Lr: 0.000890536, Loss: 0.000066, Step Loss: 0.000066, Time: 0.095985
2023-06-01 11:23:40,180:INFO: Epoch: 17/30, Step: 3/16, Lr: 0.000890536, Loss: 0.000160, Step Loss: 0.000160, Time: 0.093332
2023-06-01 11:23:40,284:INFO: Epoch: 17/30, Step: 4/16, Lr: 0.000890536, Loss: 0.000014, Step Loss: 0.000014, Time: 0.103286
2023-06-01 11:23:40,377:INFO: Epoch: 17/30, Step: 5/16, Lr: 0.000890536, Loss: 0.000033, Step Loss: 0.000033, Time: 0.091714
2023-06-01 11:23:40,470:INFO: Epoch: 17/30, Step: 6/16, Lr: 0.000890536, Loss: 0.000079, Step Loss: 0.000079, Time: 0.093254
2023-06-01 11:23:40,562:INFO: Epoch: 17/30, Step: 7/16, Lr: 0.000890536, Loss: 0.000027, Step Loss: 0.000027, Time: 0.091247
2023-06-01 11:23:40,656:INFO: Epoch: 17/30, Step: 8/16, Lr: 0.000890536, Loss: 0.000238, Step Loss: 0.000238, Time: 0.093715
2023-06-01 11:23:40,882:INFO: Epoch: 17/30, Step: 9/16, Lr: 0.000890536, Loss: 0.000315, Step Loss: 0.000315, Time: 0.225780
2023-06-01 11:23:40,979:INFO: Epoch: 17/30, Step: 10/16, Lr: 0.000890536, Loss: 0.000031, Step Loss: 0.000031, Time: 0.096483
2023-06-01 11:23:41,078:INFO: Epoch: 17/30, Step: 11/16, Lr: 0.000890536, Loss: 0.000019, Step Loss: 0.000019, Time: 0.098276
2023-06-01 11:23:41,182:INFO: Epoch: 17/30, Step: 12/16, Lr: 0.000890536, Loss: 0.000023, Step Loss: 0.000023, Time: 0.102903
2023-06-01 11:23:41,283:INFO: Epoch: 17/30, Step: 13/16, Lr: 0.000890536, Loss: 0.000038, Step Loss: 0.000038, Time: 0.100941
2023-06-01 11:23:41,382:INFO: Epoch: 17/30, Step: 14/16, Lr: 0.000890536, Loss: 0.000006, Step Loss: 0.000006, Time: 0.098549
2023-06-01 11:23:41,484:INFO: Epoch: 17/30, Step: 15/16, Lr: 0.000890536, Loss: 0.000049, Step Loss: 0.000049, Time: 0.101084
2023-06-01 11:23:41,584:INFO: Epoch: 17/30, Step: 16/16, Lr: 0.000890536, Loss: 0.000032, Step Loss: 0.000032, Time: 0.099169
2023-06-01 11:23:41,883:INFO: Epoch 17/30 Finished, Train Loss: 0.000071
2023-06-01 11:23:43,399:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.16
2023-06-01 11:23:46,852:INFO: Classfication Metrics:
2023-06-01 11:23:46,853:INFO: f1 score: 0.8714 - precision score: 0.8400 - recall score: 0.9052 - accuracy score: 0.894915
2023-06-01 11:23:46,853:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:48,999:INFO: Epoch: 18/30, Step: 1/16, Lr: 0.000797093, Loss: 0.000002, Step Loss: 0.000002, Time: 2.135616
2023-06-01 11:23:49,231:INFO: Epoch: 18/30, Step: 2/16, Lr: 0.000797093, Loss: 0.001119, Step Loss: 0.001119, Time: 0.232044
2023-06-01 11:23:49,322:INFO: Epoch: 18/30, Step: 3/16, Lr: 0.000797093, Loss: 0.000022, Step Loss: 0.000022, Time: 0.090444
2023-06-01 11:23:49,414:INFO: Epoch: 18/30, Step: 4/16, Lr: 0.000797093, Loss: 0.000035, Step Loss: 0.000035, Time: 0.091996
2023-06-01 11:23:49,505:INFO: Epoch: 18/30, Step: 5/16, Lr: 0.000797093, Loss: 0.001105, Step Loss: 0.001105, Time: 0.090546
2023-06-01 11:23:49,595:INFO: Epoch: 18/30, Step: 6/16, Lr: 0.000797093, Loss: 0.000003, Step Loss: 0.000003, Time: 0.089301
2023-06-01 11:23:49,686:INFO: Epoch: 18/30, Step: 7/16, Lr: 0.000797093, Loss: 0.000006, Step Loss: 0.000006, Time: 0.090120
2023-06-01 11:23:49,775:INFO: Epoch: 18/30, Step: 8/16, Lr: 0.000797093, Loss: 0.000110, Step Loss: 0.000110, Time: 0.089092
2023-06-01 11:23:49,871:INFO: Epoch: 18/30, Step: 9/16, Lr: 0.000797093, Loss: 0.000144, Step Loss: 0.000144, Time: 0.095232
2023-06-01 11:23:50,012:INFO: Epoch: 18/30, Step: 10/16, Lr: 0.000797093, Loss: 0.000006, Step Loss: 0.000006, Time: 0.140785
2023-06-01 11:23:50,102:INFO: Epoch: 18/30, Step: 11/16, Lr: 0.000797093, Loss: 0.001076, Step Loss: 0.001076, Time: 0.089082
2023-06-01 11:23:50,194:INFO: Epoch: 18/30, Step: 12/16, Lr: 0.000797093, Loss: 0.000192, Step Loss: 0.000192, Time: 0.091591
2023-06-01 11:23:50,284:INFO: Epoch: 18/30, Step: 13/16, Lr: 0.000797093, Loss: 0.000039, Step Loss: 0.000039, Time: 0.090174
2023-06-01 11:23:50,375:INFO: Epoch: 18/30, Step: 14/16, Lr: 0.000797093, Loss: 0.000109, Step Loss: 0.000109, Time: 0.089996
2023-06-01 11:23:50,466:INFO: Epoch: 18/30, Step: 15/16, Lr: 0.000797093, Loss: 0.001994, Step Loss: 0.001994, Time: 0.090511
2023-06-01 11:23:50,557:INFO: Epoch: 18/30, Step: 16/16, Lr: 0.000797093, Loss: 0.000089, Step Loss: 0.000089, Time: 0.091071
2023-06-01 11:23:50,776:INFO: Epoch 18/30 Finished, Train Loss: 0.000378
2023-06-01 11:23:52,320:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.17
2023-06-01 11:23:55,512:INFO: Classfication Metrics:
2023-06-01 11:23:55,512:INFO: f1 score: 0.8703 - precision score: 0.8455 - recall score: 0.8966 - accuracy score: 0.894915
2023-06-01 11:23:55,512:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:23:57,259:INFO: Epoch: 19/30, Step: 1/16, Lr: 0.000702907, Loss: 0.000069, Step Loss: 0.000069, Time: 1.736901
2023-06-01 11:23:57,362:INFO: Epoch: 19/30, Step: 2/16, Lr: 0.000702907, Loss: 0.000143, Step Loss: 0.000143, Time: 0.102862
2023-06-01 11:23:57,459:INFO: Epoch: 19/30, Step: 3/16, Lr: 0.000702907, Loss: 0.000412, Step Loss: 0.000412, Time: 0.095660
2023-06-01 11:23:57,552:INFO: Epoch: 19/30, Step: 4/16, Lr: 0.000702907, Loss: 0.000002, Step Loss: 0.000002, Time: 0.092426
2023-06-01 11:23:57,663:INFO: Epoch: 19/30, Step: 5/16, Lr: 0.000702907, Loss: 0.000204, Step Loss: 0.000204, Time: 0.085350
2023-06-01 11:23:57,754:INFO: Epoch: 19/30, Step: 6/16, Lr: 0.000702907, Loss: 0.000009, Step Loss: 0.000009, Time: 0.090402
2023-06-01 11:23:57,850:INFO: Epoch: 19/30, Step: 7/16, Lr: 0.000702907, Loss: 0.000044, Step Loss: 0.000044, Time: 0.095595
2023-06-01 11:23:57,949:INFO: Epoch: 19/30, Step: 8/16, Lr: 0.000702907, Loss: 0.000013, Step Loss: 0.000013, Time: 0.099046
2023-06-01 11:23:58,363:INFO: Epoch: 19/30, Step: 9/16, Lr: 0.000702907, Loss: 0.000024, Step Loss: 0.000024, Time: 0.413253
2023-06-01 11:23:58,454:INFO: Epoch: 19/30, Step: 10/16, Lr: 0.000702907, Loss: 0.000061, Step Loss: 0.000061, Time: 0.091299
2023-06-01 11:23:58,545:INFO: Epoch: 19/30, Step: 11/16, Lr: 0.000702907, Loss: 0.000010, Step Loss: 0.000010, Time: 0.090606
2023-06-01 11:23:58,677:INFO: Epoch: 19/30, Step: 12/16, Lr: 0.000702907, Loss: 0.000583, Step Loss: 0.000583, Time: 0.131461
2023-06-01 11:23:58,766:INFO: Epoch: 19/30, Step: 13/16, Lr: 0.000702907, Loss: 0.000066, Step Loss: 0.000066, Time: 0.088589
2023-06-01 11:23:58,856:INFO: Epoch: 19/30, Step: 14/16, Lr: 0.000702907, Loss: 0.000501, Step Loss: 0.000501, Time: 0.089378
2023-06-01 11:23:58,950:INFO: Epoch: 19/30, Step: 15/16, Lr: 0.000702907, Loss: 0.000588, Step Loss: 0.000588, Time: 0.094179
2023-06-01 11:23:59,046:INFO: Epoch: 19/30, Step: 16/16, Lr: 0.000702907, Loss: 0.000036, Step Loss: 0.000036, Time: 0.095212
2023-06-01 11:23:59,263:INFO: Epoch 19/30 Finished, Train Loss: 0.000173
2023-06-01 11:24:00,805:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.18
2023-06-01 11:24:04,012:INFO: Classfication Metrics:
2023-06-01 11:24:04,013:INFO: f1 score: 0.8714 - precision score: 0.8400 - recall score: 0.9052 - accuracy score: 0.894915
2023-06-01 11:24:04,013:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:06,038:INFO: Epoch: 20/30, Step: 1/16, Lr: 0.000609464, Loss: 0.000007, Step Loss: 0.000007, Time: 1.996971
2023-06-01 11:24:06,130:INFO: Epoch: 20/30, Step: 2/16, Lr: 0.000609464, Loss: 0.000451, Step Loss: 0.000451, Time: 0.091353
2023-06-01 11:24:06,215:INFO: Epoch: 20/30, Step: 3/16, Lr: 0.000609464, Loss: 0.000090, Step Loss: 0.000090, Time: 0.084641
2023-06-01 11:24:06,302:INFO: Epoch: 20/30, Step: 4/16, Lr: 0.000609464, Loss: 0.000081, Step Loss: 0.000081, Time: 0.087093
2023-06-01 11:24:06,390:INFO: Epoch: 20/30, Step: 5/16, Lr: 0.000609464, Loss: 0.000322, Step Loss: 0.000322, Time: 0.087162
2023-06-01 11:24:06,480:INFO: Epoch: 20/30, Step: 6/16, Lr: 0.000609464, Loss: 0.000134, Step Loss: 0.000134, Time: 0.089993
2023-06-01 11:24:06,574:INFO: Epoch: 20/30, Step: 7/16, Lr: 0.000609464, Loss: 0.000097, Step Loss: 0.000097, Time: 0.093602
2023-06-01 11:24:06,661:INFO: Epoch: 20/30, Step: 8/16, Lr: 0.000609464, Loss: 0.000152, Step Loss: 0.000152, Time: 0.086814
2023-06-01 11:24:07,170:INFO: Epoch: 20/30, Step: 9/16, Lr: 0.000609464, Loss: 0.000123, Step Loss: 0.000123, Time: 0.508547
2023-06-01 11:24:07,263:INFO: Epoch: 20/30, Step: 10/16, Lr: 0.000609464, Loss: 0.000854, Step Loss: 0.000854, Time: 0.092756
2023-06-01 11:24:07,357:INFO: Epoch: 20/30, Step: 11/16, Lr: 0.000609464, Loss: 0.000043, Step Loss: 0.000043, Time: 0.092711
2023-06-01 11:24:07,445:INFO: Epoch: 20/30, Step: 12/16, Lr: 0.000609464, Loss: 0.004428, Step Loss: 0.004428, Time: 0.088368
2023-06-01 11:24:07,536:INFO: Epoch: 20/30, Step: 13/16, Lr: 0.000609464, Loss: 0.000033, Step Loss: 0.000033, Time: 0.089904
2023-06-01 11:24:07,629:INFO: Epoch: 20/30, Step: 14/16, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.092389
2023-06-01 11:24:07,721:INFO: Epoch: 20/30, Step: 15/16, Lr: 0.000609464, Loss: 0.000149, Step Loss: 0.000149, Time: 0.091542
2023-06-01 11:24:07,812:INFO: Epoch: 20/30, Step: 16/16, Lr: 0.000609464, Loss: 0.000434, Step Loss: 0.000434, Time: 0.090415
2023-06-01 11:24:08,034:INFO: Epoch 20/30 Finished, Train Loss: 0.000462
2023-06-01 11:24:09,492:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19
2023-06-01 11:24:12,737:INFO: Classfication Metrics:
2023-06-01 11:24:12,738:INFO: f1 score: 0.8750 - precision score: 0.8468 - recall score: 0.9052 - accuracy score: 0.898305
2023-06-01 11:24:12,738:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:14,616:INFO: Epoch: 21/30, Step: 1/16, Lr: 0.000518237, Loss: 0.000030, Step Loss: 0.000030, Time: 1.845847
2023-06-01 11:24:14,723:INFO: Epoch: 21/30, Step: 2/16, Lr: 0.000518237, Loss: 0.000023, Step Loss: 0.000023, Time: 0.106700
2023-06-01 11:24:14,812:INFO: Epoch: 21/30, Step: 3/16, Lr: 0.000518237, Loss: 0.000053, Step Loss: 0.000053, Time: 0.088889
2023-06-01 11:24:14,918:INFO: Epoch: 21/30, Step: 4/16, Lr: 0.000518237, Loss: 0.000004, Step Loss: 0.000004, Time: 0.105109
2023-06-01 11:24:15,011:INFO: Epoch: 21/30, Step: 5/16, Lr: 0.000518237, Loss: 0.000064, Step Loss: 0.000064, Time: 0.092968
2023-06-01 11:24:15,104:INFO: Epoch: 21/30, Step: 6/16, Lr: 0.000518237, Loss: 0.000027, Step Loss: 0.000027, Time: 0.092896
2023-06-01 11:24:15,198:INFO: Epoch: 21/30, Step: 7/16, Lr: 0.000518237, Loss: 0.000022, Step Loss: 0.000022, Time: 0.092909
2023-06-01 11:24:15,290:INFO: Epoch: 21/30, Step: 8/16, Lr: 0.000518237, Loss: 0.000032, Step Loss: 0.000032, Time: 0.091975
2023-06-01 11:24:15,400:INFO: Epoch: 21/30, Step: 9/16, Lr: 0.000518237, Loss: 0.000009, Step Loss: 0.000009, Time: 0.108962
2023-06-01 11:24:15,501:INFO: Epoch: 21/30, Step: 10/16, Lr: 0.000518237, Loss: 0.000535, Step Loss: 0.000535, Time: 0.100918
2023-06-01 11:24:15,598:INFO: Epoch: 21/30, Step: 11/16, Lr: 0.000518237, Loss: 0.000054, Step Loss: 0.000054, Time: 0.096665
2023-06-01 11:24:15,783:INFO: Epoch: 21/30, Step: 12/16, Lr: 0.000518237, Loss: 0.000025, Step Loss: 0.000025, Time: 0.185164
2023-06-01 11:24:15,879:INFO: Epoch: 21/30, Step: 13/16, Lr: 0.000518237, Loss: 0.000029, Step Loss: 0.000029, Time: 0.095295
2023-06-01 11:24:15,975:INFO: Epoch: 21/30, Step: 14/16, Lr: 0.000518237, Loss: 0.000006, Step Loss: 0.000006, Time: 0.095650
2023-06-01 11:24:16,071:INFO: Epoch: 21/30, Step: 15/16, Lr: 0.000518237, Loss: 0.000030, Step Loss: 0.000030, Time: 0.095132
2023-06-01 11:24:16,162:INFO: Epoch: 21/30, Step: 16/16, Lr: 0.000518237, Loss: 0.000010, Step Loss: 0.000010, Time: 0.090473
2023-06-01 11:24:16,373:INFO: Epoch 21/30 Finished, Train Loss: 0.000060
2023-06-01 11:24:17,905:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20
2023-06-01 11:24:21,287:INFO: Classfication Metrics:
2023-06-01 11:24:21,287:INFO: f1 score: 0.8739 - precision score: 0.8525 - recall score: 0.8966 - accuracy score: 0.898305
2023-06-01 11:24:21,287:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:23,332:INFO: Epoch: 22/30, Step: 1/16, Lr: 0.000430666, Loss: 0.001843, Step Loss: 0.001843, Time: 2.033279
2023-06-01 11:24:23,420:INFO: Epoch: 22/30, Step: 2/16, Lr: 0.000430666, Loss: 0.000010, Step Loss: 0.000010, Time: 0.087579
2023-06-01 11:24:23,508:INFO: Epoch: 22/30, Step: 3/16, Lr: 0.000430666, Loss: 0.000074, Step Loss: 0.000074, Time: 0.087773
2023-06-01 11:24:23,604:INFO: Epoch: 22/30, Step: 4/16, Lr: 0.000430666, Loss: 0.000494, Step Loss: 0.000494, Time: 0.096041
2023-06-01 11:24:23,694:INFO: Epoch: 22/30, Step: 5/16, Lr: 0.000430666, Loss: 0.000065, Step Loss: 0.000065, Time: 0.089723
2023-06-01 11:24:23,781:INFO: Epoch: 22/30, Step: 6/16, Lr: 0.000430666, Loss: 0.000011, Step Loss: 0.000011, Time: 0.087071
2023-06-01 11:24:23,872:INFO: Epoch: 22/30, Step: 7/16, Lr: 0.000430666, Loss: 0.000069, Step Loss: 0.000069, Time: 0.090310
2023-06-01 11:24:23,962:INFO: Epoch: 22/30, Step: 8/16, Lr: 0.000430666, Loss: 0.000006, Step Loss: 0.000006, Time: 0.089233
2023-06-01 11:24:24,561:INFO: Epoch: 22/30, Step: 9/16, Lr: 0.000430666, Loss: 0.000114, Step Loss: 0.000114, Time: 0.598690
2023-06-01 11:24:24,659:INFO: Epoch: 22/30, Step: 10/16, Lr: 0.000430666, Loss: 0.000178, Step Loss: 0.000178, Time: 0.097310
2023-06-01 11:24:24,747:INFO: Epoch: 22/30, Step: 11/16, Lr: 0.000430666, Loss: 0.000161, Step Loss: 0.000161, Time: 0.088112
2023-06-01 11:24:24,838:INFO: Epoch: 22/30, Step: 12/16, Lr: 0.000430666, Loss: 0.000007, Step Loss: 0.000007, Time: 0.090208
2023-06-01 11:24:24,927:INFO: Epoch: 22/30, Step: 13/16, Lr: 0.000430666, Loss: 0.000029, Step Loss: 0.000029, Time: 0.089010
2023-06-01 11:24:25,022:INFO: Epoch: 22/30, Step: 14/16, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.094507
2023-06-01 11:24:25,107:INFO: Epoch: 22/30, Step: 15/16, Lr: 0.000430666, Loss: 0.000014, Step Loss: 0.000014, Time: 0.084376
2023-06-01 11:24:25,192:INFO: Epoch: 22/30, Step: 16/16, Lr: 0.000430666, Loss: 0.000004, Step Loss: 0.000004, Time: 0.085304
2023-06-01 11:24:25,414:INFO: Epoch 22/30 Finished, Train Loss: 0.000192
2023-06-01 11:24:26,857:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.21
2023-06-01 11:24:30,107:INFO: Classfication Metrics:
2023-06-01 11:24:30,108:INFO: f1 score: 0.8729 - precision score: 0.8583 - recall score: 0.8879 - accuracy score: 0.898305
2023-06-01 11:24:30,108:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:32,178:INFO: Epoch: 23/30, Step: 1/16, Lr: 0.000348130, Loss: 0.000047, Step Loss: 0.000047, Time: 2.059831
2023-06-01 11:24:32,269:INFO: Epoch: 23/30, Step: 2/16, Lr: 0.000348130, Loss: 0.000026, Step Loss: 0.000026, Time: 0.090939
2023-06-01 11:24:32,359:INFO: Epoch: 23/30, Step: 3/16, Lr: 0.000348130, Loss: 0.000004, Step Loss: 0.000004, Time: 0.089212
2023-06-01 11:24:32,444:INFO: Epoch: 23/30, Step: 4/16, Lr: 0.000348130, Loss: 0.000003, Step Loss: 0.000003, Time: 0.084507
2023-06-01 11:24:32,532:INFO: Epoch: 23/30, Step: 5/16, Lr: 0.000348130, Loss: 0.000068, Step Loss: 0.000068, Time: 0.087835
2023-06-01 11:24:32,622:INFO: Epoch: 23/30, Step: 6/16, Lr: 0.000348130, Loss: 0.001664, Step Loss: 0.001664, Time: 0.089065
2023-06-01 11:24:32,709:INFO: Epoch: 23/30, Step: 7/16, Lr: 0.000348130, Loss: 0.000008, Step Loss: 0.000008, Time: 0.087448
2023-06-01 11:24:32,802:INFO: Epoch: 23/30, Step: 8/16, Lr: 0.000348130, Loss: 0.000013, Step Loss: 0.000013, Time: 0.092484
2023-06-01 11:24:33,067:INFO: Epoch: 23/30, Step: 9/16, Lr: 0.000348130, Loss: 0.000010, Step Loss: 0.000010, Time: 0.261638
2023-06-01 11:24:33,157:INFO: Epoch: 23/30, Step: 10/16, Lr: 0.000348130, Loss: 0.000056, Step Loss: 0.000056, Time: 0.089138
2023-06-01 11:24:33,247:INFO: Epoch: 23/30, Step: 11/16, Lr: 0.000348130, Loss: 0.000037, Step Loss: 0.000037, Time: 0.089528
2023-06-01 11:24:33,339:INFO: Epoch: 23/30, Step: 12/16, Lr: 0.000348130, Loss: 0.000088, Step Loss: 0.000088, Time: 0.091601
2023-06-01 11:24:33,424:INFO: Epoch: 23/30, Step: 13/16, Lr: 0.000348130, Loss: 0.000207, Step Loss: 0.000207, Time: 0.084997
2023-06-01 11:24:33,514:INFO: Epoch: 23/30, Step: 14/16, Lr: 0.000348130, Loss: 0.000237, Step Loss: 0.000237, Time: 0.089072
2023-06-01 11:24:33,604:INFO: Epoch: 23/30, Step: 15/16, Lr: 0.000348130, Loss: 0.000011, Step Loss: 0.000011, Time: 0.089232
2023-06-01 11:24:33,704:INFO: Epoch: 23/30, Step: 16/16, Lr: 0.000348130, Loss: 0.000010, Step Loss: 0.000010, Time: 0.100212
2023-06-01 11:24:33,928:INFO: Epoch 23/30 Finished, Train Loss: 0.000156
2023-06-01 11:24:35,384:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.22
2023-06-01 11:24:38,633:INFO: Classfication Metrics:
2023-06-01 11:24:38,633:INFO: f1 score: 0.8739 - precision score: 0.8525 - recall score: 0.8966 - accuracy score: 0.898305
2023-06-01 11:24:38,634:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:40,554:INFO: Epoch: 24/30, Step: 1/16, Lr: 0.000271932, Loss: 0.000192, Step Loss: 0.000192, Time: 1.891261
2023-06-01 11:24:40,639:INFO: Epoch: 24/30, Step: 2/16, Lr: 0.000271932, Loss: 0.000039, Step Loss: 0.000039, Time: 0.084779
2023-06-01 11:24:40,742:INFO: Epoch: 24/30, Step: 3/16, Lr: 0.000271932, Loss: 0.000062, Step Loss: 0.000062, Time: 0.101970
2023-06-01 11:24:40,838:INFO: Epoch: 24/30, Step: 4/16, Lr: 0.000271932, Loss: 0.000005, Step Loss: 0.000005, Time: 0.095776
2023-06-01 11:24:40,930:INFO: Epoch: 24/30, Step: 5/16, Lr: 0.000271932, Loss: 0.000017, Step Loss: 0.000017, Time: 0.091417
2023-06-01 11:24:41,022:INFO: Epoch: 24/30, Step: 6/16, Lr: 0.000271932, Loss: 0.000177, Step Loss: 0.000177, Time: 0.091529
2023-06-01 11:24:41,107:INFO: Epoch: 24/30, Step: 7/16, Lr: 0.000271932, Loss: 0.000138, Step Loss: 0.000138, Time: 0.085145
2023-06-01 11:24:41,198:INFO: Epoch: 24/30, Step: 8/16, Lr: 0.000271932, Loss: 0.000013, Step Loss: 0.000013, Time: 0.090142
2023-06-01 11:24:41,301:INFO: Epoch: 24/30, Step: 9/16, Lr: 0.000271932, Loss: 0.000061, Step Loss: 0.000061, Time: 0.102352
2023-06-01 11:24:41,397:INFO: Epoch: 24/30, Step: 10/16, Lr: 0.000271932, Loss: 0.000028, Step Loss: 0.000028, Time: 0.094422
2023-06-01 11:24:41,719:INFO: Epoch: 24/30, Step: 11/16, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.321632
2023-06-01 11:24:41,809:INFO: Epoch: 24/30, Step: 12/16, Lr: 0.000271932, Loss: 0.000010, Step Loss: 0.000010, Time: 0.089539
2023-06-01 11:24:41,901:INFO: Epoch: 24/30, Step: 13/16, Lr: 0.000271932, Loss: 0.000575, Step Loss: 0.000575, Time: 0.091153
2023-06-01 11:24:41,992:INFO: Epoch: 24/30, Step: 14/16, Lr: 0.000271932, Loss: 0.000008, Step Loss: 0.000008, Time: 0.090889
2023-06-01 11:24:42,083:INFO: Epoch: 24/30, Step: 15/16, Lr: 0.000271932, Loss: 0.000027, Step Loss: 0.000027, Time: 0.090020
2023-06-01 11:24:42,179:INFO: Epoch: 24/30, Step: 16/16, Lr: 0.000271932, Loss: 0.000024, Step Loss: 0.000024, Time: 0.095598
2023-06-01 11:24:42,394:INFO: Epoch 24/30 Finished, Train Loss: 0.000086
2023-06-01 11:24:43,913:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.23
2023-06-01 11:24:47,146:INFO: Classfication Metrics:
2023-06-01 11:24:47,147:INFO: f1 score: 0.8739 - precision score: 0.8525 - recall score: 0.8966 - accuracy score: 0.898305
2023-06-01 11:24:47,147:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:49,037:INFO: Epoch: 25/30, Step: 1/16, Lr: 0.000203274, Loss: 0.000448, Step Loss: 0.000448, Time: 1.881060
2023-06-01 11:24:49,311:INFO: Epoch: 25/30, Step: 2/16, Lr: 0.000203274, Loss: 0.000043, Step Loss: 0.000043, Time: 0.272994
2023-06-01 11:24:49,400:INFO: Epoch: 25/30, Step: 3/16, Lr: 0.000203274, Loss: 0.000005, Step Loss: 0.000005, Time: 0.088912
2023-06-01 11:24:49,490:INFO: Epoch: 25/30, Step: 4/16, Lr: 0.000203274, Loss: 0.000022, Step Loss: 0.000022, Time: 0.089697
2023-06-01 11:24:49,578:INFO: Epoch: 25/30, Step: 5/16, Lr: 0.000203274, Loss: 0.000022, Step Loss: 0.000022, Time: 0.087644
2023-06-01 11:24:49,671:INFO: Epoch: 25/30, Step: 6/16, Lr: 0.000203274, Loss: 0.000014, Step Loss: 0.000014, Time: 0.092018
2023-06-01 11:24:49,759:INFO: Epoch: 25/30, Step: 7/16, Lr: 0.000203274, Loss: 0.000042, Step Loss: 0.000042, Time: 0.087774
2023-06-01 11:24:49,850:INFO: Epoch: 25/30, Step: 8/16, Lr: 0.000203274, Loss: 0.014426, Step Loss: 0.014426, Time: 0.090199
2023-06-01 11:24:50,416:INFO: Epoch: 25/30, Step: 9/16, Lr: 0.000203274, Loss: 0.001013, Step Loss: 0.001013, Time: 0.566089
2023-06-01 11:24:50,507:INFO: Epoch: 25/30, Step: 10/16, Lr: 0.000203274, Loss: 0.000029, Step Loss: 0.000029, Time: 0.090008
2023-06-01 11:24:50,598:INFO: Epoch: 25/30, Step: 11/16, Lr: 0.000203274, Loss: 0.000088, Step Loss: 0.000088, Time: 0.090887
2023-06-01 11:24:50,690:INFO: Epoch: 25/30, Step: 12/16, Lr: 0.000203274, Loss: 0.001247, Step Loss: 0.001247, Time: 0.091044
2023-06-01 11:24:50,787:INFO: Epoch: 25/30, Step: 13/16, Lr: 0.000203274, Loss: 0.000037, Step Loss: 0.000037, Time: 0.096751
2023-06-01 11:24:50,879:INFO: Epoch: 25/30, Step: 14/16, Lr: 0.000203274, Loss: 0.000092, Step Loss: 0.000092, Time: 0.091125
2023-06-01 11:24:50,971:INFO: Epoch: 25/30, Step: 15/16, Lr: 0.000203274, Loss: 0.000014, Step Loss: 0.000014, Time: 0.091872
2023-06-01 11:24:51,067:INFO: Epoch: 25/30, Step: 16/16, Lr: 0.000203274, Loss: 0.000006, Step Loss: 0.000006, Time: 0.095395
2023-06-01 11:24:51,271:INFO: Epoch 25/30 Finished, Train Loss: 0.001097
2023-06-01 11:24:52,797:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.24
2023-06-01 11:24:56,073:INFO: Classfication Metrics:
2023-06-01 11:24:56,074:INFO: f1 score: 0.8670 - precision score: 0.8632 - recall score: 0.8707 - accuracy score: 0.894915
2023-06-01 11:24:56,074:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:24:58,182:INFO: Epoch: 26/30, Step: 1/16, Lr: 0.000143237, Loss: 0.000006, Step Loss: 0.000006, Time: 2.098850
2023-06-01 11:24:58,271:INFO: Epoch: 26/30, Step: 2/16, Lr: 0.000143237, Loss: 0.000008, Step Loss: 0.000008, Time: 0.088563
2023-06-01 11:24:58,359:INFO: Epoch: 26/30, Step: 3/16, Lr: 0.000143237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.087869
2023-06-01 11:24:58,452:INFO: Epoch: 26/30, Step: 4/16, Lr: 0.000143237, Loss: 0.000013, Step Loss: 0.000013, Time: 0.092514
2023-06-01 11:24:58,554:INFO: Epoch: 26/30, Step: 5/16, Lr: 0.000143237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.100966
2023-06-01 11:24:58,643:INFO: Epoch: 26/30, Step: 6/16, Lr: 0.000143237, Loss: 0.000041, Step Loss: 0.000041, Time: 0.089072
2023-06-01 11:24:58,736:INFO: Epoch: 26/30, Step: 7/16, Lr: 0.000143237, Loss: 0.000017, Step Loss: 0.000017, Time: 0.092657
2023-06-01 11:24:58,826:INFO: Epoch: 26/30, Step: 8/16, Lr: 0.000143237, Loss: 0.000032, Step Loss: 0.000032, Time: 0.089473
2023-06-01 11:24:58,926:INFO: Epoch: 26/30, Step: 9/16, Lr: 0.000143237, Loss: 0.000094, Step Loss: 0.000094, Time: 0.099103
2023-06-01 11:24:59,018:INFO: Epoch: 26/30, Step: 10/16, Lr: 0.000143237, Loss: 0.000567, Step Loss: 0.000567, Time: 0.091985
2023-06-01 11:24:59,112:INFO: Epoch: 26/30, Step: 11/16, Lr: 0.000143237, Loss: 0.001569, Step Loss: 0.001569, Time: 0.093396
2023-06-01 11:24:59,208:INFO: Epoch: 26/30, Step: 12/16, Lr: 0.000143237, Loss: 0.000051, Step Loss: 0.000051, Time: 0.095893
2023-06-01 11:24:59,306:INFO: Epoch: 26/30, Step: 13/16, Lr: 0.000143237, Loss: 0.000158, Step Loss: 0.000158, Time: 0.097389
2023-06-01 11:24:59,392:INFO: Epoch: 26/30, Step: 14/16, Lr: 0.000143237, Loss: 0.000059, Step Loss: 0.000059, Time: 0.084936
2023-06-01 11:24:59,486:INFO: Epoch: 26/30, Step: 15/16, Lr: 0.000143237, Loss: 0.000048, Step Loss: 0.000048, Time: 0.094351
2023-06-01 11:24:59,575:INFO: Epoch: 26/30, Step: 16/16, Lr: 0.000143237, Loss: 0.000011, Step Loss: 0.000011, Time: 0.088124
2023-06-01 11:24:59,788:INFO: Epoch 26/30 Finished, Train Loss: 0.000168
2023-06-01 11:25:01,263:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.25
2023-06-01 11:25:04,548:INFO: Classfication Metrics:
2023-06-01 11:25:04,548:INFO: f1 score: 0.8670 - precision score: 0.8632 - recall score: 0.8707 - accuracy score: 0.894915
2023-06-01 11:25:04,548:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:25:06,830:INFO: Epoch: 27/30, Step: 1/16, Lr: 0.000092770, Loss: 0.000045, Step Loss: 0.000045, Time: 2.191753
2023-06-01 11:25:06,922:INFO: Epoch: 27/30, Step: 2/16, Lr: 0.000092770, Loss: 0.000019, Step Loss: 0.000019, Time: 0.091483
2023-06-01 11:25:07,011:INFO: Epoch: 27/30, Step: 3/16, Lr: 0.000092770, Loss: 0.000032, Step Loss: 0.000032, Time: 0.088463
2023-06-01 11:25:07,099:INFO: Epoch: 27/30, Step: 4/16, Lr: 0.000092770, Loss: 0.000044, Step Loss: 0.000044, Time: 0.087666
2023-06-01 11:25:07,190:INFO: Epoch: 27/30, Step: 5/16, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.090930
2023-06-01 11:25:07,279:INFO: Epoch: 27/30, Step: 6/16, Lr: 0.000092770, Loss: 0.000043, Step Loss: 0.000043, Time: 0.087882
2023-06-01 11:25:07,367:INFO: Epoch: 27/30, Step: 7/16, Lr: 0.000092770, Loss: 0.000025, Step Loss: 0.000025, Time: 0.088140
2023-06-01 11:25:07,458:INFO: Epoch: 27/30, Step: 8/16, Lr: 0.000092770, Loss: 0.000156, Step Loss: 0.000156, Time: 0.090405
2023-06-01 11:25:07,875:INFO: Epoch: 27/30, Step: 9/16, Lr: 0.000092770, Loss: 0.000254, Step Loss: 0.000254, Time: 0.416936
2023-06-01 11:25:07,966:INFO: Epoch: 27/30, Step: 10/16, Lr: 0.000092770, Loss: 0.000016, Step Loss: 0.000016, Time: 0.090246
2023-06-01 11:25:08,068:INFO: Epoch: 27/30, Step: 11/16, Lr: 0.000092770, Loss: 0.000039, Step Loss: 0.000039, Time: 0.092448
2023-06-01 11:25:08,158:INFO: Epoch: 27/30, Step: 12/16, Lr: 0.000092770, Loss: 0.000060, Step Loss: 0.000060, Time: 0.089618
2023-06-01 11:25:08,248:INFO: Epoch: 27/30, Step: 13/16, Lr: 0.000092770, Loss: 0.000015, Step Loss: 0.000015, Time: 0.089267
2023-06-01 11:25:08,336:INFO: Epoch: 27/30, Step: 14/16, Lr: 0.000092770, Loss: 0.000017, Step Loss: 0.000017, Time: 0.087835
2023-06-01 11:25:08,425:INFO: Epoch: 27/30, Step: 15/16, Lr: 0.000092770, Loss: 0.000070, Step Loss: 0.000070, Time: 0.088580
2023-06-01 11:25:08,514:INFO: Epoch: 27/30, Step: 16/16, Lr: 0.000092770, Loss: 0.000156, Step Loss: 0.000156, Time: 0.088943
2023-06-01 11:25:08,725:INFO: Epoch 27/30 Finished, Train Loss: 0.000062
2023-06-01 11:25:10,136:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.26
2023-06-01 11:25:13,430:INFO: Classfication Metrics:
2023-06-01 11:25:13,430:INFO: f1 score: 0.8670 - precision score: 0.8632 - recall score: 0.8707 - accuracy score: 0.894915
2023-06-01 11:25:13,430:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:25:15,090:INFO: Epoch: 28/30, Step: 1/16, Lr: 0.000052668, Loss: 0.000068, Step Loss: 0.000068, Time: 1.626333
2023-06-01 11:25:15,447:INFO: Epoch: 28/30, Step: 2/16, Lr: 0.000052668, Loss: 0.000037, Step Loss: 0.000037, Time: 0.357184
2023-06-01 11:25:15,539:INFO: Epoch: 28/30, Step: 3/16, Lr: 0.000052668, Loss: 0.000020, Step Loss: 0.000020, Time: 0.090886
2023-06-01 11:25:15,625:INFO: Epoch: 28/30, Step: 4/16, Lr: 0.000052668, Loss: 0.000091, Step Loss: 0.000091, Time: 0.086641
2023-06-01 11:25:15,716:INFO: Epoch: 28/30, Step: 5/16, Lr: 0.000052668, Loss: 0.000076, Step Loss: 0.000076, Time: 0.090568
2023-06-01 11:25:15,800:INFO: Epoch: 28/30, Step: 6/16, Lr: 0.000052668, Loss: 0.000011, Step Loss: 0.000011, Time: 0.083161
2023-06-01 11:25:15,892:INFO: Epoch: 28/30, Step: 7/16, Lr: 0.000052668, Loss: 0.000041, Step Loss: 0.000041, Time: 0.092332
2023-06-01 11:25:15,987:INFO: Epoch: 28/30, Step: 8/16, Lr: 0.000052668, Loss: 0.000067, Step Loss: 0.000067, Time: 0.094707
2023-06-01 11:25:16,087:INFO: Epoch: 28/30, Step: 9/16, Lr: 0.000052668, Loss: 0.000013, Step Loss: 0.000013, Time: 0.099285
2023-06-01 11:25:16,356:INFO: Epoch: 28/30, Step: 10/16, Lr: 0.000052668, Loss: 0.000039, Step Loss: 0.000039, Time: 0.268197
2023-06-01 11:25:16,451:INFO: Epoch: 28/30, Step: 11/16, Lr: 0.000052668, Loss: 0.000062, Step Loss: 0.000062, Time: 0.095217
2023-06-01 11:25:16,545:INFO: Epoch: 28/30, Step: 12/16, Lr: 0.000052668, Loss: 0.000138, Step Loss: 0.000138, Time: 0.093712
2023-06-01 11:25:16,643:INFO: Epoch: 28/30, Step: 13/16, Lr: 0.000052668, Loss: 0.000052, Step Loss: 0.000052, Time: 0.096986
2023-06-01 11:25:16,737:INFO: Epoch: 28/30, Step: 14/16, Lr: 0.000052668, Loss: 0.000036, Step Loss: 0.000036, Time: 0.093720
2023-06-01 11:25:16,830:INFO: Epoch: 28/30, Step: 15/16, Lr: 0.000052668, Loss: 0.000044, Step Loss: 0.000044, Time: 0.092125
2023-06-01 11:25:16,932:INFO: Epoch: 28/30, Step: 16/16, Lr: 0.000052668, Loss: 0.001933, Step Loss: 0.001933, Time: 0.102427
2023-06-01 11:25:17,143:INFO: Epoch 28/30 Finished, Train Loss: 0.000171
2023-06-01 11:25:18,582:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.27
2023-06-01 11:25:21,748:INFO: Classfication Metrics:
2023-06-01 11:25:21,749:INFO: f1 score: 0.8670 - precision score: 0.8632 - recall score: 0.8707 - accuracy score: 0.894915
2023-06-01 11:25:21,749:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:25:23,656:INFO: Epoch: 29/30, Step: 1/16, Lr: 0.000023563, Loss: 0.000094, Step Loss: 0.000094, Time: 1.897761
2023-06-01 11:25:23,747:INFO: Epoch: 29/30, Step: 2/16, Lr: 0.000023563, Loss: 0.000175, Step Loss: 0.000175, Time: 0.090839
2023-06-01 11:25:23,843:INFO: Epoch: 29/30, Step: 3/16, Lr: 0.000023563, Loss: 0.000004, Step Loss: 0.000004, Time: 0.095229
2023-06-01 11:25:23,945:INFO: Epoch: 29/30, Step: 4/16, Lr: 0.000023563, Loss: 0.000521, Step Loss: 0.000521, Time: 0.101737
2023-06-01 11:25:24,034:INFO: Epoch: 29/30, Step: 5/16, Lr: 0.000023563, Loss: 0.000044, Step Loss: 0.000044, Time: 0.088829
2023-06-01 11:25:24,125:INFO: Epoch: 29/30, Step: 6/16, Lr: 0.000023563, Loss: 0.000139, Step Loss: 0.000139, Time: 0.090645
2023-06-01 11:25:24,219:INFO: Epoch: 29/30, Step: 7/16, Lr: 0.000023563, Loss: 0.002105, Step Loss: 0.002105, Time: 0.093316
2023-06-01 11:25:24,315:INFO: Epoch: 29/30, Step: 8/16, Lr: 0.000023563, Loss: 0.000016, Step Loss: 0.000016, Time: 0.095500
2023-06-01 11:25:24,675:INFO: Epoch: 29/30, Step: 9/16, Lr: 0.000023563, Loss: 0.000385, Step Loss: 0.000385, Time: 0.359581
2023-06-01 11:25:24,765:INFO: Epoch: 29/30, Step: 10/16, Lr: 0.000023563, Loss: 0.000017, Step Loss: 0.000017, Time: 0.089698
2023-06-01 11:25:24,855:INFO: Epoch: 29/30, Step: 11/16, Lr: 0.000023563, Loss: 0.001214, Step Loss: 0.001214, Time: 0.089530
2023-06-01 11:25:24,947:INFO: Epoch: 29/30, Step: 12/16, Lr: 0.000023563, Loss: 0.000013, Step Loss: 0.000013, Time: 0.091006
2023-06-01 11:25:25,035:INFO: Epoch: 29/30, Step: 13/16, Lr: 0.000023563, Loss: 0.000543, Step Loss: 0.000543, Time: 0.088121
2023-06-01 11:25:25,130:INFO: Epoch: 29/30, Step: 14/16, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.094136
2023-06-01 11:25:25,219:INFO: Epoch: 29/30, Step: 15/16, Lr: 0.000023563, Loss: 0.000368, Step Loss: 0.000368, Time: 0.088793
2023-06-01 11:25:25,315:INFO: Epoch: 29/30, Step: 16/16, Lr: 0.000023563, Loss: 0.001954, Step Loss: 0.001954, Time: 0.095975
2023-06-01 11:25:25,532:INFO: Epoch 29/30 Finished, Train Loss: 0.000475
2023-06-01 11:25:26,952:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.28
2023-06-01 11:25:30,210:INFO: Classfication Metrics:
2023-06-01 11:25:30,211:INFO: f1 score: 0.8670 - precision score: 0.8632 - recall score: 0.8707 - accuracy score: 0.894915
2023-06-01 11:25:30,211:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:25:31,814:INFO: Epoch: 30/30, Step: 1/16, Lr: 0.000005914, Loss: 0.000246, Step Loss: 0.000246, Time: 1.593929
2023-06-01 11:25:32,066:INFO: Epoch: 30/30, Step: 2/16, Lr: 0.000005914, Loss: 0.000011, Step Loss: 0.000011, Time: 0.250913
2023-06-01 11:25:32,158:INFO: Epoch: 30/30, Step: 3/16, Lr: 0.000005914, Loss: 0.000008, Step Loss: 0.000008, Time: 0.092515
2023-06-01 11:25:32,257:INFO: Epoch: 30/30, Step: 4/16, Lr: 0.000005914, Loss: 0.000048, Step Loss: 0.000048, Time: 0.098093
2023-06-01 11:25:32,390:INFO: Epoch: 30/30, Step: 5/16, Lr: 0.000005914, Loss: 0.000010, Step Loss: 0.000010, Time: 0.132854
2023-06-01 11:25:32,478:INFO: Epoch: 30/30, Step: 6/16, Lr: 0.000005914, Loss: 0.000025, Step Loss: 0.000025, Time: 0.087347
2023-06-01 11:25:32,565:INFO: Epoch: 30/30, Step: 7/16, Lr: 0.000005914, Loss: 0.000009, Step Loss: 0.000009, Time: 0.087100
2023-06-01 11:25:32,654:INFO: Epoch: 30/30, Step: 8/16, Lr: 0.000005914, Loss: 0.000027, Step Loss: 0.000027, Time: 0.088544
2023-06-01 11:25:32,749:INFO: Epoch: 30/30, Step: 9/16, Lr: 0.000005914, Loss: 0.000091, Step Loss: 0.000091, Time: 0.094513
2023-06-01 11:25:32,842:INFO: Epoch: 30/30, Step: 10/16, Lr: 0.000005914, Loss: 0.000059, Step Loss: 0.000059, Time: 0.092644
2023-06-01 11:25:33,074:INFO: Epoch: 30/30, Step: 11/16, Lr: 0.000005914, Loss: 0.000314, Step Loss: 0.000314, Time: 0.231057
2023-06-01 11:25:33,164:INFO: Epoch: 30/30, Step: 12/16, Lr: 0.000005914, Loss: 0.000223, Step Loss: 0.000223, Time: 0.089529
2023-06-01 11:25:33,259:INFO: Epoch: 30/30, Step: 13/16, Lr: 0.000005914, Loss: 0.000005, Step Loss: 0.000005, Time: 0.094497
2023-06-01 11:25:33,350:INFO: Epoch: 30/30, Step: 14/16, Lr: 0.000005914, Loss: 0.000056, Step Loss: 0.000056, Time: 0.090750
2023-06-01 11:25:33,439:INFO: Epoch: 30/30, Step: 15/16, Lr: 0.000005914, Loss: 0.000029, Step Loss: 0.000029, Time: 0.088707
2023-06-01 11:25:33,539:INFO: Epoch: 30/30, Step: 16/16, Lr: 0.000005914, Loss: 0.001683, Step Loss: 0.001683, Time: 0.099053
2023-06-01 11:25:33,750:INFO: Epoch 30/30 Finished, Train Loss: 0.000178
2023-06-01 11:25:35,161:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.29
2023-06-01 11:25:38,413:INFO: Classfication Metrics:
2023-06-01 11:25:38,413:INFO: f1 score: 0.8670 - precision score: 0.8632 - recall score: 0.8707 - accuracy score: 0.894915
2023-06-01 11:25:38,413:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10, the F1 is: 0.8934
2023-06-01 11:25:38,413:INFO: ***** Running testing *****
2023-06-01 11:25:38,413:INFO:   Num examples = 295
2023-06-01 11:25:38,413:INFO:   Batch size = 128
2023-06-01 11:25:42,368:INFO: Classfication Metrics:
2023-06-01 11:25:42,368:INFO: f1 score: 0.8934 - precision score: 0.8516 - recall score: 0.9397 - accuracy score: 0.911864
2023-06-01 11:26:57,970:INFO: Effective parameters:
2023-06-01 11:26:57,970:INFO:   <<< CUDA_VISIBLE_DEVICES: 6
2023-06-01 11:26:57,970:INFO:   <<< attention_model: bilinear
2023-06-01 11:26:57,970:INFO:   <<< batch_size: 64
2023-06-01 11:26:57,970:INFO:   <<< batch_size_val: 128
2023-06-01 11:26:57,970:INFO:   <<< dataset: weibo
2023-06-01 11:26:57,970:INFO:   <<< debug: False
2023-06-01 11:26:57,970:INFO:   <<< do_train: True
2023-06-01 11:26:57,970:INFO:   <<< exchange: False
2023-06-01 11:26:57,970:INFO:   <<< exchange_early: False
2023-06-01 11:26:57,970:INFO:   <<< expand_image: True
2023-06-01 11:26:57,971:INFO:   <<< expand_language: True
2023-06-01 11:26:57,971:INFO:   <<< freeze_image: True
2023-06-01 11:26:57,971:INFO:   <<< freeze_language: True
2023-06-01 11:26:57,971:INFO:   <<< image_model_type: clip
2023-06-01 11:26:57,971:INFO:   <<< image_size: 224
2023-06-01 11:26:57,971:INFO:   <<< init_model: 
2023-06-01 11:26:57,971:INFO:   <<< l1_lamda: 0.0002
2023-06-01 11:26:57,971:INFO:   <<< language_model_type: bert
2023-06-01 11:26:57,971:INFO:   <<< local_rank: 0
2023-06-01 11:26:57,971:INFO:   <<< loss_weight: 1,1
2023-06-01 11:26:57,971:INFO:   <<< lr: 0.00015
2023-06-01 11:26:57,971:INFO:   <<< max_text_len: 50
2023-06-01 11:26:57,971:INFO:   <<< more_layer: True
2023-06-01 11:26:57,971:INFO:   <<< n_epochs: 30
2023-06-01 11:26:57,971:INFO:   <<< num_workers: 8
2023-06-01 11:26:57,971:INFO:   <<< output_dir: experiments/weibo/train_weibo_clip_bert_bilinear_more
2023-06-01 11:26:57,971:INFO:   <<< pin_memory: False
2023-06-01 11:26:57,971:INFO:   <<< pretrained_image: True
2023-06-01 11:26:57,971:INFO:   <<< pretrained_language: True
2023-06-01 11:26:57,971:INFO:   <<< rank: 0
2023-06-01 11:26:57,971:INFO:   <<< seed: 42
2023-06-01 11:26:57,971:INFO:   <<< weight_decay: 2e-05
2023-06-01 11:26:57,971:INFO:   <<< world_size: 1
2023-06-01 11:26:57,971:INFO: device: cuda:0 n_gpu: 1
2023-06-01 11:27:06,214:INFO: ***** Running training *****
2023-06-01 11:27:06,214:INFO:   Num examples = 1026
2023-06-01 11:27:06,214:INFO:   Batch size = 64
2023-06-01 11:27:06,214:INFO: ***** Running validation  *****
2023-06-01 11:27:06,214:INFO:   Num examples = 146
2023-06-01 11:27:06,214:INFO:   Batch size = 128
2023-06-01 11:27:07,786:INFO: Epoch: 1/30, Step: 1/16, Lr: 0.000150000, Loss: 1.199502, Step Loss: 1.199502, Time: 1.570107
2023-06-01 11:27:07,887:INFO: Epoch: 1/30, Step: 2/16, Lr: 0.000150000, Loss: 7.470043, Step Loss: 7.470043, Time: 0.100286
2023-06-01 11:27:07,976:INFO: Epoch: 1/30, Step: 3/16, Lr: 0.000150000, Loss: 2.677905, Step Loss: 2.677905, Time: 0.088989
2023-06-01 11:27:08,084:INFO: Epoch: 1/30, Step: 4/16, Lr: 0.000150000, Loss: 1.751332, Step Loss: 1.751332, Time: 0.107105
2023-06-01 11:27:08,175:INFO: Epoch: 1/30, Step: 5/16, Lr: 0.000150000, Loss: 2.515599, Step Loss: 2.515599, Time: 0.090785
2023-06-01 11:27:08,266:INFO: Epoch: 1/30, Step: 6/16, Lr: 0.000150000, Loss: 2.762732, Step Loss: 2.762732, Time: 0.091152
2023-06-01 11:27:08,366:INFO: Epoch: 1/30, Step: 7/16, Lr: 0.000150000, Loss: 2.680668, Step Loss: 2.680668, Time: 0.099463
2023-06-01 11:27:08,459:INFO: Epoch: 1/30, Step: 8/16, Lr: 0.000150000, Loss: 0.842304, Step Loss: 0.842304, Time: 0.092691
2023-06-01 11:27:08,609:INFO: Epoch: 1/30, Step: 9/16, Lr: 0.000150000, Loss: 0.687230, Step Loss: 0.687230, Time: 0.149635
2023-06-01 11:27:08,723:INFO: Epoch: 1/30, Step: 10/16, Lr: 0.000150000, Loss: 1.624317, Step Loss: 1.624317, Time: 0.113047
2023-06-01 11:27:08,820:INFO: Epoch: 1/30, Step: 11/16, Lr: 0.000150000, Loss: 2.265565, Step Loss: 2.265565, Time: 0.096217
2023-06-01 11:27:08,922:INFO: Epoch: 1/30, Step: 12/16, Lr: 0.000150000, Loss: 0.846362, Step Loss: 0.846362, Time: 0.101898
2023-06-01 11:27:09,023:INFO: Epoch: 1/30, Step: 13/16, Lr: 0.000150000, Loss: 0.645910, Step Loss: 0.645910, Time: 0.100224
2023-06-01 11:27:09,125:INFO: Epoch: 1/30, Step: 14/16, Lr: 0.000150000, Loss: 0.993394, Step Loss: 0.993394, Time: 0.101573
2023-06-01 11:27:09,233:INFO: Epoch: 1/30, Step: 15/16, Lr: 0.000150000, Loss: 1.276734, Step Loss: 1.276734, Time: 0.107135
2023-06-01 11:27:09,335:INFO: Epoch: 1/30, Step: 16/16, Lr: 0.000150000, Loss: 1.342295, Step Loss: 1.342295, Time: 0.101643
2023-06-01 11:27:09,497:INFO: Epoch 1/30 Finished, Train Loss: 1.973868
2023-06-01 11:27:31,519:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0
2023-06-01 11:27:34,443:INFO: Classfication Metrics:
2023-06-01 11:27:34,443:INFO: f1 score: 0.6809 - precision score: 0.8889 - recall score: 0.5517 - accuracy score: 0.796610
2023-06-01 11:27:34,443:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0, the F1 is: 0.6809
2023-06-01 11:27:36,458:INFO: Epoch: 2/30, Step: 1/16, Lr: 0.000420000, Loss: 0.725459, Step Loss: 0.725459, Time: 2.005319
2023-06-01 11:27:36,550:INFO: Epoch: 2/30, Step: 2/16, Lr: 0.000420000, Loss: 0.619163, Step Loss: 0.619163, Time: 0.091498
2023-06-01 11:27:36,641:INFO: Epoch: 2/30, Step: 3/16, Lr: 0.000420000, Loss: 2.240305, Step Loss: 2.240305, Time: 0.091507
2023-06-01 11:27:36,733:INFO: Epoch: 2/30, Step: 4/16, Lr: 0.000420000, Loss: 0.517982, Step Loss: 0.517982, Time: 0.091378
2023-06-01 11:27:36,823:INFO: Epoch: 2/30, Step: 5/16, Lr: 0.000420000, Loss: 0.753372, Step Loss: 0.753372, Time: 0.089648
2023-06-01 11:27:36,914:INFO: Epoch: 2/30, Step: 6/16, Lr: 0.000420000, Loss: 1.237752, Step Loss: 1.237752, Time: 0.090388
2023-06-01 11:27:37,003:INFO: Epoch: 2/30, Step: 7/16, Lr: 0.000420000, Loss: 0.538089, Step Loss: 0.538089, Time: 0.088737
2023-06-01 11:27:37,089:INFO: Epoch: 2/30, Step: 8/16, Lr: 0.000420000, Loss: 0.329106, Step Loss: 0.329106, Time: 0.085383
2023-06-01 11:27:37,200:INFO: Epoch: 2/30, Step: 9/16, Lr: 0.000420000, Loss: 1.179922, Step Loss: 1.179922, Time: 0.110380
2023-06-01 11:27:37,289:INFO: Epoch: 2/30, Step: 10/16, Lr: 0.000420000, Loss: 0.796703, Step Loss: 0.796703, Time: 0.088715
2023-06-01 11:27:37,379:INFO: Epoch: 2/30, Step: 11/16, Lr: 0.000420000, Loss: 0.371612, Step Loss: 0.371612, Time: 0.089562
2023-06-01 11:27:37,471:INFO: Epoch: 2/30, Step: 12/16, Lr: 0.000420000, Loss: 0.639213, Step Loss: 0.639213, Time: 0.091103
2023-06-01 11:27:37,560:INFO: Epoch: 2/30, Step: 13/16, Lr: 0.000420000, Loss: 0.895921, Step Loss: 0.895921, Time: 0.089220
2023-06-01 11:27:37,655:INFO: Epoch: 2/30, Step: 14/16, Lr: 0.000420000, Loss: 0.495831, Step Loss: 0.495831, Time: 0.093910
2023-06-01 11:27:37,750:INFO: Epoch: 2/30, Step: 15/16, Lr: 0.000420000, Loss: 0.185141, Step Loss: 0.185141, Time: 0.095108
2023-06-01 11:27:37,841:INFO: Epoch: 2/30, Step: 16/16, Lr: 0.000420000, Loss: 0.750159, Step Loss: 0.750159, Time: 0.090103
2023-06-01 11:27:37,985:INFO: Epoch 2/30 Finished, Train Loss: 0.767233
2023-06-01 11:28:09,385:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1
2023-06-01 11:28:12,308:INFO: Classfication Metrics:
2023-06-01 11:28:12,308:INFO: f1 score: 0.7914 - precision score: 0.6790 - recall score: 0.9483 - accuracy score: 0.803390
2023-06-01 11:28:12,308:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.7914
2023-06-01 11:28:13,888:INFO: Epoch: 3/30, Step: 1/16, Lr: 0.000690000, Loss: 0.570915, Step Loss: 0.570915, Time: 1.548825
2023-06-01 11:28:14,091:INFO: Epoch: 3/30, Step: 2/16, Lr: 0.000690000, Loss: 0.348122, Step Loss: 0.348122, Time: 0.202965
2023-06-01 11:28:14,180:INFO: Epoch: 3/30, Step: 3/16, Lr: 0.000690000, Loss: 0.633200, Step Loss: 0.633200, Time: 0.088726
2023-06-01 11:28:14,270:INFO: Epoch: 3/30, Step: 4/16, Lr: 0.000690000, Loss: 0.513738, Step Loss: 0.513738, Time: 0.089131
2023-06-01 11:28:14,359:INFO: Epoch: 3/30, Step: 5/16, Lr: 0.000690000, Loss: 0.344717, Step Loss: 0.344717, Time: 0.089368
2023-06-01 11:28:14,447:INFO: Epoch: 3/30, Step: 6/16, Lr: 0.000690000, Loss: 0.378825, Step Loss: 0.378825, Time: 0.087334
2023-06-01 11:28:14,537:INFO: Epoch: 3/30, Step: 7/16, Lr: 0.000690000, Loss: 0.290064, Step Loss: 0.290064, Time: 0.089264
2023-06-01 11:28:14,623:INFO: Epoch: 3/30, Step: 8/16, Lr: 0.000690000, Loss: 0.509284, Step Loss: 0.509284, Time: 0.085221
2023-06-01 11:28:14,713:INFO: Epoch: 3/30, Step: 9/16, Lr: 0.000690000, Loss: 0.594877, Step Loss: 0.594877, Time: 0.089570
2023-06-01 11:28:15,000:INFO: Epoch: 3/30, Step: 10/16, Lr: 0.000690000, Loss: 0.335969, Step Loss: 0.335969, Time: 0.286992
2023-06-01 11:28:15,092:INFO: Epoch: 3/30, Step: 11/16, Lr: 0.000690000, Loss: 0.267175, Step Loss: 0.267175, Time: 0.091872
2023-06-01 11:28:15,182:INFO: Epoch: 3/30, Step: 12/16, Lr: 0.000690000, Loss: 0.591928, Step Loss: 0.591928, Time: 0.089101
2023-06-01 11:28:15,270:INFO: Epoch: 3/30, Step: 13/16, Lr: 0.000690000, Loss: 0.455155, Step Loss: 0.455155, Time: 0.087567
2023-06-01 11:28:15,358:INFO: Epoch: 3/30, Step: 14/16, Lr: 0.000690000, Loss: 0.423462, Step Loss: 0.423462, Time: 0.087956
2023-06-01 11:28:15,446:INFO: Epoch: 3/30, Step: 15/16, Lr: 0.000690000, Loss: 0.805405, Step Loss: 0.805405, Time: 0.087389
2023-06-01 11:28:15,534:INFO: Epoch: 3/30, Step: 16/16, Lr: 0.000690000, Loss: 0.708856, Step Loss: 0.708856, Time: 0.087215
2023-06-01 11:28:15,675:INFO: Epoch 3/30 Finished, Train Loss: 0.485731
2023-06-01 11:28:36,731:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2
2023-06-01 11:28:39,778:INFO: Classfication Metrics:
2023-06-01 11:28:39,779:INFO: f1 score: 0.7958 - precision score: 0.6726 - recall score: 0.9741 - accuracy score: 0.803390
2023-06-01 11:28:39,779:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2, the F1 is: 0.7958
2023-06-01 11:28:41,610:INFO: Epoch: 4/30, Step: 1/16, Lr: 0.001230000, Loss: 0.150045, Step Loss: 0.150045, Time: 1.821683
2023-06-01 11:28:41,698:INFO: Epoch: 4/30, Step: 2/16, Lr: 0.001230000, Loss: 0.637112, Step Loss: 0.637112, Time: 0.087438
2023-06-01 11:28:41,785:INFO: Epoch: 4/30, Step: 3/16, Lr: 0.001230000, Loss: 0.660595, Step Loss: 0.660595, Time: 0.086857
2023-06-01 11:28:41,872:INFO: Epoch: 4/30, Step: 4/16, Lr: 0.001230000, Loss: 0.537386, Step Loss: 0.537386, Time: 0.086774
2023-06-01 11:28:41,962:INFO: Epoch: 4/30, Step: 5/16, Lr: 0.001230000, Loss: 0.314446, Step Loss: 0.314446, Time: 0.088760
2023-06-01 11:28:42,058:INFO: Epoch: 4/30, Step: 6/16, Lr: 0.001230000, Loss: 0.671261, Step Loss: 0.671261, Time: 0.096185
2023-06-01 11:28:42,155:INFO: Epoch: 4/30, Step: 7/16, Lr: 0.001230000, Loss: 0.682622, Step Loss: 0.682622, Time: 0.096210
2023-06-01 11:28:42,243:INFO: Epoch: 4/30, Step: 8/16, Lr: 0.001230000, Loss: 0.878913, Step Loss: 0.878913, Time: 0.087496
2023-06-01 11:28:42,676:INFO: Epoch: 4/30, Step: 9/16, Lr: 0.001230000, Loss: 0.313400, Step Loss: 0.313400, Time: 0.410598
2023-06-01 11:28:42,764:INFO: Epoch: 4/30, Step: 10/16, Lr: 0.001230000, Loss: 0.735894, Step Loss: 0.735894, Time: 0.087631
2023-06-01 11:28:42,854:INFO: Epoch: 4/30, Step: 11/16, Lr: 0.001230000, Loss: 0.257162, Step Loss: 0.257162, Time: 0.088845
2023-06-01 11:28:42,945:INFO: Epoch: 4/30, Step: 12/16, Lr: 0.001230000, Loss: 1.014749, Step Loss: 1.014749, Time: 0.090584
2023-06-01 11:28:43,035:INFO: Epoch: 4/30, Step: 13/16, Lr: 0.001230000, Loss: 0.351140, Step Loss: 0.351140, Time: 0.089560
2023-06-01 11:28:43,129:INFO: Epoch: 4/30, Step: 14/16, Lr: 0.001230000, Loss: 0.854948, Step Loss: 0.854948, Time: 0.093963
2023-06-01 11:28:43,221:INFO: Epoch: 4/30, Step: 15/16, Lr: 0.001230000, Loss: 0.192100, Step Loss: 0.192100, Time: 0.091069
2023-06-01 11:28:43,310:INFO: Epoch: 4/30, Step: 16/16, Lr: 0.001230000, Loss: 0.795074, Step Loss: 0.795074, Time: 0.088679
2023-06-01 11:28:43,455:INFO: Epoch 4/30 Finished, Train Loss: 0.565428
2023-06-01 11:28:56,233:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.3
2023-06-01 11:28:59,166:INFO: Classfication Metrics:
2023-06-01 11:28:59,166:INFO: f1 score: 0.7767 - precision score: 0.8889 - recall score: 0.6897 - accuracy score: 0.844068
2023-06-01 11:28:59,166:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2, the F1 is: 0.7958
2023-06-01 11:29:00,977:INFO: Epoch: 5/30, Step: 1/16, Lr: 0.001500000, Loss: 0.489985, Step Loss: 0.489985, Time: 1.782947
2023-06-01 11:29:01,083:INFO: Epoch: 5/30, Step: 2/16, Lr: 0.001500000, Loss: 0.446204, Step Loss: 0.446204, Time: 0.105202
2023-06-01 11:29:01,179:INFO: Epoch: 5/30, Step: 3/16, Lr: 0.001500000, Loss: 0.214816, Step Loss: 0.214816, Time: 0.095191
2023-06-01 11:29:01,279:INFO: Epoch: 5/30, Step: 4/16, Lr: 0.001500000, Loss: 0.248973, Step Loss: 0.248973, Time: 0.099782
2023-06-01 11:29:01,375:INFO: Epoch: 5/30, Step: 5/16, Lr: 0.001500000, Loss: 0.363072, Step Loss: 0.363072, Time: 0.095685
2023-06-01 11:29:01,467:INFO: Epoch: 5/30, Step: 6/16, Lr: 0.001500000, Loss: 0.160006, Step Loss: 0.160006, Time: 0.091897
2023-06-01 11:29:01,561:INFO: Epoch: 5/30, Step: 7/16, Lr: 0.001500000, Loss: 0.136392, Step Loss: 0.136392, Time: 0.093834
2023-06-01 11:29:01,669:INFO: Epoch: 5/30, Step: 8/16, Lr: 0.001500000, Loss: 0.480263, Step Loss: 0.480263, Time: 0.107009
2023-06-01 11:29:01,823:INFO: Epoch: 5/30, Step: 9/16, Lr: 0.001500000, Loss: 0.306630, Step Loss: 0.306630, Time: 0.153616
2023-06-01 11:29:01,920:INFO: Epoch: 5/30, Step: 10/16, Lr: 0.001500000, Loss: 0.395334, Step Loss: 0.395334, Time: 0.096834
2023-06-01 11:29:02,007:INFO: Epoch: 5/30, Step: 11/16, Lr: 0.001500000, Loss: 0.511504, Step Loss: 0.511504, Time: 0.086419
2023-06-01 11:29:02,106:INFO: Epoch: 5/30, Step: 12/16, Lr: 0.001500000, Loss: 0.285379, Step Loss: 0.285379, Time: 0.098018
2023-06-01 11:29:02,200:INFO: Epoch: 5/30, Step: 13/16, Lr: 0.001500000, Loss: 0.391567, Step Loss: 0.391567, Time: 0.094178
2023-06-01 11:29:02,291:INFO: Epoch: 5/30, Step: 14/16, Lr: 0.001500000, Loss: 0.482744, Step Loss: 0.482744, Time: 0.090423
2023-06-01 11:29:02,383:INFO: Epoch: 5/30, Step: 15/16, Lr: 0.001500000, Loss: 0.703236, Step Loss: 0.703236, Time: 0.091202
2023-06-01 11:29:02,497:INFO: Epoch: 5/30, Step: 16/16, Lr: 0.001500000, Loss: 0.900862, Step Loss: 0.900862, Time: 0.090611
2023-06-01 11:29:02,668:INFO: Epoch 5/30 Finished, Train Loss: 0.407311
2023-06-01 11:29:19,446:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4
2023-06-01 11:29:22,567:INFO: Classfication Metrics:
2023-06-01 11:29:22,567:INFO: f1 score: 0.8621 - precision score: 0.8621 - recall score: 0.8621 - accuracy score: 0.891525
2023-06-01 11:29:22,567:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:29:24,370:INFO: Epoch: 6/30, Step: 1/16, Lr: 0.001500000, Loss: 0.045277, Step Loss: 0.045277, Time: 1.755081
2023-06-01 11:29:24,459:INFO: Epoch: 6/30, Step: 2/16, Lr: 0.001500000, Loss: 0.576491, Step Loss: 0.576491, Time: 0.088078
2023-06-01 11:29:24,547:INFO: Epoch: 6/30, Step: 3/16, Lr: 0.001500000, Loss: 0.044410, Step Loss: 0.044410, Time: 0.087625
2023-06-01 11:29:24,635:INFO: Epoch: 6/30, Step: 4/16, Lr: 0.001500000, Loss: 0.199174, Step Loss: 0.199174, Time: 0.087489
2023-06-01 11:29:24,721:INFO: Epoch: 6/30, Step: 5/16, Lr: 0.001500000, Loss: 0.331402, Step Loss: 0.331402, Time: 0.086107
2023-06-01 11:29:24,813:INFO: Epoch: 6/30, Step: 6/16, Lr: 0.001500000, Loss: 0.115558, Step Loss: 0.115558, Time: 0.091566
2023-06-01 11:29:24,905:INFO: Epoch: 6/30, Step: 7/16, Lr: 0.001500000, Loss: 0.560365, Step Loss: 0.560365, Time: 0.091438
2023-06-01 11:29:24,993:INFO: Epoch: 6/30, Step: 8/16, Lr: 0.001500000, Loss: 0.160550, Step Loss: 0.160550, Time: 0.086946
2023-06-01 11:29:25,185:INFO: Epoch: 6/30, Step: 9/16, Lr: 0.001500000, Loss: 0.393304, Step Loss: 0.393304, Time: 0.191768
2023-06-01 11:29:25,272:INFO: Epoch: 6/30, Step: 10/16, Lr: 0.001500000, Loss: 0.255306, Step Loss: 0.255306, Time: 0.087175
2023-06-01 11:29:25,362:INFO: Epoch: 6/30, Step: 11/16, Lr: 0.001500000, Loss: 0.107023, Step Loss: 0.107023, Time: 0.089385
2023-06-01 11:29:25,458:INFO: Epoch: 6/30, Step: 12/16, Lr: 0.001500000, Loss: 0.580113, Step Loss: 0.580113, Time: 0.095508
2023-06-01 11:29:25,547:INFO: Epoch: 6/30, Step: 13/16, Lr: 0.001500000, Loss: 0.082160, Step Loss: 0.082160, Time: 0.088308
2023-06-01 11:29:25,638:INFO: Epoch: 6/30, Step: 14/16, Lr: 0.001500000, Loss: 0.839484, Step Loss: 0.839484, Time: 0.091143
2023-06-01 11:29:25,730:INFO: Epoch: 6/30, Step: 15/16, Lr: 0.001500000, Loss: 0.012571, Step Loss: 0.012571, Time: 0.091007
2023-06-01 11:29:25,819:INFO: Epoch: 6/30, Step: 16/16, Lr: 0.001500000, Loss: 0.055127, Step Loss: 0.055127, Time: 0.088489
2023-06-01 11:29:25,959:INFO: Epoch 6/30 Finished, Train Loss: 0.272395
2023-06-01 11:29:42,249:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5
2023-06-01 11:29:45,160:INFO: Classfication Metrics:
2023-06-01 11:29:45,160:INFO: f1 score: 0.6629 - precision score: 0.9831 - recall score: 0.5000 - accuracy score: 0.800000
2023-06-01 11:29:45,160:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:29:46,667:INFO: Epoch: 7/30, Step: 1/16, Lr: 0.001494086, Loss: 1.185292, Step Loss: 1.185292, Time: 1.496679
2023-06-01 11:29:46,764:INFO: Epoch: 7/30, Step: 2/16, Lr: 0.001494086, Loss: 0.258079, Step Loss: 0.258079, Time: 0.096508
2023-06-01 11:29:46,854:INFO: Epoch: 7/30, Step: 3/16, Lr: 0.001494086, Loss: 1.121572, Step Loss: 1.121572, Time: 0.089949
2023-06-01 11:29:46,947:INFO: Epoch: 7/30, Step: 4/16, Lr: 0.001494086, Loss: 0.196981, Step Loss: 0.196981, Time: 0.091865
2023-06-01 11:29:47,043:INFO: Epoch: 7/30, Step: 5/16, Lr: 0.001494086, Loss: 0.238890, Step Loss: 0.238890, Time: 0.095333
2023-06-01 11:29:47,145:INFO: Epoch: 7/30, Step: 6/16, Lr: 0.001494086, Loss: 0.319186, Step Loss: 0.319186, Time: 0.101678
2023-06-01 11:29:47,234:INFO: Epoch: 7/30, Step: 7/16, Lr: 0.001494086, Loss: 0.199016, Step Loss: 0.199016, Time: 0.088734
2023-06-01 11:29:47,326:INFO: Epoch: 7/30, Step: 8/16, Lr: 0.001494086, Loss: 0.170077, Step Loss: 0.170077, Time: 0.091859
2023-06-01 11:29:47,614:INFO: Epoch: 7/30, Step: 9/16, Lr: 0.001494086, Loss: 1.012792, Step Loss: 1.012792, Time: 0.287337
2023-06-01 11:29:47,701:INFO: Epoch: 7/30, Step: 10/16, Lr: 0.001494086, Loss: 0.107163, Step Loss: 0.107163, Time: 0.086968
2023-06-01 11:29:47,790:INFO: Epoch: 7/30, Step: 11/16, Lr: 0.001494086, Loss: 0.221533, Step Loss: 0.221533, Time: 0.088506
2023-06-01 11:29:47,889:INFO: Epoch: 7/30, Step: 12/16, Lr: 0.001494086, Loss: 0.242604, Step Loss: 0.242604, Time: 0.098304
2023-06-01 11:29:48,043:INFO: Epoch: 7/30, Step: 13/16, Lr: 0.001494086, Loss: 0.102444, Step Loss: 0.102444, Time: 0.153819
2023-06-01 11:29:48,151:INFO: Epoch: 7/30, Step: 14/16, Lr: 0.001494086, Loss: 0.146073, Step Loss: 0.146073, Time: 0.095691
2023-06-01 11:29:48,244:INFO: Epoch: 7/30, Step: 15/16, Lr: 0.001494086, Loss: 0.711366, Step Loss: 0.711366, Time: 0.092158
2023-06-01 11:29:48,337:INFO: Epoch: 7/30, Step: 16/16, Lr: 0.001494086, Loss: 0.529110, Step Loss: 0.529110, Time: 0.093390
2023-06-01 11:29:48,473:INFO: Epoch 7/30 Finished, Train Loss: 0.422636
2023-06-01 11:30:07,123:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6
2023-06-01 11:30:10,149:INFO: Classfication Metrics:
2023-06-01 11:30:10,150:INFO: f1 score: 0.8376 - precision score: 0.8305 - recall score: 0.8448 - accuracy score: 0.871186
2023-06-01 11:30:10,150:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:30:11,822:INFO: Epoch: 8/30, Step: 1/16, Lr: 0.001476437, Loss: 0.049255, Step Loss: 0.049255, Time: 1.660803
2023-06-01 11:30:11,913:INFO: Epoch: 8/30, Step: 2/16, Lr: 0.001476437, Loss: 0.247534, Step Loss: 0.247534, Time: 0.090860
2023-06-01 11:30:12,057:INFO: Epoch: 8/30, Step: 3/16, Lr: 0.001476437, Loss: 0.928514, Step Loss: 0.928514, Time: 0.143566
2023-06-01 11:30:12,151:INFO: Epoch: 8/30, Step: 4/16, Lr: 0.001476437, Loss: 0.140157, Step Loss: 0.140157, Time: 0.093405
2023-06-01 11:30:12,243:INFO: Epoch: 8/30, Step: 5/16, Lr: 0.001476437, Loss: 0.060706, Step Loss: 0.060706, Time: 0.092003
2023-06-01 11:30:12,335:INFO: Epoch: 8/30, Step: 6/16, Lr: 0.001476437, Loss: 0.289526, Step Loss: 0.289526, Time: 0.091520
2023-06-01 11:30:12,428:INFO: Epoch: 8/30, Step: 7/16, Lr: 0.001476437, Loss: 0.169730, Step Loss: 0.169730, Time: 0.092887
2023-06-01 11:30:12,522:INFO: Epoch: 8/30, Step: 8/16, Lr: 0.001476437, Loss: 0.159129, Step Loss: 0.159129, Time: 0.093260
2023-06-01 11:30:13,180:INFO: Epoch: 8/30, Step: 9/16, Lr: 0.001476437, Loss: 0.421306, Step Loss: 0.421306, Time: 0.657166
2023-06-01 11:30:13,278:INFO: Epoch: 8/30, Step: 10/16, Lr: 0.001476437, Loss: 0.545539, Step Loss: 0.545539, Time: 0.097970
2023-06-01 11:30:13,372:INFO: Epoch: 8/30, Step: 11/16, Lr: 0.001476437, Loss: 0.106054, Step Loss: 0.106054, Time: 0.093526
2023-06-01 11:30:13,466:INFO: Epoch: 8/30, Step: 12/16, Lr: 0.001476437, Loss: 0.057597, Step Loss: 0.057597, Time: 0.094082
2023-06-01 11:30:13,587:INFO: Epoch: 8/30, Step: 13/16, Lr: 0.001476437, Loss: 0.224022, Step Loss: 0.224022, Time: 0.091186
2023-06-01 11:30:13,676:INFO: Epoch: 8/30, Step: 14/16, Lr: 0.001476437, Loss: 0.113786, Step Loss: 0.113786, Time: 0.089073
2023-06-01 11:30:13,767:INFO: Epoch: 8/30, Step: 15/16, Lr: 0.001476437, Loss: 0.191602, Step Loss: 0.191602, Time: 0.090028
2023-06-01 11:30:13,863:INFO: Epoch: 8/30, Step: 16/16, Lr: 0.001476437, Loss: 0.244511, Step Loss: 0.244511, Time: 0.095756
2023-06-01 11:30:14,032:INFO: Epoch 8/30 Finished, Train Loss: 0.246810
2023-06-01 11:30:30,608:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.7
2023-06-01 11:30:33,697:INFO: Classfication Metrics:
2023-06-01 11:30:33,705:INFO: f1 score: 0.8519 - precision score: 0.9200 - recall score: 0.7931 - accuracy score: 0.891525
2023-06-01 11:30:33,705:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:30:35,428:INFO: Epoch: 9/30, Step: 1/16, Lr: 0.001447332, Loss: 0.090783, Step Loss: 0.090783, Time: 1.693737
2023-06-01 11:30:35,523:INFO: Epoch: 9/30, Step: 2/16, Lr: 0.001447332, Loss: 0.200191, Step Loss: 0.200191, Time: 0.093951
2023-06-01 11:30:35,610:INFO: Epoch: 9/30, Step: 3/16, Lr: 0.001447332, Loss: 0.230543, Step Loss: 0.230543, Time: 0.087323
2023-06-01 11:30:35,701:INFO: Epoch: 9/30, Step: 4/16, Lr: 0.001447332, Loss: 0.108327, Step Loss: 0.108327, Time: 0.090332
2023-06-01 11:30:35,793:INFO: Epoch: 9/30, Step: 5/16, Lr: 0.001447332, Loss: 0.037807, Step Loss: 0.037807, Time: 0.091369
2023-06-01 11:30:35,880:INFO: Epoch: 9/30, Step: 6/16, Lr: 0.001447332, Loss: 0.046352, Step Loss: 0.046352, Time: 0.086823
2023-06-01 11:30:35,971:INFO: Epoch: 9/30, Step: 7/16, Lr: 0.001447332, Loss: 0.096234, Step Loss: 0.096234, Time: 0.090318
2023-06-01 11:30:36,059:INFO: Epoch: 9/30, Step: 8/16, Lr: 0.001447332, Loss: 0.204535, Step Loss: 0.204535, Time: 0.087759
2023-06-01 11:30:36,310:INFO: Epoch: 9/30, Step: 9/16, Lr: 0.001447332, Loss: 0.036029, Step Loss: 0.036029, Time: 0.250321
2023-06-01 11:30:36,399:INFO: Epoch: 9/30, Step: 10/16, Lr: 0.001447332, Loss: 0.051432, Step Loss: 0.051432, Time: 0.088609
2023-06-01 11:30:36,485:INFO: Epoch: 9/30, Step: 11/16, Lr: 0.001447332, Loss: 0.000593, Step Loss: 0.000593, Time: 0.085275
2023-06-01 11:30:36,575:INFO: Epoch: 9/30, Step: 12/16, Lr: 0.001447332, Loss: 0.208358, Step Loss: 0.208358, Time: 0.089895
2023-06-01 11:30:36,665:INFO: Epoch: 9/30, Step: 13/16, Lr: 0.001447332, Loss: 0.315183, Step Loss: 0.315183, Time: 0.089999
2023-06-01 11:30:36,754:INFO: Epoch: 9/30, Step: 14/16, Lr: 0.001447332, Loss: 0.095133, Step Loss: 0.095133, Time: 0.088789
2023-06-01 11:30:36,852:INFO: Epoch: 9/30, Step: 15/16, Lr: 0.001447332, Loss: 0.091086, Step Loss: 0.091086, Time: 0.097879
2023-06-01 11:30:36,946:INFO: Epoch: 9/30, Step: 16/16, Lr: 0.001447332, Loss: 0.411608, Step Loss: 0.411608, Time: 0.093324
2023-06-01 11:30:37,092:INFO: Epoch 9/30 Finished, Train Loss: 0.139012
2023-06-01 11:30:57,420:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.8
2023-06-01 11:31:00,460:INFO: Classfication Metrics:
2023-06-01 11:31:00,460:INFO: f1 score: 0.8085 - precision score: 0.6867 - recall score: 0.9828 - accuracy score: 0.816949
2023-06-01 11:31:00,460:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:31:02,167:INFO: Epoch: 10/30, Step: 1/16, Lr: 0.001407230, Loss: 0.270300, Step Loss: 0.270300, Time: 1.676911
2023-06-01 11:31:02,263:INFO: Epoch: 10/30, Step: 2/16, Lr: 0.001407230, Loss: 0.175238, Step Loss: 0.175238, Time: 0.095861
2023-06-01 11:31:02,351:INFO: Epoch: 10/30, Step: 3/16, Lr: 0.001407230, Loss: 0.049730, Step Loss: 0.049730, Time: 0.087281
2023-06-01 11:31:02,443:INFO: Epoch: 10/30, Step: 4/16, Lr: 0.001407230, Loss: 0.154948, Step Loss: 0.154948, Time: 0.092071
2023-06-01 11:31:02,538:INFO: Epoch: 10/30, Step: 5/16, Lr: 0.001407230, Loss: 0.223237, Step Loss: 0.223237, Time: 0.095181
2023-06-01 11:31:02,627:INFO: Epoch: 10/30, Step: 6/16, Lr: 0.001407230, Loss: 0.500255, Step Loss: 0.500255, Time: 0.087904
2023-06-01 11:31:02,714:INFO: Epoch: 10/30, Step: 7/16, Lr: 0.001407230, Loss: 0.210098, Step Loss: 0.210098, Time: 0.086871
2023-06-01 11:31:02,805:INFO: Epoch: 10/30, Step: 8/16, Lr: 0.001407230, Loss: 0.005577, Step Loss: 0.005577, Time: 0.090843
2023-06-01 11:31:02,898:INFO: Epoch: 10/30, Step: 9/16, Lr: 0.001407230, Loss: 0.017402, Step Loss: 0.017402, Time: 0.092903
2023-06-01 11:31:03,010:INFO: Epoch: 10/30, Step: 10/16, Lr: 0.001407230, Loss: 0.384701, Step Loss: 0.384701, Time: 0.111357
2023-06-01 11:31:03,159:INFO: Epoch: 10/30, Step: 11/16, Lr: 0.001407230, Loss: 0.677783, Step Loss: 0.677783, Time: 0.148011
2023-06-01 11:31:03,246:INFO: Epoch: 10/30, Step: 12/16, Lr: 0.001407230, Loss: 0.130916, Step Loss: 0.130916, Time: 0.086681
2023-06-01 11:31:03,465:INFO: Epoch: 10/30, Step: 13/16, Lr: 0.001407230, Loss: 0.003668, Step Loss: 0.003668, Time: 0.218709
2023-06-01 11:31:03,554:INFO: Epoch: 10/30, Step: 14/16, Lr: 0.001407230, Loss: 0.407173, Step Loss: 0.407173, Time: 0.088737
2023-06-01 11:31:03,649:INFO: Epoch: 10/30, Step: 15/16, Lr: 0.001407230, Loss: 0.462354, Step Loss: 0.462354, Time: 0.094465
2023-06-01 11:31:03,735:INFO: Epoch: 10/30, Step: 16/16, Lr: 0.001407230, Loss: 0.478811, Step Loss: 0.478811, Time: 0.085790
2023-06-01 11:31:03,878:INFO: Epoch 10/30 Finished, Train Loss: 0.259512
2023-06-01 11:31:27,914:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.9
2023-06-01 11:31:30,767:INFO: Classfication Metrics:
2023-06-01 11:31:30,768:INFO: f1 score: 0.8406 - precision score: 0.9560 - recall score: 0.7500 - accuracy score: 0.888136
2023-06-01 11:31:30,768:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:31:32,206:INFO: Epoch: 11/30, Step: 1/16, Lr: 0.001356763, Loss: 0.002210, Step Loss: 0.002210, Time: 1.421344
2023-06-01 11:31:32,296:INFO: Epoch: 11/30, Step: 2/16, Lr: 0.001356763, Loss: 0.000089, Step Loss: 0.000089, Time: 0.089896
2023-06-01 11:31:32,387:INFO: Epoch: 11/30, Step: 3/16, Lr: 0.001356763, Loss: 0.019617, Step Loss: 0.019617, Time: 0.089771
2023-06-01 11:31:32,736:INFO: Epoch: 11/30, Step: 4/16, Lr: 0.001356763, Loss: 0.135699, Step Loss: 0.135699, Time: 0.349334
2023-06-01 11:31:32,821:INFO: Epoch: 11/30, Step: 5/16, Lr: 0.001356763, Loss: 0.188014, Step Loss: 0.188014, Time: 0.084044
2023-06-01 11:31:32,909:INFO: Epoch: 11/30, Step: 6/16, Lr: 0.001356763, Loss: 0.240834, Step Loss: 0.240834, Time: 0.087295
2023-06-01 11:31:32,993:INFO: Epoch: 11/30, Step: 7/16, Lr: 0.001356763, Loss: 0.000284, Step Loss: 0.000284, Time: 0.083927
2023-06-01 11:31:33,082:INFO: Epoch: 11/30, Step: 8/16, Lr: 0.001356763, Loss: 0.000909, Step Loss: 0.000909, Time: 0.088820
2023-06-01 11:31:33,264:INFO: Epoch: 11/30, Step: 9/16, Lr: 0.001356763, Loss: 0.049292, Step Loss: 0.049292, Time: 0.180970
2023-06-01 11:31:33,351:INFO: Epoch: 11/30, Step: 10/16, Lr: 0.001356763, Loss: 0.169742, Step Loss: 0.169742, Time: 0.087092
2023-06-01 11:31:33,439:INFO: Epoch: 11/30, Step: 11/16, Lr: 0.001356763, Loss: 0.006495, Step Loss: 0.006495, Time: 0.087628
2023-06-01 11:31:33,541:INFO: Epoch: 11/30, Step: 12/16, Lr: 0.001356763, Loss: 0.043130, Step Loss: 0.043130, Time: 0.100880
2023-06-01 11:31:33,630:INFO: Epoch: 11/30, Step: 13/16, Lr: 0.001356763, Loss: 0.015602, Step Loss: 0.015602, Time: 0.089121
2023-06-01 11:31:33,723:INFO: Epoch: 11/30, Step: 14/16, Lr: 0.001356763, Loss: 0.001093, Step Loss: 0.001093, Time: 0.091881
2023-06-01 11:31:33,811:INFO: Epoch: 11/30, Step: 15/16, Lr: 0.001356763, Loss: 0.000018, Step Loss: 0.000018, Time: 0.088373
2023-06-01 11:31:33,906:INFO: Epoch: 11/30, Step: 16/16, Lr: 0.001356763, Loss: 0.007204, Step Loss: 0.007204, Time: 0.094541
2023-06-01 11:31:34,064:INFO: Epoch 11/30 Finished, Train Loss: 0.055014
2023-06-01 11:31:50,734:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10
2023-06-01 11:31:53,814:INFO: Classfication Metrics:
2023-06-01 11:31:53,814:INFO: f1 score: 0.8439 - precision score: 0.8264 - recall score: 0.8621 - accuracy score: 0.874576
2023-06-01 11:31:53,815:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:31:55,742:INFO: Epoch: 12/30, Step: 1/16, Lr: 0.001296726, Loss: 0.038491, Step Loss: 0.038491, Time: 1.916039
2023-06-01 11:31:55,836:INFO: Epoch: 12/30, Step: 2/16, Lr: 0.001296726, Loss: 0.046950, Step Loss: 0.046950, Time: 0.093867
2023-06-01 11:31:55,941:INFO: Epoch: 12/30, Step: 3/16, Lr: 0.001296726, Loss: 0.047788, Step Loss: 0.047788, Time: 0.104940
2023-06-01 11:31:56,037:INFO: Epoch: 12/30, Step: 4/16, Lr: 0.001296726, Loss: 0.000305, Step Loss: 0.000305, Time: 0.095045
2023-06-01 11:31:56,136:INFO: Epoch: 12/30, Step: 5/16, Lr: 0.001296726, Loss: 0.022562, Step Loss: 0.022562, Time: 0.098186
2023-06-01 11:31:56,232:INFO: Epoch: 12/30, Step: 6/16, Lr: 0.001296726, Loss: 0.000867, Step Loss: 0.000867, Time: 0.095661
2023-06-01 11:31:56,326:INFO: Epoch: 12/30, Step: 7/16, Lr: 0.001296726, Loss: 0.006734, Step Loss: 0.006734, Time: 0.093534
2023-06-01 11:31:56,424:INFO: Epoch: 12/30, Step: 8/16, Lr: 0.001296726, Loss: 0.009979, Step Loss: 0.009979, Time: 0.097522
2023-06-01 11:31:56,639:INFO: Epoch: 12/30, Step: 9/16, Lr: 0.001296726, Loss: 0.000012, Step Loss: 0.000012, Time: 0.214640
2023-06-01 11:31:56,742:INFO: Epoch: 12/30, Step: 10/16, Lr: 0.001296726, Loss: 0.000032, Step Loss: 0.000032, Time: 0.102432
2023-06-01 11:31:56,840:INFO: Epoch: 12/30, Step: 11/16, Lr: 0.001296726, Loss: 0.000541, Step Loss: 0.000541, Time: 0.097145
2023-06-01 11:31:56,940:INFO: Epoch: 12/30, Step: 12/16, Lr: 0.001296726, Loss: 0.000001, Step Loss: 0.000001, Time: 0.098540
2023-06-01 11:31:57,041:INFO: Epoch: 12/30, Step: 13/16, Lr: 0.001296726, Loss: 0.000020, Step Loss: 0.000020, Time: 0.100868
2023-06-01 11:31:57,126:INFO: Epoch: 12/30, Step: 14/16, Lr: 0.001296726, Loss: 0.000009, Step Loss: 0.000009, Time: 0.084658
2023-06-01 11:31:57,211:INFO: Epoch: 12/30, Step: 15/16, Lr: 0.001296726, Loss: 0.001572, Step Loss: 0.001572, Time: 0.084501
2023-06-01 11:31:57,297:INFO: Epoch: 12/30, Step: 16/16, Lr: 0.001296726, Loss: 0.000268, Step Loss: 0.000268, Time: 0.085969
2023-06-01 11:31:57,466:INFO: Epoch 12/30 Finished, Train Loss: 0.011008
2023-06-01 11:32:19,556:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.11
2023-06-01 11:32:22,690:INFO: Classfication Metrics:
2023-06-01 11:32:22,690:INFO: f1 score: 0.8584 - precision score: 0.8818 - recall score: 0.8362 - accuracy score: 0.891525
2023-06-01 11:32:22,690:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:32:24,236:INFO: Epoch: 13/30, Step: 1/16, Lr: 0.001228068, Loss: 0.005514, Step Loss: 0.005514, Time: 1.521045
2023-06-01 11:32:24,701:INFO: Epoch: 13/30, Step: 2/16, Lr: 0.001228068, Loss: 0.000923, Step Loss: 0.000923, Time: 0.464578
2023-06-01 11:32:24,797:INFO: Epoch: 13/30, Step: 3/16, Lr: 0.001228068, Loss: 0.000046, Step Loss: 0.000046, Time: 0.095285
2023-06-01 11:32:24,888:INFO: Epoch: 13/30, Step: 4/16, Lr: 0.001228068, Loss: 0.000047, Step Loss: 0.000047, Time: 0.090544
2023-06-01 11:32:24,978:INFO: Epoch: 13/30, Step: 5/16, Lr: 0.001228068, Loss: 0.000164, Step Loss: 0.000164, Time: 0.089218
2023-06-01 11:32:25,069:INFO: Epoch: 13/30, Step: 6/16, Lr: 0.001228068, Loss: 0.055761, Step Loss: 0.055761, Time: 0.091338
2023-06-01 11:32:25,166:INFO: Epoch: 13/30, Step: 7/16, Lr: 0.001228068, Loss: 0.000008, Step Loss: 0.000008, Time: 0.096329
2023-06-01 11:32:25,269:INFO: Epoch: 13/30, Step: 8/16, Lr: 0.001228068, Loss: 0.000121, Step Loss: 0.000121, Time: 0.102648
2023-06-01 11:32:25,411:INFO: Epoch: 13/30, Step: 9/16, Lr: 0.001228068, Loss: 0.008845, Step Loss: 0.008845, Time: 0.102254
2023-06-01 11:32:25,520:INFO: Epoch: 13/30, Step: 10/16, Lr: 0.001228068, Loss: 0.001160, Step Loss: 0.001160, Time: 0.108255
2023-06-01 11:32:25,614:INFO: Epoch: 13/30, Step: 11/16, Lr: 0.001228068, Loss: 0.000007, Step Loss: 0.000007, Time: 0.093726
2023-06-01 11:32:25,715:INFO: Epoch: 13/30, Step: 12/16, Lr: 0.001228068, Loss: 0.001241, Step Loss: 0.001241, Time: 0.099904
2023-06-01 11:32:25,806:INFO: Epoch: 13/30, Step: 13/16, Lr: 0.001228068, Loss: 0.000043, Step Loss: 0.000043, Time: 0.090173
2023-06-01 11:32:25,896:INFO: Epoch: 13/30, Step: 14/16, Lr: 0.001228068, Loss: 0.000888, Step Loss: 0.000888, Time: 0.089832
2023-06-01 11:32:25,989:INFO: Epoch: 13/30, Step: 15/16, Lr: 0.001228068, Loss: 0.000109, Step Loss: 0.000109, Time: 0.092511
2023-06-01 11:32:26,084:INFO: Epoch: 13/30, Step: 16/16, Lr: 0.001228068, Loss: 0.002429, Step Loss: 0.002429, Time: 0.094034
2023-06-01 11:32:26,227:INFO: Epoch 13/30 Finished, Train Loss: 0.004832
2023-06-01 11:32:44,784:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.12
2023-06-01 11:32:48,023:INFO: Classfication Metrics:
2023-06-01 11:32:48,023:INFO: f1 score: 0.8492 - precision score: 0.7868 - recall score: 0.9224 - accuracy score: 0.871186
2023-06-01 11:32:48,023:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:32:49,715:INFO: Epoch: 14/30, Step: 1/16, Lr: 0.001151870, Loss: 0.000018, Step Loss: 0.000018, Time: 1.662995
2023-06-01 11:32:50,037:INFO: Epoch: 14/30, Step: 2/16, Lr: 0.001151870, Loss: 0.017130, Step Loss: 0.017130, Time: 0.321682
2023-06-01 11:32:50,126:INFO: Epoch: 14/30, Step: 3/16, Lr: 0.001151870, Loss: 0.002813, Step Loss: 0.002813, Time: 0.088289
2023-06-01 11:32:50,214:INFO: Epoch: 14/30, Step: 4/16, Lr: 0.001151870, Loss: 0.000002, Step Loss: 0.000002, Time: 0.087907
2023-06-01 11:32:50,303:INFO: Epoch: 14/30, Step: 5/16, Lr: 0.001151870, Loss: 0.000064, Step Loss: 0.000064, Time: 0.087833
2023-06-01 11:32:50,391:INFO: Epoch: 14/30, Step: 6/16, Lr: 0.001151870, Loss: 0.007145, Step Loss: 0.007145, Time: 0.087694
2023-06-01 11:32:50,486:INFO: Epoch: 14/30, Step: 7/16, Lr: 0.001151870, Loss: 0.000007, Step Loss: 0.000007, Time: 0.094832
2023-06-01 11:32:50,572:INFO: Epoch: 14/30, Step: 8/16, Lr: 0.001151870, Loss: 0.000039, Step Loss: 0.000039, Time: 0.085910
2023-06-01 11:32:50,664:INFO: Epoch: 14/30, Step: 9/16, Lr: 0.001151870, Loss: 0.000039, Step Loss: 0.000039, Time: 0.091460
2023-06-01 11:32:50,966:INFO: Epoch: 14/30, Step: 10/16, Lr: 0.001151870, Loss: 0.000103, Step Loss: 0.000103, Time: 0.301332
2023-06-01 11:32:51,059:INFO: Epoch: 14/30, Step: 11/16, Lr: 0.001151870, Loss: 0.000021, Step Loss: 0.000021, Time: 0.092975
2023-06-01 11:32:51,154:INFO: Epoch: 14/30, Step: 12/16, Lr: 0.001151870, Loss: 0.000048, Step Loss: 0.000048, Time: 0.094515
2023-06-01 11:32:51,243:INFO: Epoch: 14/30, Step: 13/16, Lr: 0.001151870, Loss: 0.000250, Step Loss: 0.000250, Time: 0.088238
2023-06-01 11:32:51,336:INFO: Epoch: 14/30, Step: 14/16, Lr: 0.001151870, Loss: 0.000179, Step Loss: 0.000179, Time: 0.092529
2023-06-01 11:32:51,426:INFO: Epoch: 14/30, Step: 15/16, Lr: 0.001151870, Loss: 0.000464, Step Loss: 0.000464, Time: 0.089718
2023-06-01 11:32:51,515:INFO: Epoch: 14/30, Step: 16/16, Lr: 0.001151870, Loss: 0.000750, Step Loss: 0.000750, Time: 0.088686
2023-06-01 11:32:51,651:INFO: Epoch 14/30 Finished, Train Loss: 0.001817
2023-06-01 11:33:16,770:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.13
2023-06-01 11:33:19,693:INFO: Classfication Metrics:
2023-06-01 11:33:19,693:INFO: f1 score: 0.8452 - precision score: 0.8211 - recall score: 0.8707 - accuracy score: 0.874576
2023-06-01 11:33:19,693:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:33:21,246:INFO: Epoch: 15/30, Step: 1/16, Lr: 0.001069334, Loss: 0.002630, Step Loss: 0.002630, Time: 1.527635
2023-06-01 11:33:21,335:INFO: Epoch: 15/30, Step: 2/16, Lr: 0.001069334, Loss: 0.000051, Step Loss: 0.000051, Time: 0.088255
2023-06-01 11:33:21,431:INFO: Epoch: 15/30, Step: 3/16, Lr: 0.001069334, Loss: 0.001061, Step Loss: 0.001061, Time: 0.095856
2023-06-01 11:33:21,523:INFO: Epoch: 15/30, Step: 4/16, Lr: 0.001069334, Loss: 0.000321, Step Loss: 0.000321, Time: 0.091386
2023-06-01 11:33:21,617:INFO: Epoch: 15/30, Step: 5/16, Lr: 0.001069334, Loss: 0.000518, Step Loss: 0.000518, Time: 0.093219
2023-06-01 11:33:21,704:INFO: Epoch: 15/30, Step: 6/16, Lr: 0.001069334, Loss: 0.000108, Step Loss: 0.000108, Time: 0.087419
2023-06-01 11:33:21,789:INFO: Epoch: 15/30, Step: 7/16, Lr: 0.001069334, Loss: 0.000024, Step Loss: 0.000024, Time: 0.084380
2023-06-01 11:33:21,874:INFO: Epoch: 15/30, Step: 8/16, Lr: 0.001069334, Loss: 0.000107, Step Loss: 0.000107, Time: 0.084584
2023-06-01 11:33:22,226:INFO: Epoch: 15/30, Step: 9/16, Lr: 0.001069334, Loss: 0.000012, Step Loss: 0.000012, Time: 0.351964
2023-06-01 11:33:22,318:INFO: Epoch: 15/30, Step: 10/16, Lr: 0.001069334, Loss: 0.000252, Step Loss: 0.000252, Time: 0.091351
2023-06-01 11:33:22,407:INFO: Epoch: 15/30, Step: 11/16, Lr: 0.001069334, Loss: 0.000086, Step Loss: 0.000086, Time: 0.087871
2023-06-01 11:33:22,502:INFO: Epoch: 15/30, Step: 12/16, Lr: 0.001069334, Loss: 0.000091, Step Loss: 0.000091, Time: 0.095104
2023-06-01 11:33:22,591:INFO: Epoch: 15/30, Step: 13/16, Lr: 0.001069334, Loss: 0.000510, Step Loss: 0.000510, Time: 0.087990
2023-06-01 11:33:22,679:INFO: Epoch: 15/30, Step: 14/16, Lr: 0.001069334, Loss: 0.000263, Step Loss: 0.000263, Time: 0.087402
2023-06-01 11:33:22,772:INFO: Epoch: 15/30, Step: 15/16, Lr: 0.001069334, Loss: 0.000012, Step Loss: 0.000012, Time: 0.092422
2023-06-01 11:33:22,867:INFO: Epoch: 15/30, Step: 16/16, Lr: 0.001069334, Loss: 0.000011, Step Loss: 0.000011, Time: 0.094651
2023-06-01 11:33:23,003:INFO: Epoch 15/30 Finished, Train Loss: 0.000379
2023-06-01 11:33:47,748:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.14
2023-06-01 11:33:50,632:INFO: Classfication Metrics:
2023-06-01 11:33:50,632:INFO: f1 score: 0.8496 - precision score: 0.8727 - recall score: 0.8276 - accuracy score: 0.884746
2023-06-01 11:33:50,632:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:33:52,364:INFO: Epoch: 16/30, Step: 1/16, Lr: 0.000981763, Loss: 0.000145, Step Loss: 0.000145, Time: 1.717729
2023-06-01 11:33:52,469:INFO: Epoch: 16/30, Step: 2/16, Lr: 0.000981763, Loss: 0.000095, Step Loss: 0.000095, Time: 0.105124
2023-06-01 11:33:52,557:INFO: Epoch: 16/30, Step: 3/16, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.087068
2023-06-01 11:33:52,651:INFO: Epoch: 16/30, Step: 4/16, Lr: 0.000981763, Loss: 0.039214, Step Loss: 0.039214, Time: 0.093375
2023-06-01 11:33:52,743:INFO: Epoch: 16/30, Step: 5/16, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.091949
2023-06-01 11:33:52,838:INFO: Epoch: 16/30, Step: 6/16, Lr: 0.000981763, Loss: 0.002353, Step Loss: 0.002353, Time: 0.093837
2023-06-01 11:33:52,926:INFO: Epoch: 16/30, Step: 7/16, Lr: 0.000981763, Loss: 0.000011, Step Loss: 0.000011, Time: 0.088326
2023-06-01 11:33:53,025:INFO: Epoch: 16/30, Step: 8/16, Lr: 0.000981763, Loss: 0.000060, Step Loss: 0.000060, Time: 0.098674
2023-06-01 11:33:53,266:INFO: Epoch: 16/30, Step: 9/16, Lr: 0.000981763, Loss: 0.000198, Step Loss: 0.000198, Time: 0.239857
2023-06-01 11:33:53,356:INFO: Epoch: 16/30, Step: 10/16, Lr: 0.000981763, Loss: 0.000880, Step Loss: 0.000880, Time: 0.089450
2023-06-01 11:33:53,451:INFO: Epoch: 16/30, Step: 11/16, Lr: 0.000981763, Loss: 0.000124, Step Loss: 0.000124, Time: 0.095018
2023-06-01 11:33:53,541:INFO: Epoch: 16/30, Step: 12/16, Lr: 0.000981763, Loss: 0.018461, Step Loss: 0.018461, Time: 0.089209
2023-06-01 11:33:53,631:INFO: Epoch: 16/30, Step: 13/16, Lr: 0.000981763, Loss: 0.000011, Step Loss: 0.000011, Time: 0.090178
2023-06-01 11:33:53,719:INFO: Epoch: 16/30, Step: 14/16, Lr: 0.000981763, Loss: 0.000132, Step Loss: 0.000132, Time: 0.087430
2023-06-01 11:33:53,815:INFO: Epoch: 16/30, Step: 15/16, Lr: 0.000981763, Loss: 0.005559, Step Loss: 0.005559, Time: 0.095653
2023-06-01 11:33:53,908:INFO: Epoch: 16/30, Step: 16/16, Lr: 0.000981763, Loss: 0.000012, Step Loss: 0.000012, Time: 0.092837
2023-06-01 11:33:54,036:INFO: Epoch 16/30 Finished, Train Loss: 0.004204
2023-06-01 11:34:12,350:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15
2023-06-01 11:34:15,255:INFO: Classfication Metrics:
2023-06-01 11:34:15,255:INFO: f1 score: 0.8390 - precision score: 0.8250 - recall score: 0.8534 - accuracy score: 0.871186
2023-06-01 11:34:15,255:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:34:16,887:INFO: Epoch: 17/30, Step: 1/16, Lr: 0.000890536, Loss: 0.001899, Step Loss: 0.001899, Time: 1.601840
2023-06-01 11:34:16,975:INFO: Epoch: 17/30, Step: 2/16, Lr: 0.000890536, Loss: 0.000283, Step Loss: 0.000283, Time: 0.087590
2023-06-01 11:34:17,065:INFO: Epoch: 17/30, Step: 3/16, Lr: 0.000890536, Loss: 0.000171, Step Loss: 0.000171, Time: 0.089512
2023-06-01 11:34:17,167:INFO: Epoch: 17/30, Step: 4/16, Lr: 0.000890536, Loss: 0.000630, Step Loss: 0.000630, Time: 0.101483
2023-06-01 11:34:17,257:INFO: Epoch: 17/30, Step: 5/16, Lr: 0.000890536, Loss: 0.000013, Step Loss: 0.000013, Time: 0.089533
2023-06-01 11:34:17,350:INFO: Epoch: 17/30, Step: 6/16, Lr: 0.000890536, Loss: 0.002552, Step Loss: 0.002552, Time: 0.092797
2023-06-01 11:34:17,446:INFO: Epoch: 17/30, Step: 7/16, Lr: 0.000890536, Loss: 0.000041, Step Loss: 0.000041, Time: 0.095678
2023-06-01 11:34:17,545:INFO: Epoch: 17/30, Step: 8/16, Lr: 0.000890536, Loss: 0.000126, Step Loss: 0.000126, Time: 0.098340
2023-06-01 11:34:17,724:INFO: Epoch: 17/30, Step: 9/16, Lr: 0.000890536, Loss: 0.000660, Step Loss: 0.000660, Time: 0.178785
2023-06-01 11:34:17,815:INFO: Epoch: 17/30, Step: 10/16, Lr: 0.000890536, Loss: 0.020343, Step Loss: 0.020343, Time: 0.091233
2023-06-01 11:34:17,906:INFO: Epoch: 17/30, Step: 11/16, Lr: 0.000890536, Loss: 0.000004, Step Loss: 0.000004, Time: 0.089720
2023-06-01 11:34:18,004:INFO: Epoch: 17/30, Step: 12/16, Lr: 0.000890536, Loss: 0.001425, Step Loss: 0.001425, Time: 0.097428
2023-06-01 11:34:18,093:INFO: Epoch: 17/30, Step: 13/16, Lr: 0.000890536, Loss: 0.002724, Step Loss: 0.002724, Time: 0.089182
2023-06-01 11:34:18,185:INFO: Epoch: 17/30, Step: 14/16, Lr: 0.000890536, Loss: 0.000036, Step Loss: 0.000036, Time: 0.091328
2023-06-01 11:34:18,284:INFO: Epoch: 17/30, Step: 15/16, Lr: 0.000890536, Loss: 0.000380, Step Loss: 0.000380, Time: 0.098032
2023-06-01 11:34:18,374:INFO: Epoch: 17/30, Step: 16/16, Lr: 0.000890536, Loss: 0.000045, Step Loss: 0.000045, Time: 0.090145
2023-06-01 11:34:18,551:INFO: Epoch 17/30 Finished, Train Loss: 0.001958
2023-06-01 11:34:40,605:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.16
2023-06-01 11:34:43,596:INFO: Classfication Metrics:
2023-06-01 11:34:43,597:INFO: f1 score: 0.8475 - precision score: 0.8333 - recall score: 0.8621 - accuracy score: 0.877966
2023-06-01 11:34:43,597:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:34:45,335:INFO: Epoch: 18/30, Step: 1/16, Lr: 0.000797093, Loss: 0.000001, Step Loss: 0.000001, Time: 1.707745
2023-06-01 11:34:45,602:INFO: Epoch: 18/30, Step: 2/16, Lr: 0.000797093, Loss: 0.000112, Step Loss: 0.000112, Time: 0.266925
2023-06-01 11:34:45,691:INFO: Epoch: 18/30, Step: 3/16, Lr: 0.000797093, Loss: 0.000045, Step Loss: 0.000045, Time: 0.088321
2023-06-01 11:34:45,779:INFO: Epoch: 18/30, Step: 4/16, Lr: 0.000797093, Loss: 0.000091, Step Loss: 0.000091, Time: 0.087566
2023-06-01 11:34:45,866:INFO: Epoch: 18/30, Step: 5/16, Lr: 0.000797093, Loss: 0.002332, Step Loss: 0.002332, Time: 0.086968
2023-06-01 11:34:45,952:INFO: Epoch: 18/30, Step: 6/16, Lr: 0.000797093, Loss: 0.002372, Step Loss: 0.002372, Time: 0.085875
2023-06-01 11:34:46,039:INFO: Epoch: 18/30, Step: 7/16, Lr: 0.000797093, Loss: 0.000070, Step Loss: 0.000070, Time: 0.086263
2023-06-01 11:34:46,126:INFO: Epoch: 18/30, Step: 8/16, Lr: 0.000797093, Loss: 0.000031, Step Loss: 0.000031, Time: 0.087224
2023-06-01 11:34:46,217:INFO: Epoch: 18/30, Step: 9/16, Lr: 0.000797093, Loss: 0.000017, Step Loss: 0.000017, Time: 0.090722
2023-06-01 11:34:46,379:INFO: Epoch: 18/30, Step: 10/16, Lr: 0.000797093, Loss: 0.000004, Step Loss: 0.000004, Time: 0.161947
2023-06-01 11:34:46,496:INFO: Epoch: 18/30, Step: 11/16, Lr: 0.000797093, Loss: 0.000009, Step Loss: 0.000009, Time: 0.116397
2023-06-01 11:34:46,585:INFO: Epoch: 18/30, Step: 12/16, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.088655
2023-06-01 11:34:46,680:INFO: Epoch: 18/30, Step: 13/16, Lr: 0.000797093, Loss: 0.000019, Step Loss: 0.000019, Time: 0.094359
2023-06-01 11:34:46,763:INFO: Epoch: 18/30, Step: 14/16, Lr: 0.000797093, Loss: 0.000004, Step Loss: 0.000004, Time: 0.082835
2023-06-01 11:34:46,853:INFO: Epoch: 18/30, Step: 15/16, Lr: 0.000797093, Loss: 0.002026, Step Loss: 0.002026, Time: 0.089350
2023-06-01 11:34:46,947:INFO: Epoch: 18/30, Step: 16/16, Lr: 0.000797093, Loss: 0.000197, Step Loss: 0.000197, Time: 0.093632
2023-06-01 11:34:47,094:INFO: Epoch 18/30 Finished, Train Loss: 0.000458
2023-06-01 11:34:55,132:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.17
2023-06-01 11:34:58,133:INFO: Classfication Metrics:
2023-06-01 11:34:58,134:INFO: f1 score: 0.8619 - precision score: 0.8374 - recall score: 0.8879 - accuracy score: 0.888136
2023-06-01 11:34:58,134:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:34:59,832:INFO: Epoch: 19/30, Step: 1/16, Lr: 0.000702907, Loss: 0.000008, Step Loss: 0.000008, Time: 1.667661
2023-06-01 11:34:59,926:INFO: Epoch: 19/30, Step: 2/16, Lr: 0.000702907, Loss: 0.000066, Step Loss: 0.000066, Time: 0.093814
2023-06-01 11:35:00,029:INFO: Epoch: 19/30, Step: 3/16, Lr: 0.000702907, Loss: 0.000039, Step Loss: 0.000039, Time: 0.102666
2023-06-01 11:35:00,123:INFO: Epoch: 19/30, Step: 4/16, Lr: 0.000702907, Loss: 0.000004, Step Loss: 0.000004, Time: 0.093835
2023-06-01 11:35:00,213:INFO: Epoch: 19/30, Step: 5/16, Lr: 0.000702907, Loss: 0.000002, Step Loss: 0.000002, Time: 0.089667
2023-06-01 11:35:00,304:INFO: Epoch: 19/30, Step: 6/16, Lr: 0.000702907, Loss: 0.000017, Step Loss: 0.000017, Time: 0.089790
2023-06-01 11:35:00,395:INFO: Epoch: 19/30, Step: 7/16, Lr: 0.000702907, Loss: 0.000095, Step Loss: 0.000095, Time: 0.090545
2023-06-01 11:35:00,489:INFO: Epoch: 19/30, Step: 8/16, Lr: 0.000702907, Loss: 0.000095, Step Loss: 0.000095, Time: 0.093930
2023-06-01 11:35:00,915:INFO: Epoch: 19/30, Step: 9/16, Lr: 0.000702907, Loss: 0.000062, Step Loss: 0.000062, Time: 0.425266
2023-06-01 11:35:01,005:INFO: Epoch: 19/30, Step: 10/16, Lr: 0.000702907, Loss: 0.000431, Step Loss: 0.000431, Time: 0.090261
2023-06-01 11:35:01,093:INFO: Epoch: 19/30, Step: 11/16, Lr: 0.000702907, Loss: 0.000024, Step Loss: 0.000024, Time: 0.087480
2023-06-01 11:35:01,186:INFO: Epoch: 19/30, Step: 12/16, Lr: 0.000702907, Loss: 0.000232, Step Loss: 0.000232, Time: 0.092479
2023-06-01 11:35:01,270:INFO: Epoch: 19/30, Step: 13/16, Lr: 0.000702907, Loss: 0.000005, Step Loss: 0.000005, Time: 0.083765
2023-06-01 11:35:01,354:INFO: Epoch: 19/30, Step: 14/16, Lr: 0.000702907, Loss: 0.000934, Step Loss: 0.000934, Time: 0.083187
2023-06-01 11:35:01,442:INFO: Epoch: 19/30, Step: 15/16, Lr: 0.000702907, Loss: 0.000004, Step Loss: 0.000004, Time: 0.088542
2023-06-01 11:35:01,531:INFO: Epoch: 19/30, Step: 16/16, Lr: 0.000702907, Loss: 0.000157, Step Loss: 0.000157, Time: 0.088457
2023-06-01 11:35:01,703:INFO: Epoch 19/30 Finished, Train Loss: 0.000136
2023-06-01 11:35:12,136:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.18
2023-06-01 11:35:15,054:INFO: Classfication Metrics:
2023-06-01 11:35:15,054:INFO: f1 score: 0.8560 - precision score: 0.8189 - recall score: 0.8966 - accuracy score: 0.881356
2023-06-01 11:35:15,055:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:35:16,768:INFO: Epoch: 20/30, Step: 1/16, Lr: 0.000609464, Loss: 0.000056, Step Loss: 0.000056, Time: 1.703924
2023-06-01 11:35:16,857:INFO: Epoch: 20/30, Step: 2/16, Lr: 0.000609464, Loss: 0.000146, Step Loss: 0.000146, Time: 0.089071
2023-06-01 11:35:16,952:INFO: Epoch: 20/30, Step: 3/16, Lr: 0.000609464, Loss: 0.000130, Step Loss: 0.000130, Time: 0.094460
2023-06-01 11:35:17,045:INFO: Epoch: 20/30, Step: 4/16, Lr: 0.000609464, Loss: 0.000090, Step Loss: 0.000090, Time: 0.092125
2023-06-01 11:35:17,135:INFO: Epoch: 20/30, Step: 5/16, Lr: 0.000609464, Loss: 0.000080, Step Loss: 0.000080, Time: 0.089564
2023-06-01 11:35:17,227:INFO: Epoch: 20/30, Step: 6/16, Lr: 0.000609464, Loss: 0.000003, Step Loss: 0.000003, Time: 0.091834
2023-06-01 11:35:17,318:INFO: Epoch: 20/30, Step: 7/16, Lr: 0.000609464, Loss: 0.000052, Step Loss: 0.000052, Time: 0.090688
2023-06-01 11:35:17,404:INFO: Epoch: 20/30, Step: 8/16, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.085663
2023-06-01 11:35:17,935:INFO: Epoch: 20/30, Step: 9/16, Lr: 0.000609464, Loss: 0.000020, Step Loss: 0.000020, Time: 0.530502
2023-06-01 11:35:18,020:INFO: Epoch: 20/30, Step: 10/16, Lr: 0.000609464, Loss: 0.000037, Step Loss: 0.000037, Time: 0.084676
2023-06-01 11:35:18,105:INFO: Epoch: 20/30, Step: 11/16, Lr: 0.000609464, Loss: 0.000002, Step Loss: 0.000002, Time: 0.084378
2023-06-01 11:35:18,188:INFO: Epoch: 20/30, Step: 12/16, Lr: 0.000609464, Loss: 0.000020, Step Loss: 0.000020, Time: 0.082686
2023-06-01 11:35:18,274:INFO: Epoch: 20/30, Step: 13/16, Lr: 0.000609464, Loss: 0.000006, Step Loss: 0.000006, Time: 0.085592
2023-06-01 11:35:18,359:INFO: Epoch: 20/30, Step: 14/16, Lr: 0.000609464, Loss: 0.000017, Step Loss: 0.000017, Time: 0.085205
2023-06-01 11:35:18,441:INFO: Epoch: 20/30, Step: 15/16, Lr: 0.000609464, Loss: 0.000345, Step Loss: 0.000345, Time: 0.081567
2023-06-01 11:35:18,524:INFO: Epoch: 20/30, Step: 16/16, Lr: 0.000609464, Loss: 0.000166, Step Loss: 0.000166, Time: 0.082904
2023-06-01 11:35:18,663:INFO: Epoch 20/30 Finished, Train Loss: 0.000073
2023-06-01 11:35:34,287:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19
2023-06-01 11:35:37,248:INFO: Classfication Metrics:
2023-06-01 11:35:37,248:INFO: f1 score: 0.8595 - precision score: 0.8254 - recall score: 0.8966 - accuracy score: 0.884746
2023-06-01 11:35:37,248:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8621
2023-06-01 11:35:38,763:INFO: Epoch: 21/30, Step: 1/16, Lr: 0.000518237, Loss: 0.000031, Step Loss: 0.000031, Time: 1.504083
2023-06-01 11:35:38,864:INFO: Epoch: 21/30, Step: 2/16, Lr: 0.000518237, Loss: 0.000009, Step Loss: 0.000009, Time: 0.100129
2023-06-01 11:35:38,954:INFO: Epoch: 21/30, Step: 3/16, Lr: 0.000518237, Loss: 0.000017, Step Loss: 0.000017, Time: 0.090092
2023-06-01 11:35:39,151:INFO: Epoch: 21/30, Step: 4/16, Lr: 0.000518237, Loss: 0.002437, Step Loss: 0.002437, Time: 0.196102
2023-06-01 11:35:39,249:INFO: Epoch: 21/30, Step: 5/16, Lr: 0.000518237, Loss: 0.000079, Step Loss: 0.000079, Time: 0.097559
2023-06-01 11:35:39,341:INFO: Epoch: 21/30, Step: 6/16, Lr: 0.000518237, Loss: 0.000048, Step Loss: 0.000048, Time: 0.092028
2023-06-01 11:35:39,434:INFO: Epoch: 21/30, Step: 7/16, Lr: 0.000518237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.092221
2023-06-01 11:35:39,530:INFO: Epoch: 21/30, Step: 8/16, Lr: 0.000518237, Loss: 0.000041, Step Loss: 0.000041, Time: 0.095927
2023-06-01 11:35:39,638:INFO: Epoch: 21/30, Step: 9/16, Lr: 0.000518237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.106970
2023-06-01 11:35:39,740:INFO: Epoch: 21/30, Step: 10/16, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.101532
2023-06-01 11:35:39,842:INFO: Epoch: 21/30, Step: 11/16, Lr: 0.000518237, Loss: 0.000035, Step Loss: 0.000035, Time: 0.101451
2023-06-01 11:35:40,011:INFO: Epoch: 21/30, Step: 12/16, Lr: 0.000518237, Loss: 0.000013, Step Loss: 0.000013, Time: 0.168041
2023-06-01 11:35:40,103:INFO: Epoch: 21/30, Step: 13/16, Lr: 0.000518237, Loss: 0.000089, Step Loss: 0.000089, Time: 0.092220
2023-06-01 11:35:40,205:INFO: Epoch: 21/30, Step: 14/16, Lr: 0.000518237, Loss: 0.000031, Step Loss: 0.000031, Time: 0.100960
2023-06-01 11:35:40,301:INFO: Epoch: 21/30, Step: 15/16, Lr: 0.000518237, Loss: 0.000006, Step Loss: 0.000006, Time: 0.096164
2023-06-01 11:35:40,399:INFO: Epoch: 21/30, Step: 16/16, Lr: 0.000518237, Loss: 0.000026, Step Loss: 0.000026, Time: 0.096954
2023-06-01 11:35:40,540:INFO: Epoch 21/30 Finished, Train Loss: 0.000179
2023-06-01 11:35:53,588:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20
2023-06-01 11:35:56,665:INFO: Classfication Metrics:
2023-06-01 11:35:56,665:INFO: f1 score: 0.8655 - precision score: 0.8443 - recall score: 0.8879 - accuracy score: 0.891525
2023-06-01 11:35:56,665:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:35:58,324:INFO: Epoch: 22/30, Step: 1/16, Lr: 0.000430666, Loss: 0.000007, Step Loss: 0.000007, Time: 1.649085
2023-06-01 11:35:58,414:INFO: Epoch: 22/30, Step: 2/16, Lr: 0.000430666, Loss: 0.000033, Step Loss: 0.000033, Time: 0.089202
2023-06-01 11:35:58,503:INFO: Epoch: 22/30, Step: 3/16, Lr: 0.000430666, Loss: 0.000060, Step Loss: 0.000060, Time: 0.089188
2023-06-01 11:35:58,594:INFO: Epoch: 22/30, Step: 4/16, Lr: 0.000430666, Loss: 0.000355, Step Loss: 0.000355, Time: 0.090303
2023-06-01 11:35:58,686:INFO: Epoch: 22/30, Step: 5/16, Lr: 0.000430666, Loss: 0.000246, Step Loss: 0.000246, Time: 0.091297
2023-06-01 11:35:58,775:INFO: Epoch: 22/30, Step: 6/16, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.089413
2023-06-01 11:35:58,864:INFO: Epoch: 22/30, Step: 7/16, Lr: 0.000430666, Loss: 0.000009, Step Loss: 0.000009, Time: 0.088628
2023-06-01 11:35:58,964:INFO: Epoch: 22/30, Step: 8/16, Lr: 0.000430666, Loss: 0.000177, Step Loss: 0.000177, Time: 0.098637
2023-06-01 11:35:59,518:INFO: Epoch: 22/30, Step: 9/16, Lr: 0.000430666, Loss: 0.000006, Step Loss: 0.000006, Time: 0.554362
2023-06-01 11:35:59,609:INFO: Epoch: 22/30, Step: 10/16, Lr: 0.000430666, Loss: 0.000011, Step Loss: 0.000011, Time: 0.090377
2023-06-01 11:35:59,701:INFO: Epoch: 22/30, Step: 11/16, Lr: 0.000430666, Loss: 0.003912, Step Loss: 0.003912, Time: 0.091754
2023-06-01 11:35:59,794:INFO: Epoch: 22/30, Step: 12/16, Lr: 0.000430666, Loss: 0.000002, Step Loss: 0.000002, Time: 0.091873
2023-06-01 11:35:59,890:INFO: Epoch: 22/30, Step: 13/16, Lr: 0.000430666, Loss: 0.000429, Step Loss: 0.000429, Time: 0.095576
2023-06-01 11:35:59,980:INFO: Epoch: 22/30, Step: 14/16, Lr: 0.000430666, Loss: 0.000472, Step Loss: 0.000472, Time: 0.090037
2023-06-01 11:36:00,071:INFO: Epoch: 22/30, Step: 15/16, Lr: 0.000430666, Loss: 0.000032, Step Loss: 0.000032, Time: 0.090697
2023-06-01 11:36:00,167:INFO: Epoch: 22/30, Step: 16/16, Lr: 0.000430666, Loss: 0.000111, Step Loss: 0.000111, Time: 0.094962
2023-06-01 11:36:00,309:INFO: Epoch 22/30 Finished, Train Loss: 0.000366
2023-06-01 11:36:12,351:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.21
2023-06-01 11:36:15,301:INFO: Classfication Metrics:
2023-06-01 11:36:15,301:INFO: f1 score: 0.8547 - precision score: 0.8475 - recall score: 0.8621 - accuracy score: 0.884746
2023-06-01 11:36:15,301:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:36:17,094:INFO: Epoch: 23/30, Step: 1/16, Lr: 0.000348130, Loss: 0.000006, Step Loss: 0.000006, Time: 1.783119
2023-06-01 11:36:17,186:INFO: Epoch: 23/30, Step: 2/16, Lr: 0.000348130, Loss: 0.000021, Step Loss: 0.000021, Time: 0.091744
2023-06-01 11:36:17,278:INFO: Epoch: 23/30, Step: 3/16, Lr: 0.000348130, Loss: 0.000007, Step Loss: 0.000007, Time: 0.091171
2023-06-01 11:36:17,370:INFO: Epoch: 23/30, Step: 4/16, Lr: 0.000348130, Loss: 0.000442, Step Loss: 0.000442, Time: 0.091708
2023-06-01 11:36:17,467:INFO: Epoch: 23/30, Step: 5/16, Lr: 0.000348130, Loss: 0.000114, Step Loss: 0.000114, Time: 0.096466
2023-06-01 11:36:17,565:INFO: Epoch: 23/30, Step: 6/16, Lr: 0.000348130, Loss: 0.000002, Step Loss: 0.000002, Time: 0.097857
2023-06-01 11:36:17,657:INFO: Epoch: 23/30, Step: 7/16, Lr: 0.000348130, Loss: 0.000009, Step Loss: 0.000009, Time: 0.091584
2023-06-01 11:36:17,758:INFO: Epoch: 23/30, Step: 8/16, Lr: 0.000348130, Loss: 0.000037, Step Loss: 0.000037, Time: 0.100656
2023-06-01 11:36:17,979:INFO: Epoch: 23/30, Step: 9/16, Lr: 0.000348130, Loss: 0.000014, Step Loss: 0.000014, Time: 0.220107
2023-06-01 11:36:18,070:INFO: Epoch: 23/30, Step: 10/16, Lr: 0.000348130, Loss: 0.000149, Step Loss: 0.000149, Time: 0.090894
2023-06-01 11:36:18,163:INFO: Epoch: 23/30, Step: 11/16, Lr: 0.000348130, Loss: 0.000820, Step Loss: 0.000820, Time: 0.091710
2023-06-01 11:36:18,255:INFO: Epoch: 23/30, Step: 12/16, Lr: 0.000348130, Loss: 0.000034, Step Loss: 0.000034, Time: 0.091789
2023-06-01 11:36:18,347:INFO: Epoch: 23/30, Step: 13/16, Lr: 0.000348130, Loss: 0.000001, Step Loss: 0.000001, Time: 0.092047
2023-06-01 11:36:18,439:INFO: Epoch: 23/30, Step: 14/16, Lr: 0.000348130, Loss: 0.000130, Step Loss: 0.000130, Time: 0.091139
2023-06-01 11:36:18,533:INFO: Epoch: 23/30, Step: 15/16, Lr: 0.000348130, Loss: 0.000047, Step Loss: 0.000047, Time: 0.093451
2023-06-01 11:36:18,628:INFO: Epoch: 23/30, Step: 16/16, Lr: 0.000348130, Loss: 0.000006, Step Loss: 0.000006, Time: 0.094420
2023-06-01 11:36:18,764:INFO: Epoch 23/30 Finished, Train Loss: 0.000115
2023-06-01 11:36:30,385:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.22
2023-06-01 11:36:33,274:INFO: Classfication Metrics:
2023-06-01 11:36:33,274:INFO: f1 score: 0.8571 - precision score: 0.8609 - recall score: 0.8534 - accuracy score: 0.888136
2023-06-01 11:36:33,274:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:36:34,914:INFO: Epoch: 24/30, Step: 1/16, Lr: 0.000271932, Loss: 0.000015, Step Loss: 0.000015, Time: 1.629646
2023-06-01 11:36:35,003:INFO: Epoch: 24/30, Step: 2/16, Lr: 0.000271932, Loss: 0.000009, Step Loss: 0.000009, Time: 0.088272
2023-06-01 11:36:35,118:INFO: Epoch: 24/30, Step: 3/16, Lr: 0.000271932, Loss: 0.000171, Step Loss: 0.000171, Time: 0.115122
2023-06-01 11:36:35,205:INFO: Epoch: 24/30, Step: 4/16, Lr: 0.000271932, Loss: 0.001374, Step Loss: 0.001374, Time: 0.086470
2023-06-01 11:36:35,294:INFO: Epoch: 24/30, Step: 5/16, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.088862
2023-06-01 11:36:35,381:INFO: Epoch: 24/30, Step: 6/16, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.086471
2023-06-01 11:36:35,470:INFO: Epoch: 24/30, Step: 7/16, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.088714
2023-06-01 11:36:35,559:INFO: Epoch: 24/30, Step: 8/16, Lr: 0.000271932, Loss: 0.000149, Step Loss: 0.000149, Time: 0.088033
2023-06-01 11:36:35,688:INFO: Epoch: 24/30, Step: 9/16, Lr: 0.000271932, Loss: 0.000196, Step Loss: 0.000196, Time: 0.129137
2023-06-01 11:36:35,778:INFO: Epoch: 24/30, Step: 10/16, Lr: 0.000271932, Loss: 0.000058, Step Loss: 0.000058, Time: 0.089451
2023-06-01 11:36:36,119:INFO: Epoch: 24/30, Step: 11/16, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.340405
2023-06-01 11:36:36,210:INFO: Epoch: 24/30, Step: 12/16, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.090285
2023-06-01 11:36:36,302:INFO: Epoch: 24/30, Step: 13/16, Lr: 0.000271932, Loss: 0.000014, Step Loss: 0.000014, Time: 0.091729
2023-06-01 11:36:36,393:INFO: Epoch: 24/30, Step: 14/16, Lr: 0.000271932, Loss: 0.000021, Step Loss: 0.000021, Time: 0.090664
2023-06-01 11:36:36,479:INFO: Epoch: 24/30, Step: 15/16, Lr: 0.000271932, Loss: 0.000030, Step Loss: 0.000030, Time: 0.085225
2023-06-01 11:36:36,570:INFO: Epoch: 24/30, Step: 16/16, Lr: 0.000271932, Loss: 0.000276, Step Loss: 0.000276, Time: 0.090676
2023-06-01 11:36:36,712:INFO: Epoch 24/30 Finished, Train Loss: 0.000145
2023-06-01 11:36:46,737:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.23
2023-06-01 11:36:49,624:INFO: Classfication Metrics:
2023-06-01 11:36:49,625:INFO: f1 score: 0.8571 - precision score: 0.8609 - recall score: 0.8534 - accuracy score: 0.888136
2023-06-01 11:36:49,625:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:36:51,206:INFO: Epoch: 25/30, Step: 1/16, Lr: 0.000203274, Loss: 0.000200, Step Loss: 0.000200, Time: 1.571737
2023-06-01 11:36:51,453:INFO: Epoch: 25/30, Step: 2/16, Lr: 0.000203274, Loss: 0.000021, Step Loss: 0.000021, Time: 0.245645
2023-06-01 11:36:51,542:INFO: Epoch: 25/30, Step: 3/16, Lr: 0.000203274, Loss: 0.000047, Step Loss: 0.000047, Time: 0.088810
2023-06-01 11:36:51,631:INFO: Epoch: 25/30, Step: 4/16, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.088414
2023-06-01 11:36:51,724:INFO: Epoch: 25/30, Step: 5/16, Lr: 0.000203274, Loss: 0.000011, Step Loss: 0.000011, Time: 0.092477
2023-06-01 11:36:51,816:INFO: Epoch: 25/30, Step: 6/16, Lr: 0.000203274, Loss: 0.000104, Step Loss: 0.000104, Time: 0.091698
2023-06-01 11:36:51,906:INFO: Epoch: 25/30, Step: 7/16, Lr: 0.000203274, Loss: 0.000017, Step Loss: 0.000017, Time: 0.090245
2023-06-01 11:36:51,998:INFO: Epoch: 25/30, Step: 8/16, Lr: 0.000203274, Loss: 0.000007, Step Loss: 0.000007, Time: 0.091142
2023-06-01 11:36:52,566:INFO: Epoch: 25/30, Step: 9/16, Lr: 0.000203274, Loss: 0.000015, Step Loss: 0.000015, Time: 0.568038
2023-06-01 11:36:52,657:INFO: Epoch: 25/30, Step: 10/16, Lr: 0.000203274, Loss: 0.000016, Step Loss: 0.000016, Time: 0.090392
2023-06-01 11:36:52,747:INFO: Epoch: 25/30, Step: 11/16, Lr: 0.000203274, Loss: 0.000056, Step Loss: 0.000056, Time: 0.088937
2023-06-01 11:36:52,837:INFO: Epoch: 25/30, Step: 12/16, Lr: 0.000203274, Loss: 0.000022, Step Loss: 0.000022, Time: 0.089599
2023-06-01 11:36:52,932:INFO: Epoch: 25/30, Step: 13/16, Lr: 0.000203274, Loss: 0.000002, Step Loss: 0.000002, Time: 0.095308
2023-06-01 11:36:53,022:INFO: Epoch: 25/30, Step: 14/16, Lr: 0.000203274, Loss: 0.000132, Step Loss: 0.000132, Time: 0.089021
2023-06-01 11:36:53,117:INFO: Epoch: 25/30, Step: 15/16, Lr: 0.000203274, Loss: 0.000010, Step Loss: 0.000010, Time: 0.094191
2023-06-01 11:36:53,208:INFO: Epoch: 25/30, Step: 16/16, Lr: 0.000203274, Loss: 0.000021, Step Loss: 0.000021, Time: 0.091254
2023-06-01 11:36:53,345:INFO: Epoch 25/30 Finished, Train Loss: 0.000043
2023-06-01 11:37:04,162:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.24
2023-06-01 11:37:07,023:INFO: Classfication Metrics:
2023-06-01 11:37:07,023:INFO: f1 score: 0.8498 - precision score: 0.8462 - recall score: 0.8534 - accuracy score: 0.881356
2023-06-01 11:37:07,024:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:37:08,753:INFO: Epoch: 26/30, Step: 1/16, Lr: 0.000143237, Loss: 0.000011, Step Loss: 0.000011, Time: 1.719656
2023-06-01 11:37:08,843:INFO: Epoch: 26/30, Step: 2/16, Lr: 0.000143237, Loss: 0.000020, Step Loss: 0.000020, Time: 0.089807
2023-06-01 11:37:08,933:INFO: Epoch: 26/30, Step: 3/16, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.089484
2023-06-01 11:37:09,025:INFO: Epoch: 26/30, Step: 4/16, Lr: 0.000143237, Loss: 0.000159, Step Loss: 0.000159, Time: 0.091516
2023-06-01 11:37:09,126:INFO: Epoch: 26/30, Step: 5/16, Lr: 0.000143237, Loss: 0.000034, Step Loss: 0.000034, Time: 0.100841
2023-06-01 11:37:09,215:INFO: Epoch: 26/30, Step: 6/16, Lr: 0.000143237, Loss: 0.000004, Step Loss: 0.000004, Time: 0.088367
2023-06-01 11:37:09,308:INFO: Epoch: 26/30, Step: 7/16, Lr: 0.000143237, Loss: 0.000300, Step Loss: 0.000300, Time: 0.092574
2023-06-01 11:37:09,401:INFO: Epoch: 26/30, Step: 8/16, Lr: 0.000143237, Loss: 0.000010, Step Loss: 0.000010, Time: 0.092582
2023-06-01 11:37:09,509:INFO: Epoch: 26/30, Step: 9/16, Lr: 0.000143237, Loss: 0.000025, Step Loss: 0.000025, Time: 0.107584
2023-06-01 11:37:09,603:INFO: Epoch: 26/30, Step: 10/16, Lr: 0.000143237, Loss: 0.000012, Step Loss: 0.000012, Time: 0.093949
2023-06-01 11:37:09,703:INFO: Epoch: 26/30, Step: 11/16, Lr: 0.000143237, Loss: 0.000043, Step Loss: 0.000043, Time: 0.098808
2023-06-01 11:37:09,795:INFO: Epoch: 26/30, Step: 12/16, Lr: 0.000143237, Loss: 0.000023, Step Loss: 0.000023, Time: 0.091601
2023-06-01 11:37:09,895:INFO: Epoch: 26/30, Step: 13/16, Lr: 0.000143237, Loss: 0.000012, Step Loss: 0.000012, Time: 0.100324
2023-06-01 11:37:09,986:INFO: Epoch: 26/30, Step: 14/16, Lr: 0.000143237, Loss: 0.000016, Step Loss: 0.000016, Time: 0.089850
2023-06-01 11:37:10,077:INFO: Epoch: 26/30, Step: 15/16, Lr: 0.000143237, Loss: 0.000025, Step Loss: 0.000025, Time: 0.091112
2023-06-01 11:37:10,165:INFO: Epoch: 26/30, Step: 16/16, Lr: 0.000143237, Loss: 0.000005, Step Loss: 0.000005, Time: 0.088003
2023-06-01 11:37:10,301:INFO: Epoch 26/30 Finished, Train Loss: 0.000044
2023-06-01 11:37:20,810:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.25
2023-06-01 11:37:23,663:INFO: Classfication Metrics:
2023-06-01 11:37:23,663:INFO: f1 score: 0.8596 - precision score: 0.8487 - recall score: 0.8707 - accuracy score: 0.888136
2023-06-01 11:37:23,663:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:37:25,628:INFO: Epoch: 27/30, Step: 1/16, Lr: 0.000092770, Loss: 0.000148, Step Loss: 0.000148, Time: 1.951972
2023-06-01 11:37:25,716:INFO: Epoch: 27/30, Step: 2/16, Lr: 0.000092770, Loss: 0.000005, Step Loss: 0.000005, Time: 0.087769
2023-06-01 11:37:25,806:INFO: Epoch: 27/30, Step: 3/16, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.089703
2023-06-01 11:37:25,894:INFO: Epoch: 27/30, Step: 4/16, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.088491
2023-06-01 11:37:25,980:INFO: Epoch: 27/30, Step: 5/16, Lr: 0.000092770, Loss: 0.000010, Step Loss: 0.000010, Time: 0.085558
2023-06-01 11:37:26,070:INFO: Epoch: 27/30, Step: 6/16, Lr: 0.000092770, Loss: 0.000014, Step Loss: 0.000014, Time: 0.089572
2023-06-01 11:37:26,159:INFO: Epoch: 27/30, Step: 7/16, Lr: 0.000092770, Loss: 0.000008, Step Loss: 0.000008, Time: 0.088637
2023-06-01 11:37:26,248:INFO: Epoch: 27/30, Step: 8/16, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.087965
2023-06-01 11:37:26,674:INFO: Epoch: 27/30, Step: 9/16, Lr: 0.000092770, Loss: 0.001092, Step Loss: 0.001092, Time: 0.425921
2023-06-01 11:37:26,763:INFO: Epoch: 27/30, Step: 10/16, Lr: 0.000092770, Loss: 0.000057, Step Loss: 0.000057, Time: 0.088731
2023-06-01 11:37:26,853:INFO: Epoch: 27/30, Step: 11/16, Lr: 0.000092770, Loss: 0.000066, Step Loss: 0.000066, Time: 0.089917
2023-06-01 11:37:26,943:INFO: Epoch: 27/30, Step: 12/16, Lr: 0.000092770, Loss: 0.000009, Step Loss: 0.000009, Time: 0.088908
2023-06-01 11:37:27,030:INFO: Epoch: 27/30, Step: 13/16, Lr: 0.000092770, Loss: 0.000016, Step Loss: 0.000016, Time: 0.087315
2023-06-01 11:37:27,119:INFO: Epoch: 27/30, Step: 14/16, Lr: 0.000092770, Loss: 0.000005, Step Loss: 0.000005, Time: 0.087854
2023-06-01 11:37:27,208:INFO: Epoch: 27/30, Step: 15/16, Lr: 0.000092770, Loss: 0.000011, Step Loss: 0.000011, Time: 0.088900
2023-06-01 11:37:27,292:INFO: Epoch: 27/30, Step: 16/16, Lr: 0.000092770, Loss: 0.000009, Step Loss: 0.000009, Time: 0.084300
2023-06-01 11:37:27,435:INFO: Epoch 27/30 Finished, Train Loss: 0.000091
2023-06-01 11:37:38,108:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.26
2023-06-01 11:37:40,976:INFO: Classfication Metrics:
2023-06-01 11:37:40,976:INFO: f1 score: 0.8596 - precision score: 0.8487 - recall score: 0.8707 - accuracy score: 0.888136
2023-06-01 11:37:40,976:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:37:42,346:INFO: Epoch: 28/30, Step: 1/16, Lr: 0.000052668, Loss: 0.000040, Step Loss: 0.000040, Time: 1.344410
2023-06-01 11:37:42,739:INFO: Epoch: 28/30, Step: 2/16, Lr: 0.000052668, Loss: 0.000103, Step Loss: 0.000103, Time: 0.392802
2023-06-01 11:37:42,830:INFO: Epoch: 28/30, Step: 3/16, Lr: 0.000052668, Loss: 0.000017, Step Loss: 0.000017, Time: 0.089788
2023-06-01 11:37:42,919:INFO: Epoch: 28/30, Step: 4/16, Lr: 0.000052668, Loss: 0.000044, Step Loss: 0.000044, Time: 0.088500
2023-06-01 11:37:43,007:INFO: Epoch: 28/30, Step: 5/16, Lr: 0.000052668, Loss: 0.000048, Step Loss: 0.000048, Time: 0.088183
2023-06-01 11:37:43,095:INFO: Epoch: 28/30, Step: 6/16, Lr: 0.000052668, Loss: 0.000010, Step Loss: 0.000010, Time: 0.087584
2023-06-01 11:37:43,182:INFO: Epoch: 28/30, Step: 7/16, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.086304
2023-06-01 11:37:43,279:INFO: Epoch: 28/30, Step: 8/16, Lr: 0.000052668, Loss: 0.000008, Step Loss: 0.000008, Time: 0.096179
2023-06-01 11:37:43,364:INFO: Epoch: 28/30, Step: 9/16, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.084913
2023-06-01 11:37:43,659:INFO: Epoch: 28/30, Step: 10/16, Lr: 0.000052668, Loss: 0.000039, Step Loss: 0.000039, Time: 0.294331
2023-06-01 11:37:43,746:INFO: Epoch: 28/30, Step: 11/16, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.087225
2023-06-01 11:37:43,835:INFO: Epoch: 28/30, Step: 12/16, Lr: 0.000052668, Loss: 0.000040, Step Loss: 0.000040, Time: 0.088756
2023-06-01 11:37:43,926:INFO: Epoch: 28/30, Step: 13/16, Lr: 0.000052668, Loss: 0.000040, Step Loss: 0.000040, Time: 0.090003
2023-06-01 11:37:44,015:INFO: Epoch: 28/30, Step: 14/16, Lr: 0.000052668, Loss: 0.000012, Step Loss: 0.000012, Time: 0.088928
2023-06-01 11:37:44,106:INFO: Epoch: 28/30, Step: 15/16, Lr: 0.000052668, Loss: 0.000007, Step Loss: 0.000007, Time: 0.090179
2023-06-01 11:37:44,203:INFO: Epoch: 28/30, Step: 16/16, Lr: 0.000052668, Loss: 0.000004, Step Loss: 0.000004, Time: 0.096403
2023-06-01 11:37:44,347:INFO: Epoch 28/30 Finished, Train Loss: 0.000026
2023-06-01 11:37:50,695:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.27
2023-06-01 11:37:53,572:INFO: Classfication Metrics:
2023-06-01 11:37:53,572:INFO: f1 score: 0.8596 - precision score: 0.8487 - recall score: 0.8707 - accuracy score: 0.888136
2023-06-01 11:37:53,572:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:37:55,201:INFO: Epoch: 29/30, Step: 1/16, Lr: 0.000023563, Loss: 0.000004, Step Loss: 0.000004, Time: 1.611232
2023-06-01 11:37:55,297:INFO: Epoch: 29/30, Step: 2/16, Lr: 0.000023563, Loss: 0.000063, Step Loss: 0.000063, Time: 0.096256
2023-06-01 11:37:55,386:INFO: Epoch: 29/30, Step: 3/16, Lr: 0.000023563, Loss: 0.000010, Step Loss: 0.000010, Time: 0.088338
2023-06-01 11:37:55,478:INFO: Epoch: 29/30, Step: 4/16, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.091969
2023-06-01 11:37:55,566:INFO: Epoch: 29/30, Step: 5/16, Lr: 0.000023563, Loss: 0.000019, Step Loss: 0.000019, Time: 0.086985
2023-06-01 11:37:55,652:INFO: Epoch: 29/30, Step: 6/16, Lr: 0.000023563, Loss: 0.000024, Step Loss: 0.000024, Time: 0.086073
2023-06-01 11:37:55,739:INFO: Epoch: 29/30, Step: 7/16, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.086566
2023-06-01 11:37:55,834:INFO: Epoch: 29/30, Step: 8/16, Lr: 0.000023563, Loss: 0.002273, Step Loss: 0.002273, Time: 0.094774
2023-06-01 11:37:56,189:INFO: Epoch: 29/30, Step: 9/16, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.355055
2023-06-01 11:37:56,277:INFO: Epoch: 29/30, Step: 10/16, Lr: 0.000023563, Loss: 0.000005, Step Loss: 0.000005, Time: 0.087420
2023-06-01 11:37:56,366:INFO: Epoch: 29/30, Step: 11/16, Lr: 0.000023563, Loss: 0.000006, Step Loss: 0.000006, Time: 0.088093
2023-06-01 11:37:56,452:INFO: Epoch: 29/30, Step: 12/16, Lr: 0.000023563, Loss: 0.000003, Step Loss: 0.000003, Time: 0.086200
2023-06-01 11:37:56,541:INFO: Epoch: 29/30, Step: 13/16, Lr: 0.000023563, Loss: 0.000861, Step Loss: 0.000861, Time: 0.088600
2023-06-01 11:37:56,630:INFO: Epoch: 29/30, Step: 14/16, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.088223
2023-06-01 11:37:56,718:INFO: Epoch: 29/30, Step: 15/16, Lr: 0.000023563, Loss: 0.000123, Step Loss: 0.000123, Time: 0.087990
2023-06-01 11:37:56,813:INFO: Epoch: 29/30, Step: 16/16, Lr: 0.000023563, Loss: 0.000067, Step Loss: 0.000067, Time: 0.095201
2023-06-01 11:37:56,954:INFO: Epoch 29/30 Finished, Train Loss: 0.000216
2023-06-01 11:38:04,266:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.28
2023-06-01 11:38:07,194:INFO: Classfication Metrics:
2023-06-01 11:38:07,194:INFO: f1 score: 0.8596 - precision score: 0.8487 - recall score: 0.8707 - accuracy score: 0.888136
2023-06-01 11:38:07,194:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:38:08,512:INFO: Epoch: 30/30, Step: 1/16, Lr: 0.000005914, Loss: 0.000039, Step Loss: 0.000039, Time: 1.307018
2023-06-01 11:38:08,791:INFO: Epoch: 30/30, Step: 2/16, Lr: 0.000005914, Loss: 0.000065, Step Loss: 0.000065, Time: 0.278224
2023-06-01 11:38:08,886:INFO: Epoch: 30/30, Step: 3/16, Lr: 0.000005914, Loss: 0.000015, Step Loss: 0.000015, Time: 0.094695
2023-06-01 11:38:08,972:INFO: Epoch: 30/30, Step: 4/16, Lr: 0.000005914, Loss: 0.000026, Step Loss: 0.000026, Time: 0.085179
2023-06-01 11:38:09,067:INFO: Epoch: 30/30, Step: 5/16, Lr: 0.000005914, Loss: 0.000016, Step Loss: 0.000016, Time: 0.094401
2023-06-01 11:38:09,156:INFO: Epoch: 30/30, Step: 6/16, Lr: 0.000005914, Loss: 0.000106, Step Loss: 0.000106, Time: 0.088557
2023-06-01 11:38:09,245:INFO: Epoch: 30/30, Step: 7/16, Lr: 0.000005914, Loss: 0.000032, Step Loss: 0.000032, Time: 0.088554
2023-06-01 11:38:09,333:INFO: Epoch: 30/30, Step: 8/16, Lr: 0.000005914, Loss: 0.000003, Step Loss: 0.000003, Time: 0.087603
2023-06-01 11:38:09,432:INFO: Epoch: 30/30, Step: 9/16, Lr: 0.000005914, Loss: 0.000015, Step Loss: 0.000015, Time: 0.098439
2023-06-01 11:38:09,528:INFO: Epoch: 30/30, Step: 10/16, Lr: 0.000005914, Loss: 0.000041, Step Loss: 0.000041, Time: 0.095629
2023-06-01 11:38:09,766:INFO: Epoch: 30/30, Step: 11/16, Lr: 0.000005914, Loss: 0.000013, Step Loss: 0.000013, Time: 0.238223
2023-06-01 11:38:09,858:INFO: Epoch: 30/30, Step: 12/16, Lr: 0.000005914, Loss: 0.000003, Step Loss: 0.000003, Time: 0.091107
2023-06-01 11:38:09,951:INFO: Epoch: 30/30, Step: 13/16, Lr: 0.000005914, Loss: 0.000008, Step Loss: 0.000008, Time: 0.092735
2023-06-01 11:38:10,047:INFO: Epoch: 30/30, Step: 14/16, Lr: 0.000005914, Loss: 0.000030, Step Loss: 0.000030, Time: 0.095805
2023-06-01 11:38:10,137:INFO: Epoch: 30/30, Step: 15/16, Lr: 0.000005914, Loss: 0.000025, Step Loss: 0.000025, Time: 0.089528
2023-06-01 11:38:10,230:INFO: Epoch: 30/30, Step: 16/16, Lr: 0.000005914, Loss: 0.000019, Step Loss: 0.000019, Time: 0.092683
2023-06-01 11:38:10,375:INFO: Epoch 30/30 Finished, Train Loss: 0.000028
2023-06-01 11:38:23,554:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.29
2023-06-01 11:38:26,486:INFO: Classfication Metrics:
2023-06-01 11:38:26,486:INFO: f1 score: 0.8596 - precision score: 0.8487 - recall score: 0.8707 - accuracy score: 0.888136
2023-06-01 11:38:26,486:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20, the F1 is: 0.8655
2023-06-01 11:38:26,486:INFO: ***** Running testing *****
2023-06-01 11:38:26,486:INFO:   Num examples = 295
2023-06-01 11:38:26,486:INFO:   Batch size = 128
2023-06-01 11:38:30,043:INFO: Classfication Metrics:
2023-06-01 11:38:30,043:INFO: f1 score: 0.8655 - precision score: 0.8443 - recall score: 0.8879 - accuracy score: 0.891525
2023-06-01 11:40:53,182:INFO: Effective parameters:
2023-06-01 11:40:53,182:INFO:   <<< CUDA_VISIBLE_DEVICES: 6
2023-06-01 11:40:53,182:INFO:   <<< attention_model: bilinear
2023-06-01 11:40:53,182:INFO:   <<< batch_size: 32
2023-06-01 11:40:53,182:INFO:   <<< batch_size_val: 128
2023-06-01 11:40:53,182:INFO:   <<< dataset: weibo
2023-06-01 11:40:53,182:INFO:   <<< debug: False
2023-06-01 11:40:53,182:INFO:   <<< do_train: True
2023-06-01 11:40:53,182:INFO:   <<< exchange: False
2023-06-01 11:40:53,182:INFO:   <<< exchange_early: False
2023-06-01 11:40:53,182:INFO:   <<< expand_image: True
2023-06-01 11:40:53,182:INFO:   <<< expand_language: True
2023-06-01 11:40:53,182:INFO:   <<< freeze_image: True
2023-06-01 11:40:53,182:INFO:   <<< freeze_language: True
2023-06-01 11:40:53,182:INFO:   <<< image_model_type: clip
2023-06-01 11:40:53,182:INFO:   <<< image_size: 224
2023-06-01 11:40:53,182:INFO:   <<< init_model: 
2023-06-01 11:40:53,182:INFO:   <<< l1_lamda: 0.0002
2023-06-01 11:40:53,182:INFO:   <<< language_model_type: bert
2023-06-01 11:40:53,183:INFO:   <<< local_rank: 0
2023-06-01 11:40:53,183:INFO:   <<< loss_weight: 1,1
2023-06-01 11:40:53,183:INFO:   <<< lr: 0.00015
2023-06-01 11:40:53,183:INFO:   <<< max_text_len: 50
2023-06-01 11:40:53,183:INFO:   <<< more_layer: True
2023-06-01 11:40:53,183:INFO:   <<< n_epochs: 30
2023-06-01 11:40:53,183:INFO:   <<< num_workers: 8
2023-06-01 11:40:53,183:INFO:   <<< output_dir: experiments/weibo/train_weibo_clip_bert_bilinear_more
2023-06-01 11:40:53,183:INFO:   <<< pin_memory: False
2023-06-01 11:40:53,183:INFO:   <<< pretrained_image: True
2023-06-01 11:40:53,183:INFO:   <<< pretrained_language: True
2023-06-01 11:40:53,183:INFO:   <<< rank: 0
2023-06-01 11:40:53,183:INFO:   <<< seed: 42
2023-06-01 11:40:53,183:INFO:   <<< weight_decay: 2e-05
2023-06-01 11:40:53,183:INFO:   <<< world_size: 1
2023-06-01 11:40:53,183:INFO: device: cuda:0 n_gpu: 1
2023-06-01 11:41:05,596:INFO: ***** Running training *****
2023-06-01 11:41:05,597:INFO:   Num examples = 1026
2023-06-01 11:41:05,597:INFO:   Batch size = 32
2023-06-01 11:41:05,597:INFO: ***** Running validation  *****
2023-06-01 11:41:05,597:INFO:   Num examples = 146
2023-06-01 11:41:05,597:INFO:   Batch size = 128
2023-06-01 11:41:06,581:INFO: Epoch: 1/30, Step: 1/32, Lr: 0.000150000, Loss: 1.059445, Step Loss: 1.059445, Time: 0.977627
2023-06-01 11:41:06,657:INFO: Epoch: 1/30, Step: 2/32, Lr: 0.000150000, Loss: 6.619665, Step Loss: 6.619665, Time: 0.075944
2023-06-01 11:41:06,734:INFO: Epoch: 1/30, Step: 3/32, Lr: 0.000150000, Loss: 2.672862, Step Loss: 2.672862, Time: 0.076048
2023-06-01 11:41:06,806:INFO: Epoch: 1/30, Step: 4/32, Lr: 0.000150000, Loss: 1.886422, Step Loss: 1.886422, Time: 0.072114
2023-06-01 11:41:06,878:INFO: Epoch: 1/30, Step: 5/32, Lr: 0.000150000, Loss: 3.275665, Step Loss: 3.275665, Time: 0.071047
2023-06-01 11:41:06,947:INFO: Epoch: 1/30, Step: 6/32, Lr: 0.000150000, Loss: 4.387888, Step Loss: 4.387888, Time: 0.069211
2023-06-01 11:41:07,029:INFO: Epoch: 1/30, Step: 7/32, Lr: 0.000150000, Loss: 2.832682, Step Loss: 2.832682, Time: 0.081316
2023-06-01 11:41:07,106:INFO: Epoch: 1/30, Step: 8/32, Lr: 0.000150000, Loss: 1.343015, Step Loss: 1.343015, Time: 0.076889
2023-06-01 11:41:07,179:INFO: Epoch: 1/30, Step: 9/32, Lr: 0.000150000, Loss: 0.982433, Step Loss: 0.982433, Time: 0.072420
2023-06-01 11:41:07,258:INFO: Epoch: 1/30, Step: 10/32, Lr: 0.000150000, Loss: 3.222727, Step Loss: 3.222727, Time: 0.079243
2023-06-01 11:41:07,330:INFO: Epoch: 1/30, Step: 11/32, Lr: 0.000150000, Loss: 1.418578, Step Loss: 1.418578, Time: 0.071339
2023-06-01 11:41:07,402:INFO: Epoch: 1/30, Step: 12/32, Lr: 0.000150000, Loss: 2.015133, Step Loss: 2.015133, Time: 0.071499
2023-06-01 11:41:07,474:INFO: Epoch: 1/30, Step: 13/32, Lr: 0.000150000, Loss: 0.722285, Step Loss: 0.722285, Time: 0.072096
2023-06-01 11:41:07,538:INFO: Epoch: 1/30, Step: 14/32, Lr: 0.000150000, Loss: 1.748126, Step Loss: 1.748126, Time: 0.063317
2023-06-01 11:41:07,606:INFO: Epoch: 1/30, Step: 15/32, Lr: 0.000150000, Loss: 1.679676, Step Loss: 1.679676, Time: 0.068307
2023-06-01 11:41:07,677:INFO: Epoch: 1/30, Step: 16/32, Lr: 0.000150000, Loss: 0.831916, Step Loss: 0.831916, Time: 0.070747
2023-06-01 11:41:07,749:INFO: Epoch: 1/30, Step: 17/32, Lr: 0.000150000, Loss: 1.068501, Step Loss: 1.068501, Time: 0.071793
2023-06-01 11:41:07,823:INFO: Epoch: 1/30, Step: 18/32, Lr: 0.000150000, Loss: 0.257865, Step Loss: 0.257865, Time: 0.072989
2023-06-01 11:41:07,895:INFO: Epoch: 1/30, Step: 19/32, Lr: 0.000150000, Loss: 0.345504, Step Loss: 0.345504, Time: 0.071838
2023-06-01 11:41:07,969:INFO: Epoch: 1/30, Step: 20/32, Lr: 0.000150000, Loss: 0.971597, Step Loss: 0.971597, Time: 0.073788
2023-06-01 11:41:08,047:INFO: Epoch: 1/30, Step: 21/32, Lr: 0.000150000, Loss: 1.397751, Step Loss: 1.397751, Time: 0.077588
2023-06-01 11:41:08,127:INFO: Epoch: 1/30, Step: 22/32, Lr: 0.000150000, Loss: 0.512851, Step Loss: 0.512851, Time: 0.074105
2023-06-01 11:41:08,198:INFO: Epoch: 1/30, Step: 23/32, Lr: 0.000150000, Loss: 0.598000, Step Loss: 0.598000, Time: 0.070986
2023-06-01 11:41:08,270:INFO: Epoch: 1/30, Step: 24/32, Lr: 0.000150000, Loss: 0.740434, Step Loss: 0.740434, Time: 0.071769
2023-06-01 11:41:08,342:INFO: Epoch: 1/30, Step: 25/32, Lr: 0.000150000, Loss: 0.772326, Step Loss: 0.772326, Time: 0.071948
2023-06-01 11:41:08,426:INFO: Epoch: 1/30, Step: 26/32, Lr: 0.000150000, Loss: 0.653774, Step Loss: 0.653774, Time: 0.083954
2023-06-01 11:41:08,498:INFO: Epoch: 1/30, Step: 27/32, Lr: 0.000150000, Loss: 0.360971, Step Loss: 0.360971, Time: 0.071583
2023-06-01 11:41:08,577:INFO: Epoch: 1/30, Step: 28/32, Lr: 0.000150000, Loss: 0.779545, Step Loss: 0.779545, Time: 0.078019
2023-06-01 11:41:08,645:INFO: Epoch: 1/30, Step: 29/32, Lr: 0.000150000, Loss: 1.198076, Step Loss: 1.198076, Time: 0.068372
2023-06-01 11:41:08,713:INFO: Epoch: 1/30, Step: 30/32, Lr: 0.000150000, Loss: 0.253403, Step Loss: 0.253403, Time: 0.067805
2023-06-01 11:41:08,785:INFO: Epoch: 1/30, Step: 31/32, Lr: 0.000150000, Loss: 0.539536, Step Loss: 0.539536, Time: 0.071316
2023-06-01 11:41:08,861:INFO: Epoch: 1/30, Step: 32/32, Lr: 0.000150000, Loss: 0.818077, Step Loss: 0.818077, Time: 0.075720
2023-06-01 11:41:08,986:INFO: Epoch 1/30 Finished, Train Loss: 1.498960
2023-06-01 11:41:15,179:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0
2023-06-01 11:41:18,100:INFO: Classfication Metrics:
2023-06-01 11:41:18,100:INFO: f1 score: 0.7635 - precision score: 0.6278 - recall score: 0.9741 - accuracy score: 0.762712
2023-06-01 11:41:18,100:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0, the F1 is: 0.7635
2023-06-01 11:41:19,263:INFO: Epoch: 2/30, Step: 1/32, Lr: 0.000420000, Loss: 1.099907, Step Loss: 1.099907, Time: 1.079992
2023-06-01 11:41:19,602:INFO: Epoch: 2/30, Step: 2/32, Lr: 0.000420000, Loss: 0.233837, Step Loss: 0.233837, Time: 0.338640
2023-06-01 11:41:19,677:INFO: Epoch: 2/30, Step: 3/32, Lr: 0.000420000, Loss: 0.869288, Step Loss: 0.869288, Time: 0.075081
2023-06-01 11:41:19,747:INFO: Epoch: 2/30, Step: 4/32, Lr: 0.000420000, Loss: 0.481725, Step Loss: 0.481725, Time: 0.069177
2023-06-01 11:41:19,817:INFO: Epoch: 2/30, Step: 5/32, Lr: 0.000420000, Loss: 0.195340, Step Loss: 0.195340, Time: 0.070416
2023-06-01 11:41:19,887:INFO: Epoch: 2/30, Step: 6/32, Lr: 0.000420000, Loss: 0.557236, Step Loss: 0.557236, Time: 0.068941
2023-06-01 11:41:19,957:INFO: Epoch: 2/30, Step: 7/32, Lr: 0.000420000, Loss: 0.342189, Step Loss: 0.342189, Time: 0.070146
2023-06-01 11:41:20,026:INFO: Epoch: 2/30, Step: 8/32, Lr: 0.000420000, Loss: 0.486651, Step Loss: 0.486651, Time: 0.068587
2023-06-01 11:41:20,109:INFO: Epoch: 2/30, Step: 9/32, Lr: 0.000420000, Loss: 0.460063, Step Loss: 0.460063, Time: 0.082182
2023-06-01 11:41:20,189:INFO: Epoch: 2/30, Step: 10/32, Lr: 0.000420000, Loss: 0.262789, Step Loss: 0.262789, Time: 0.079714
2023-06-01 11:41:20,261:INFO: Epoch: 2/30, Step: 11/32, Lr: 0.000420000, Loss: 0.504744, Step Loss: 0.504744, Time: 0.071782
2023-06-01 11:41:20,335:INFO: Epoch: 2/30, Step: 12/32, Lr: 0.000420000, Loss: 0.294845, Step Loss: 0.294845, Time: 0.073445
2023-06-01 11:41:20,403:INFO: Epoch: 2/30, Step: 13/32, Lr: 0.000420000, Loss: 0.236056, Step Loss: 0.236056, Time: 0.068126
2023-06-01 11:41:20,477:INFO: Epoch: 2/30, Step: 14/32, Lr: 0.000420000, Loss: 0.220458, Step Loss: 0.220458, Time: 0.074069
2023-06-01 11:41:20,551:INFO: Epoch: 2/30, Step: 15/32, Lr: 0.000420000, Loss: 0.346332, Step Loss: 0.346332, Time: 0.072682
2023-06-01 11:41:20,621:INFO: Epoch: 2/30, Step: 16/32, Lr: 0.000420000, Loss: 0.247956, Step Loss: 0.247956, Time: 0.069965
2023-06-01 11:41:20,698:INFO: Epoch: 2/30, Step: 17/32, Lr: 0.000420000, Loss: 0.948574, Step Loss: 0.948574, Time: 0.076898
2023-06-01 11:41:20,780:INFO: Epoch: 2/30, Step: 18/32, Lr: 0.000420000, Loss: 0.465893, Step Loss: 0.465893, Time: 0.081936
2023-06-01 11:41:20,848:INFO: Epoch: 2/30, Step: 19/32, Lr: 0.000420000, Loss: 0.618275, Step Loss: 0.618275, Time: 0.067288
2023-06-01 11:41:20,917:INFO: Epoch: 2/30, Step: 20/32, Lr: 0.000420000, Loss: 0.441483, Step Loss: 0.441483, Time: 0.068880
2023-06-01 11:41:20,991:INFO: Epoch: 2/30, Step: 21/32, Lr: 0.000420000, Loss: 0.902273, Step Loss: 0.902273, Time: 0.073134
2023-06-01 11:41:21,074:INFO: Epoch: 2/30, Step: 22/32, Lr: 0.000420000, Loss: 0.204307, Step Loss: 0.204307, Time: 0.083059
2023-06-01 11:41:21,154:INFO: Epoch: 2/30, Step: 23/32, Lr: 0.000420000, Loss: 0.623532, Step Loss: 0.623532, Time: 0.079509
2023-06-01 11:41:21,225:INFO: Epoch: 2/30, Step: 24/32, Lr: 0.000420000, Loss: 0.129129, Step Loss: 0.129129, Time: 0.070642
2023-06-01 11:41:21,299:INFO: Epoch: 2/30, Step: 25/32, Lr: 0.000420000, Loss: 0.778287, Step Loss: 0.778287, Time: 0.073441
2023-06-01 11:41:21,367:INFO: Epoch: 2/30, Step: 26/32, Lr: 0.000420000, Loss: 0.271959, Step Loss: 0.271959, Time: 0.067594
2023-06-01 11:41:21,436:INFO: Epoch: 2/30, Step: 27/32, Lr: 0.000420000, Loss: 1.271296, Step Loss: 1.271296, Time: 0.068974
2023-06-01 11:41:21,510:INFO: Epoch: 2/30, Step: 28/32, Lr: 0.000420000, Loss: 0.245137, Step Loss: 0.245137, Time: 0.073812
2023-06-01 11:41:21,586:INFO: Epoch: 2/30, Step: 29/32, Lr: 0.000420000, Loss: 0.539660, Step Loss: 0.539660, Time: 0.075752
2023-06-01 11:41:21,662:INFO: Epoch: 2/30, Step: 30/32, Lr: 0.000420000, Loss: 0.296259, Step Loss: 0.296259, Time: 0.075209
2023-06-01 11:41:21,735:INFO: Epoch: 2/30, Step: 31/32, Lr: 0.000420000, Loss: 0.416550, Step Loss: 0.416550, Time: 0.072873
2023-06-01 11:41:21,803:INFO: Epoch: 2/30, Step: 32/32, Lr: 0.000420000, Loss: 0.500444, Step Loss: 0.500444, Time: 0.067801
2023-06-01 11:41:21,923:INFO: Epoch 2/30 Finished, Train Loss: 0.484140
2023-06-01 11:41:28,905:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1
2023-06-01 11:41:31,852:INFO: Classfication Metrics:
2023-06-01 11:41:31,853:INFO: f1 score: 0.8500 - precision score: 0.8226 - recall score: 0.8793 - accuracy score: 0.877966
2023-06-01 11:41:31,853:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.8500
2023-06-01 11:41:32,896:INFO: Epoch: 3/30, Step: 1/32, Lr: 0.000690000, Loss: 0.226679, Step Loss: 0.226679, Time: 1.027352
2023-06-01 11:41:32,976:INFO: Epoch: 3/30, Step: 2/32, Lr: 0.000690000, Loss: 0.141243, Step Loss: 0.141243, Time: 0.078985
2023-06-01 11:41:33,050:INFO: Epoch: 3/30, Step: 3/32, Lr: 0.000690000, Loss: 0.263517, Step Loss: 0.263517, Time: 0.074438
2023-06-01 11:41:33,143:INFO: Epoch: 3/30, Step: 4/32, Lr: 0.000690000, Loss: 0.436488, Step Loss: 0.436488, Time: 0.091751
2023-06-01 11:41:33,229:INFO: Epoch: 3/30, Step: 5/32, Lr: 0.000690000, Loss: 0.067223, Step Loss: 0.067223, Time: 0.085418
2023-06-01 11:41:33,308:INFO: Epoch: 3/30, Step: 6/32, Lr: 0.000690000, Loss: 0.280170, Step Loss: 0.280170, Time: 0.078117
2023-06-01 11:41:33,380:INFO: Epoch: 3/30, Step: 7/32, Lr: 0.000690000, Loss: 0.095790, Step Loss: 0.095790, Time: 0.071430
2023-06-01 11:41:33,462:INFO: Epoch: 3/30, Step: 8/32, Lr: 0.000690000, Loss: 0.174205, Step Loss: 0.174205, Time: 0.081668
2023-06-01 11:41:33,555:INFO: Epoch: 3/30, Step: 9/32, Lr: 0.000690000, Loss: 0.266942, Step Loss: 0.266942, Time: 0.092140
2023-06-01 11:41:33,638:INFO: Epoch: 3/30, Step: 10/32, Lr: 0.000690000, Loss: 0.297534, Step Loss: 0.297534, Time: 0.081884
2023-06-01 11:41:33,719:INFO: Epoch: 3/30, Step: 11/32, Lr: 0.000690000, Loss: 0.632757, Step Loss: 0.632757, Time: 0.081001
2023-06-01 11:41:33,802:INFO: Epoch: 3/30, Step: 12/32, Lr: 0.000690000, Loss: 0.522572, Step Loss: 0.522572, Time: 0.082567
2023-06-01 11:41:33,878:INFO: Epoch: 3/30, Step: 13/32, Lr: 0.000690000, Loss: 0.450579, Step Loss: 0.450579, Time: 0.075314
2023-06-01 11:41:33,965:INFO: Epoch: 3/30, Step: 14/32, Lr: 0.000690000, Loss: 0.312343, Step Loss: 0.312343, Time: 0.085607
2023-06-01 11:41:34,045:INFO: Epoch: 3/30, Step: 15/32, Lr: 0.000690000, Loss: 0.279476, Step Loss: 0.279476, Time: 0.079312
2023-06-01 11:41:34,125:INFO: Epoch: 3/30, Step: 16/32, Lr: 0.000690000, Loss: 0.251589, Step Loss: 0.251589, Time: 0.079901
2023-06-01 11:41:34,215:INFO: Epoch: 3/30, Step: 17/32, Lr: 0.000690000, Loss: 0.986381, Step Loss: 0.986381, Time: 0.089244
2023-06-01 11:41:34,294:INFO: Epoch: 3/30, Step: 18/32, Lr: 0.000690000, Loss: 0.629294, Step Loss: 0.629294, Time: 0.078368
2023-06-01 11:41:34,376:INFO: Epoch: 3/30, Step: 19/32, Lr: 0.000690000, Loss: 0.447061, Step Loss: 0.447061, Time: 0.080998
2023-06-01 11:41:34,464:INFO: Epoch: 3/30, Step: 20/32, Lr: 0.000690000, Loss: 0.499192, Step Loss: 0.499192, Time: 0.087342
2023-06-01 11:41:34,545:INFO: Epoch: 3/30, Step: 21/32, Lr: 0.000690000, Loss: 0.281616, Step Loss: 0.281616, Time: 0.080332
2023-06-01 11:41:34,620:INFO: Epoch: 3/30, Step: 22/32, Lr: 0.000690000, Loss: 0.332606, Step Loss: 0.332606, Time: 0.074946
2023-06-01 11:41:34,700:INFO: Epoch: 3/30, Step: 23/32, Lr: 0.000690000, Loss: 1.564172, Step Loss: 1.564172, Time: 0.078904
2023-06-01 11:41:34,776:INFO: Epoch: 3/30, Step: 24/32, Lr: 0.000690000, Loss: 5.358081, Step Loss: 5.358081, Time: 0.075423
2023-06-01 11:41:34,863:INFO: Epoch: 3/30, Step: 25/32, Lr: 0.000690000, Loss: 1.019475, Step Loss: 1.019475, Time: 0.086695
2023-06-01 11:41:34,943:INFO: Epoch: 3/30, Step: 26/32, Lr: 0.000690000, Loss: 0.859724, Step Loss: 0.859724, Time: 0.078971
2023-06-01 11:41:35,014:INFO: Epoch: 3/30, Step: 27/32, Lr: 0.000690000, Loss: 1.431314, Step Loss: 1.431314, Time: 0.070982
2023-06-01 11:41:35,097:INFO: Epoch: 3/30, Step: 28/32, Lr: 0.000690000, Loss: 2.396724, Step Loss: 2.396724, Time: 0.082135
2023-06-01 11:41:35,170:INFO: Epoch: 3/30, Step: 29/32, Lr: 0.000690000, Loss: 0.289857, Step Loss: 0.289857, Time: 0.072750
2023-06-01 11:41:35,248:INFO: Epoch: 3/30, Step: 30/32, Lr: 0.000690000, Loss: 3.257927, Step Loss: 3.257927, Time: 0.077274
2023-06-01 11:41:35,327:INFO: Epoch: 3/30, Step: 31/32, Lr: 0.000690000, Loss: 3.663636, Step Loss: 3.663636, Time: 0.078878
2023-06-01 11:41:35,401:INFO: Epoch: 3/30, Step: 32/32, Lr: 0.000690000, Loss: 1.822969, Step Loss: 1.822969, Time: 0.073399
2023-06-01 11:41:35,535:INFO: Epoch 3/30 Finished, Train Loss: 0.923098
2023-06-01 11:41:46,579:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2
2023-06-01 11:41:49,635:INFO: Classfication Metrics:
2023-06-01 11:41:49,636:INFO: f1 score: 0.3309 - precision score: 1.0000 - recall score: 0.1983 - accuracy score: 0.684746
2023-06-01 11:41:49,636:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.8500
2023-06-01 11:41:50,598:INFO: Epoch: 4/30, Step: 1/32, Lr: 0.001230000, Loss: 1.761257, Step Loss: 1.761257, Time: 0.949378
2023-06-01 11:41:50,944:INFO: Epoch: 4/30, Step: 2/32, Lr: 0.001230000, Loss: 0.420561, Step Loss: 0.420561, Time: 0.345731
2023-06-01 11:41:51,019:INFO: Epoch: 4/30, Step: 3/32, Lr: 0.001230000, Loss: 1.277496, Step Loss: 1.277496, Time: 0.074148
2023-06-01 11:41:51,097:INFO: Epoch: 4/30, Step: 4/32, Lr: 0.001230000, Loss: 0.887813, Step Loss: 0.887813, Time: 0.077116
2023-06-01 11:41:51,175:INFO: Epoch: 4/30, Step: 5/32, Lr: 0.001230000, Loss: 0.648114, Step Loss: 0.648114, Time: 0.077664
2023-06-01 11:41:51,250:INFO: Epoch: 4/30, Step: 6/32, Lr: 0.001230000, Loss: 1.680308, Step Loss: 1.680308, Time: 0.074530
2023-06-01 11:41:51,324:INFO: Epoch: 4/30, Step: 7/32, Lr: 0.001230000, Loss: 1.216974, Step Loss: 1.216974, Time: 0.072996
2023-06-01 11:41:51,402:INFO: Epoch: 4/30, Step: 8/32, Lr: 0.001230000, Loss: 0.485051, Step Loss: 0.485051, Time: 0.077950
2023-06-01 11:41:51,477:INFO: Epoch: 4/30, Step: 9/32, Lr: 0.001230000, Loss: 0.339456, Step Loss: 0.339456, Time: 0.074355
2023-06-01 11:41:51,572:INFO: Epoch: 4/30, Step: 10/32, Lr: 0.001230000, Loss: 0.814342, Step Loss: 0.814342, Time: 0.094629
2023-06-01 11:41:51,646:INFO: Epoch: 4/30, Step: 11/32, Lr: 0.001230000, Loss: 0.356801, Step Loss: 0.356801, Time: 0.073075
2023-06-01 11:41:51,724:INFO: Epoch: 4/30, Step: 12/32, Lr: 0.001230000, Loss: 0.473431, Step Loss: 0.473431, Time: 0.078037
2023-06-01 11:41:51,867:INFO: Epoch: 4/30, Step: 13/32, Lr: 0.001230000, Loss: 0.608462, Step Loss: 0.608462, Time: 0.141618
2023-06-01 11:41:51,943:INFO: Epoch: 4/30, Step: 14/32, Lr: 0.001230000, Loss: 2.637568, Step Loss: 2.637568, Time: 0.074863
2023-06-01 11:41:52,019:INFO: Epoch: 4/30, Step: 15/32, Lr: 0.001230000, Loss: 0.829542, Step Loss: 0.829542, Time: 0.076235
2023-06-01 11:41:52,100:INFO: Epoch: 4/30, Step: 16/32, Lr: 0.001230000, Loss: 1.852475, Step Loss: 1.852475, Time: 0.080209
2023-06-01 11:41:52,175:INFO: Epoch: 4/30, Step: 17/32, Lr: 0.001230000, Loss: 1.226627, Step Loss: 1.226627, Time: 0.074057
2023-06-01 11:41:52,267:INFO: Epoch: 4/30, Step: 18/32, Lr: 0.001230000, Loss: 1.888636, Step Loss: 1.888636, Time: 0.091587
2023-06-01 11:41:52,340:INFO: Epoch: 4/30, Step: 19/32, Lr: 0.001230000, Loss: 1.151691, Step Loss: 1.151691, Time: 0.072232
2023-06-01 11:41:52,414:INFO: Epoch: 4/30, Step: 20/32, Lr: 0.001230000, Loss: 0.909257, Step Loss: 0.909257, Time: 0.073630
2023-06-01 11:41:52,504:INFO: Epoch: 4/30, Step: 21/32, Lr: 0.001230000, Loss: 1.424453, Step Loss: 1.424453, Time: 0.089456
2023-06-01 11:41:52,588:INFO: Epoch: 4/30, Step: 22/32, Lr: 0.001230000, Loss: 0.783923, Step Loss: 0.783923, Time: 0.082964
2023-06-01 11:41:52,663:INFO: Epoch: 4/30, Step: 23/32, Lr: 0.001230000, Loss: 1.466619, Step Loss: 1.466619, Time: 0.074463
2023-06-01 11:41:52,735:INFO: Epoch: 4/30, Step: 24/32, Lr: 0.001230000, Loss: 1.059491, Step Loss: 1.059491, Time: 0.071514
2023-06-01 11:41:52,813:INFO: Epoch: 4/30, Step: 25/32, Lr: 0.001230000, Loss: 0.816753, Step Loss: 0.816753, Time: 0.077204
2023-06-01 11:41:52,891:INFO: Epoch: 4/30, Step: 26/32, Lr: 0.001230000, Loss: 1.699969, Step Loss: 1.699969, Time: 0.077593
2023-06-01 11:41:52,962:INFO: Epoch: 4/30, Step: 27/32, Lr: 0.001230000, Loss: 2.386647, Step Loss: 2.386647, Time: 0.070665
2023-06-01 11:41:53,034:INFO: Epoch: 4/30, Step: 28/32, Lr: 0.001230000, Loss: 0.689918, Step Loss: 0.689918, Time: 0.071176
2023-06-01 11:41:53,115:INFO: Epoch: 4/30, Step: 29/32, Lr: 0.001230000, Loss: 3.350190, Step Loss: 3.350190, Time: 0.080961
2023-06-01 11:41:53,191:INFO: Epoch: 4/30, Step: 30/32, Lr: 0.001230000, Loss: 1.253480, Step Loss: 1.253480, Time: 0.075186
2023-06-01 11:41:53,276:INFO: Epoch: 4/30, Step: 31/32, Lr: 0.001230000, Loss: 0.914974, Step Loss: 0.914974, Time: 0.083893
2023-06-01 11:41:53,350:INFO: Epoch: 4/30, Step: 32/32, Lr: 0.001230000, Loss: 0.943234, Step Loss: 0.943234, Time: 0.074218
2023-06-01 11:41:53,490:INFO: Epoch 4/30 Finished, Train Loss: 1.195485
2023-06-01 11:42:00,305:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.3
2023-06-01 11:42:03,261:INFO: Classfication Metrics:
2023-06-01 11:42:03,261:INFO: f1 score: 0.7766 - precision score: 0.6457 - recall score: 0.9741 - accuracy score: 0.779661
2023-06-01 11:42:03,261:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.8500
2023-06-01 11:42:04,336:INFO: Epoch: 5/30, Step: 1/32, Lr: 0.001500000, Loss: 2.002398, Step Loss: 2.002398, Time: 1.065540
2023-06-01 11:42:04,424:INFO: Epoch: 5/30, Step: 2/32, Lr: 0.001500000, Loss: 0.250455, Step Loss: 0.250455, Time: 0.087398
2023-06-01 11:42:04,511:INFO: Epoch: 5/30, Step: 3/32, Lr: 0.001500000, Loss: 0.937489, Step Loss: 0.937489, Time: 0.086886
2023-06-01 11:42:04,583:INFO: Epoch: 5/30, Step: 4/32, Lr: 0.001500000, Loss: 1.202629, Step Loss: 1.202629, Time: 0.071304
2023-06-01 11:42:04,667:INFO: Epoch: 5/30, Step: 5/32, Lr: 0.001500000, Loss: 0.896961, Step Loss: 0.896961, Time: 0.084415
2023-06-01 11:42:04,744:INFO: Epoch: 5/30, Step: 6/32, Lr: 0.001500000, Loss: 0.363383, Step Loss: 0.363383, Time: 0.075884
2023-06-01 11:42:04,818:INFO: Epoch: 5/30, Step: 7/32, Lr: 0.001500000, Loss: 0.866562, Step Loss: 0.866562, Time: 0.073234
2023-06-01 11:42:04,892:INFO: Epoch: 5/30, Step: 8/32, Lr: 0.001500000, Loss: 1.737049, Step Loss: 1.737049, Time: 0.073975
2023-06-01 11:42:04,975:INFO: Epoch: 5/30, Step: 9/32, Lr: 0.001500000, Loss: 0.794083, Step Loss: 0.794083, Time: 0.082379
2023-06-01 11:42:05,055:INFO: Epoch: 5/30, Step: 10/32, Lr: 0.001500000, Loss: 0.374545, Step Loss: 0.374545, Time: 0.079110
2023-06-01 11:42:05,139:INFO: Epoch: 5/30, Step: 11/32, Lr: 0.001500000, Loss: 1.311991, Step Loss: 1.311991, Time: 0.083445
2023-06-01 11:42:05,224:INFO: Epoch: 5/30, Step: 12/32, Lr: 0.001500000, Loss: 0.879880, Step Loss: 0.879880, Time: 0.084070
2023-06-01 11:42:05,300:INFO: Epoch: 5/30, Step: 13/32, Lr: 0.001500000, Loss: 0.343535, Step Loss: 0.343535, Time: 0.075195
2023-06-01 11:42:05,379:INFO: Epoch: 5/30, Step: 14/32, Lr: 0.001500000, Loss: 0.705019, Step Loss: 0.705019, Time: 0.078548
2023-06-01 11:42:05,454:INFO: Epoch: 5/30, Step: 15/32, Lr: 0.001500000, Loss: 0.884176, Step Loss: 0.884176, Time: 0.074740
2023-06-01 11:42:05,539:INFO: Epoch: 5/30, Step: 16/32, Lr: 0.001500000, Loss: 0.858896, Step Loss: 0.858896, Time: 0.084600
2023-06-01 11:42:05,619:INFO: Epoch: 5/30, Step: 17/32, Lr: 0.001500000, Loss: 0.391975, Step Loss: 0.391975, Time: 0.079401
2023-06-01 11:42:05,699:INFO: Epoch: 5/30, Step: 18/32, Lr: 0.001500000, Loss: 0.541563, Step Loss: 0.541563, Time: 0.079207
2023-06-01 11:42:05,780:INFO: Epoch: 5/30, Step: 19/32, Lr: 0.001500000, Loss: 0.237494, Step Loss: 0.237494, Time: 0.080458
2023-06-01 11:42:05,868:INFO: Epoch: 5/30, Step: 20/32, Lr: 0.001500000, Loss: 0.701148, Step Loss: 0.701148, Time: 0.087180
2023-06-01 11:42:05,953:INFO: Epoch: 5/30, Step: 21/32, Lr: 0.001500000, Loss: 0.052451, Step Loss: 0.052451, Time: 0.084626
2023-06-01 11:42:06,036:INFO: Epoch: 5/30, Step: 22/32, Lr: 0.001500000, Loss: 0.030513, Step Loss: 0.030513, Time: 0.082601
2023-06-01 11:42:06,116:INFO: Epoch: 5/30, Step: 23/32, Lr: 0.001500000, Loss: 0.229579, Step Loss: 0.229579, Time: 0.079381
2023-06-01 11:42:06,200:INFO: Epoch: 5/30, Step: 24/32, Lr: 0.001500000, Loss: 0.296605, Step Loss: 0.296605, Time: 0.083318
2023-06-01 11:42:06,289:INFO: Epoch: 5/30, Step: 25/32, Lr: 0.001500000, Loss: 0.442176, Step Loss: 0.442176, Time: 0.087665
2023-06-01 11:42:06,364:INFO: Epoch: 5/30, Step: 26/32, Lr: 0.001500000, Loss: 0.126897, Step Loss: 0.126897, Time: 0.075123
2023-06-01 11:42:06,442:INFO: Epoch: 5/30, Step: 27/32, Lr: 0.001500000, Loss: 0.274861, Step Loss: 0.274861, Time: 0.077319
2023-06-01 11:42:06,529:INFO: Epoch: 5/30, Step: 28/32, Lr: 0.001500000, Loss: 0.311534, Step Loss: 0.311534, Time: 0.086025
2023-06-01 11:42:06,604:INFO: Epoch: 5/30, Step: 29/32, Lr: 0.001500000, Loss: 0.042380, Step Loss: 0.042380, Time: 0.074758
2023-06-01 11:42:06,683:INFO: Epoch: 5/30, Step: 30/32, Lr: 0.001500000, Loss: 0.176876, Step Loss: 0.176876, Time: 0.078056
2023-06-01 11:42:06,771:INFO: Epoch: 5/30, Step: 31/32, Lr: 0.001500000, Loss: 0.106590, Step Loss: 0.106590, Time: 0.087317
2023-06-01 11:42:06,847:INFO: Epoch: 5/30, Step: 32/32, Lr: 0.001500000, Loss: 0.653307, Step Loss: 0.653307, Time: 0.075797
2023-06-01 11:42:06,976:INFO: Epoch 5/30 Finished, Train Loss: 0.594531
2023-06-01 11:42:14,583:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4
2023-06-01 11:42:17,446:INFO: Classfication Metrics:
2023-06-01 11:42:17,446:INFO: f1 score: 0.8127 - precision score: 0.7556 - recall score: 0.8793 - accuracy score: 0.840678
2023-06-01 11:42:17,446:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.8500
2023-06-01 11:42:18,598:INFO: Epoch: 6/30, Step: 1/32, Lr: 0.001500000, Loss: 0.053723, Step Loss: 0.053723, Time: 1.126539
2023-06-01 11:42:18,678:INFO: Epoch: 6/30, Step: 2/32, Lr: 0.001500000, Loss: 0.421009, Step Loss: 0.421009, Time: 0.079548
2023-06-01 11:42:18,750:INFO: Epoch: 6/30, Step: 3/32, Lr: 0.001500000, Loss: 0.283878, Step Loss: 0.283878, Time: 0.070970
2023-06-01 11:42:18,821:INFO: Epoch: 6/30, Step: 4/32, Lr: 0.001500000, Loss: 0.032001, Step Loss: 0.032001, Time: 0.071175
2023-06-01 11:42:18,896:INFO: Epoch: 6/30, Step: 5/32, Lr: 0.001500000, Loss: 0.273326, Step Loss: 0.273326, Time: 0.074536
2023-06-01 11:42:18,980:INFO: Epoch: 6/30, Step: 6/32, Lr: 0.001500000, Loss: 0.203089, Step Loss: 0.203089, Time: 0.083318
2023-06-01 11:42:19,056:INFO: Epoch: 6/30, Step: 7/32, Lr: 0.001500000, Loss: 0.257360, Step Loss: 0.257360, Time: 0.075690
2023-06-01 11:42:19,128:INFO: Epoch: 6/30, Step: 8/32, Lr: 0.001500000, Loss: 0.345069, Step Loss: 0.345069, Time: 0.071101
2023-06-01 11:42:19,217:INFO: Epoch: 6/30, Step: 9/32, Lr: 0.001500000, Loss: 0.679276, Step Loss: 0.679276, Time: 0.088234
2023-06-01 11:42:19,296:INFO: Epoch: 6/30, Step: 10/32, Lr: 0.001500000, Loss: 0.573047, Step Loss: 0.573047, Time: 0.078028
2023-06-01 11:42:19,373:INFO: Epoch: 6/30, Step: 11/32, Lr: 0.001500000, Loss: 0.095879, Step Loss: 0.095879, Time: 0.076402
2023-06-01 11:42:19,454:INFO: Epoch: 6/30, Step: 12/32, Lr: 0.001500000, Loss: 0.816390, Step Loss: 0.816390, Time: 0.080856
2023-06-01 11:42:19,531:INFO: Epoch: 6/30, Step: 13/32, Lr: 0.001500000, Loss: 0.165769, Step Loss: 0.165769, Time: 0.076003
2023-06-01 11:42:19,607:INFO: Epoch: 6/30, Step: 14/32, Lr: 0.001500000, Loss: 0.090078, Step Loss: 0.090078, Time: 0.075631
2023-06-01 11:42:19,684:INFO: Epoch: 6/30, Step: 15/32, Lr: 0.001500000, Loss: 0.286347, Step Loss: 0.286347, Time: 0.077355
2023-06-01 11:42:19,769:INFO: Epoch: 6/30, Step: 16/32, Lr: 0.001500000, Loss: 0.162123, Step Loss: 0.162123, Time: 0.083548
2023-06-01 11:42:19,872:INFO: Epoch: 6/30, Step: 17/32, Lr: 0.001500000, Loss: 0.165903, Step Loss: 0.165903, Time: 0.103195
2023-06-01 11:42:19,954:INFO: Epoch: 6/30, Step: 18/32, Lr: 0.001500000, Loss: 0.382869, Step Loss: 0.382869, Time: 0.081226
2023-06-01 11:42:20,035:INFO: Epoch: 6/30, Step: 19/32, Lr: 0.001500000, Loss: 0.436614, Step Loss: 0.436614, Time: 0.079847
2023-06-01 11:42:20,122:INFO: Epoch: 6/30, Step: 20/32, Lr: 0.001500000, Loss: 0.403771, Step Loss: 0.403771, Time: 0.086627
2023-06-01 11:42:20,207:INFO: Epoch: 6/30, Step: 21/32, Lr: 0.001500000, Loss: 0.140888, Step Loss: 0.140888, Time: 0.084714
2023-06-01 11:42:20,295:INFO: Epoch: 6/30, Step: 22/32, Lr: 0.001500000, Loss: 0.037580, Step Loss: 0.037580, Time: 0.086775
2023-06-01 11:42:20,373:INFO: Epoch: 6/30, Step: 23/32, Lr: 0.001500000, Loss: 0.235585, Step Loss: 0.235585, Time: 0.078007
2023-06-01 11:42:20,448:INFO: Epoch: 6/30, Step: 24/32, Lr: 0.001500000, Loss: 0.787904, Step Loss: 0.787904, Time: 0.073824
2023-06-01 11:42:20,526:INFO: Epoch: 6/30, Step: 25/32, Lr: 0.001500000, Loss: 0.000782, Step Loss: 0.000782, Time: 0.078051
2023-06-01 11:42:20,607:INFO: Epoch: 6/30, Step: 26/32, Lr: 0.001500000, Loss: 0.000975, Step Loss: 0.000975, Time: 0.081134
2023-06-01 11:42:20,686:INFO: Epoch: 6/30, Step: 27/32, Lr: 0.001500000, Loss: 0.541214, Step Loss: 0.541214, Time: 0.078395
2023-06-01 11:42:20,760:INFO: Epoch: 6/30, Step: 28/32, Lr: 0.001500000, Loss: 0.254261, Step Loss: 0.254261, Time: 0.073288
2023-06-01 11:42:20,843:INFO: Epoch: 6/30, Step: 29/32, Lr: 0.001500000, Loss: 0.214856, Step Loss: 0.214856, Time: 0.083226
2023-06-01 11:42:20,930:INFO: Epoch: 6/30, Step: 30/32, Lr: 0.001500000, Loss: 0.219191, Step Loss: 0.219191, Time: 0.086102
2023-06-01 11:42:21,012:INFO: Epoch: 6/30, Step: 31/32, Lr: 0.001500000, Loss: 0.387038, Step Loss: 0.387038, Time: 0.081513
2023-06-01 11:42:21,085:INFO: Epoch: 6/30, Step: 32/32, Lr: 0.001500000, Loss: 0.161359, Step Loss: 0.161359, Time: 0.072136
2023-06-01 11:42:21,208:INFO: Epoch 6/30 Finished, Train Loss: 0.284661
2023-06-01 11:42:29,975:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5
2023-06-01 11:42:32,998:INFO: Classfication Metrics:
2023-06-01 11:42:32,998:INFO: f1 score: 0.8340 - precision score: 0.7552 - recall score: 0.9310 - accuracy score: 0.854237
2023-06-01 11:42:32,998:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1, the F1 is: 0.8500
2023-06-01 11:42:34,219:INFO: Epoch: 7/30, Step: 1/32, Lr: 0.001494086, Loss: 0.171529, Step Loss: 0.171529, Time: 1.179539
2023-06-01 11:42:34,298:INFO: Epoch: 7/30, Step: 2/32, Lr: 0.001494086, Loss: 0.005263, Step Loss: 0.005263, Time: 0.079261
2023-06-01 11:42:34,381:INFO: Epoch: 7/30, Step: 3/32, Lr: 0.001494086, Loss: 0.020948, Step Loss: 0.020948, Time: 0.081979
2023-06-01 11:42:34,456:INFO: Epoch: 7/30, Step: 4/32, Lr: 0.001494086, Loss: 0.000913, Step Loss: 0.000913, Time: 0.074738
2023-06-01 11:42:34,531:INFO: Epoch: 7/30, Step: 5/32, Lr: 0.001494086, Loss: 0.013778, Step Loss: 0.013778, Time: 0.074120
2023-06-01 11:42:34,608:INFO: Epoch: 7/30, Step: 6/32, Lr: 0.001494086, Loss: 0.150374, Step Loss: 0.150374, Time: 0.076707
2023-06-01 11:42:34,685:INFO: Epoch: 7/30, Step: 7/32, Lr: 0.001494086, Loss: 0.145233, Step Loss: 0.145233, Time: 0.075700
2023-06-01 11:42:34,767:INFO: Epoch: 7/30, Step: 8/32, Lr: 0.001494086, Loss: 0.136284, Step Loss: 0.136284, Time: 0.082209
2023-06-01 11:42:34,878:INFO: Epoch: 7/30, Step: 9/32, Lr: 0.001494086, Loss: 0.012496, Step Loss: 0.012496, Time: 0.096515
2023-06-01 11:42:34,960:INFO: Epoch: 7/30, Step: 10/32, Lr: 0.001494086, Loss: 0.132819, Step Loss: 0.132819, Time: 0.080908
2023-06-01 11:42:35,047:INFO: Epoch: 7/30, Step: 11/32, Lr: 0.001494086, Loss: 0.119991, Step Loss: 0.119991, Time: 0.086683
2023-06-01 11:42:35,126:INFO: Epoch: 7/30, Step: 12/32, Lr: 0.001494086, Loss: 0.077853, Step Loss: 0.077853, Time: 0.078618
2023-06-01 11:42:35,205:INFO: Epoch: 7/30, Step: 13/32, Lr: 0.001494086, Loss: 0.011426, Step Loss: 0.011426, Time: 0.077728
2023-06-01 11:42:35,286:INFO: Epoch: 7/30, Step: 14/32, Lr: 0.001494086, Loss: 0.000088, Step Loss: 0.000088, Time: 0.080507
2023-06-01 11:42:35,367:INFO: Epoch: 7/30, Step: 15/32, Lr: 0.001494086, Loss: 0.079010, Step Loss: 0.079010, Time: 0.080969
2023-06-01 11:42:35,448:INFO: Epoch: 7/30, Step: 16/32, Lr: 0.001494086, Loss: 0.005216, Step Loss: 0.005216, Time: 0.080008
2023-06-01 11:42:35,551:INFO: Epoch: 7/30, Step: 17/32, Lr: 0.001494086, Loss: 0.477390, Step Loss: 0.477390, Time: 0.102513
2023-06-01 11:42:35,632:INFO: Epoch: 7/30, Step: 18/32, Lr: 0.001494086, Loss: 0.044280, Step Loss: 0.044280, Time: 0.081008
2023-06-01 11:42:35,714:INFO: Epoch: 7/30, Step: 19/32, Lr: 0.001494086, Loss: 0.001730, Step Loss: 0.001730, Time: 0.080661
2023-06-01 11:42:35,792:INFO: Epoch: 7/30, Step: 20/32, Lr: 0.001494086, Loss: 0.016622, Step Loss: 0.016622, Time: 0.078175
2023-06-01 11:42:35,874:INFO: Epoch: 7/30, Step: 21/32, Lr: 0.001494086, Loss: 0.011345, Step Loss: 0.011345, Time: 0.081264
2023-06-01 11:42:35,954:INFO: Epoch: 7/30, Step: 22/32, Lr: 0.001494086, Loss: 0.175282, Step Loss: 0.175282, Time: 0.079024
2023-06-01 11:42:36,038:INFO: Epoch: 7/30, Step: 23/32, Lr: 0.001494086, Loss: 0.057674, Step Loss: 0.057674, Time: 0.083613
2023-06-01 11:42:36,121:INFO: Epoch: 7/30, Step: 24/32, Lr: 0.001494086, Loss: 0.001512, Step Loss: 0.001512, Time: 0.082153
2023-06-01 11:42:36,205:INFO: Epoch: 7/30, Step: 25/32, Lr: 0.001494086, Loss: 0.061182, Step Loss: 0.061182, Time: 0.083737
2023-06-01 11:42:36,278:INFO: Epoch: 7/30, Step: 26/32, Lr: 0.001494086, Loss: 0.171067, Step Loss: 0.171067, Time: 0.073273
2023-06-01 11:42:36,352:INFO: Epoch: 7/30, Step: 27/32, Lr: 0.001494086, Loss: 0.003705, Step Loss: 0.003705, Time: 0.073715
2023-06-01 11:42:36,433:INFO: Epoch: 7/30, Step: 28/32, Lr: 0.001494086, Loss: 0.000333, Step Loss: 0.000333, Time: 0.079654
2023-06-01 11:42:36,515:INFO: Epoch: 7/30, Step: 29/32, Lr: 0.001494086, Loss: 0.119550, Step Loss: 0.119550, Time: 0.081683
2023-06-01 11:42:36,586:INFO: Epoch: 7/30, Step: 30/32, Lr: 0.001494086, Loss: 0.002360, Step Loss: 0.002360, Time: 0.071456
2023-06-01 11:42:36,662:INFO: Epoch: 7/30, Step: 31/32, Lr: 0.001494086, Loss: 0.055684, Step Loss: 0.055684, Time: 0.075299
2023-06-01 11:42:36,743:INFO: Epoch: 7/30, Step: 32/32, Lr: 0.001494086, Loss: 0.001596, Step Loss: 0.001596, Time: 0.080346
2023-06-01 11:42:36,900:INFO: Epoch 7/30 Finished, Train Loss: 0.071392
2023-06-01 11:42:42,872:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6
2023-06-01 11:42:45,928:INFO: Classfication Metrics:
2023-06-01 11:42:45,928:INFO: f1 score: 0.9013 - precision score: 0.8974 - recall score: 0.9052 - accuracy score: 0.922034
2023-06-01 11:42:45,928:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:42:47,011:INFO: Epoch: 8/30, Step: 1/32, Lr: 0.001476437, Loss: 0.022351, Step Loss: 0.022351, Time: 1.055120
2023-06-01 11:42:47,123:INFO: Epoch: 8/30, Step: 2/32, Lr: 0.001476437, Loss: 0.293488, Step Loss: 0.293488, Time: 0.111429
2023-06-01 11:42:47,200:INFO: Epoch: 8/30, Step: 3/32, Lr: 0.001476437, Loss: 0.035453, Step Loss: 0.035453, Time: 0.075759
2023-06-01 11:42:47,275:INFO: Epoch: 8/30, Step: 4/32, Lr: 0.001476437, Loss: 0.007832, Step Loss: 0.007832, Time: 0.074017
2023-06-01 11:42:47,364:INFO: Epoch: 8/30, Step: 5/32, Lr: 0.001476437, Loss: 0.005179, Step Loss: 0.005179, Time: 0.089547
2023-06-01 11:42:47,439:INFO: Epoch: 8/30, Step: 6/32, Lr: 0.001476437, Loss: 0.032110, Step Loss: 0.032110, Time: 0.074146
2023-06-01 11:42:47,509:INFO: Epoch: 8/30, Step: 7/32, Lr: 0.001476437, Loss: 0.104900, Step Loss: 0.104900, Time: 0.069452
2023-06-01 11:42:47,586:INFO: Epoch: 8/30, Step: 8/32, Lr: 0.001476437, Loss: 0.018175, Step Loss: 0.018175, Time: 0.076166
2023-06-01 11:42:47,661:INFO: Epoch: 8/30, Step: 9/32, Lr: 0.001476437, Loss: 0.000032, Step Loss: 0.000032, Time: 0.074287
2023-06-01 11:42:47,749:INFO: Epoch: 8/30, Step: 10/32, Lr: 0.001476437, Loss: 0.195660, Step Loss: 0.195660, Time: 0.087083
2023-06-01 11:42:47,828:INFO: Epoch: 8/30, Step: 11/32, Lr: 0.001476437, Loss: 0.000559, Step Loss: 0.000559, Time: 0.079095
2023-06-01 11:42:47,904:INFO: Epoch: 8/30, Step: 12/32, Lr: 0.001476437, Loss: 0.029802, Step Loss: 0.029802, Time: 0.074849
2023-06-01 11:42:47,985:INFO: Epoch: 8/30, Step: 13/32, Lr: 0.001476437, Loss: 0.087597, Step Loss: 0.087597, Time: 0.080348
2023-06-01 11:42:48,060:INFO: Epoch: 8/30, Step: 14/32, Lr: 0.001476437, Loss: 0.055389, Step Loss: 0.055389, Time: 0.074539
2023-06-01 11:42:48,142:INFO: Epoch: 8/30, Step: 15/32, Lr: 0.001476437, Loss: 0.001037, Step Loss: 0.001037, Time: 0.081689
2023-06-01 11:42:48,216:INFO: Epoch: 8/30, Step: 16/32, Lr: 0.001476437, Loss: 0.012640, Step Loss: 0.012640, Time: 0.073310
2023-06-01 11:42:48,293:INFO: Epoch: 8/30, Step: 17/32, Lr: 0.001476437, Loss: 0.134425, Step Loss: 0.134425, Time: 0.076537
2023-06-01 11:42:48,420:INFO: Epoch: 8/30, Step: 18/32, Lr: 0.001476437, Loss: 0.101103, Step Loss: 0.101103, Time: 0.126338
2023-06-01 11:42:48,492:INFO: Epoch: 8/30, Step: 19/32, Lr: 0.001476437, Loss: 0.031742, Step Loss: 0.031742, Time: 0.071673
2023-06-01 11:42:48,567:INFO: Epoch: 8/30, Step: 20/32, Lr: 0.001476437, Loss: 0.141614, Step Loss: 0.141614, Time: 0.074130
2023-06-01 11:42:48,636:INFO: Epoch: 8/30, Step: 21/32, Lr: 0.001476437, Loss: 0.296171, Step Loss: 0.296171, Time: 0.068805
2023-06-01 11:42:48,711:INFO: Epoch: 8/30, Step: 22/32, Lr: 0.001476437, Loss: 0.023682, Step Loss: 0.023682, Time: 0.074304
2023-06-01 11:42:48,781:INFO: Epoch: 8/30, Step: 23/32, Lr: 0.001476437, Loss: 0.042439, Step Loss: 0.042439, Time: 0.069067
2023-06-01 11:42:48,855:INFO: Epoch: 8/30, Step: 24/32, Lr: 0.001476437, Loss: 0.145324, Step Loss: 0.145324, Time: 0.074049
2023-06-01 11:42:48,934:INFO: Epoch: 8/30, Step: 25/32, Lr: 0.001476437, Loss: 0.027630, Step Loss: 0.027630, Time: 0.078143
2023-06-01 11:42:49,017:INFO: Epoch: 8/30, Step: 26/32, Lr: 0.001476437, Loss: 0.008472, Step Loss: 0.008472, Time: 0.082087
2023-06-01 11:42:49,091:INFO: Epoch: 8/30, Step: 27/32, Lr: 0.001476437, Loss: 0.014378, Step Loss: 0.014378, Time: 0.073741
2023-06-01 11:42:49,160:INFO: Epoch: 8/30, Step: 28/32, Lr: 0.001476437, Loss: 0.000203, Step Loss: 0.000203, Time: 0.068136
2023-06-01 11:42:49,234:INFO: Epoch: 8/30, Step: 29/32, Lr: 0.001476437, Loss: 0.017099, Step Loss: 0.017099, Time: 0.073864
2023-06-01 11:42:49,314:INFO: Epoch: 8/30, Step: 30/32, Lr: 0.001476437, Loss: 0.160464, Step Loss: 0.160464, Time: 0.079561
2023-06-01 11:42:49,390:INFO: Epoch: 8/30, Step: 31/32, Lr: 0.001476437, Loss: 0.025998, Step Loss: 0.025998, Time: 0.074623
2023-06-01 11:42:49,463:INFO: Epoch: 8/30, Step: 32/32, Lr: 0.001476437, Loss: 0.040820, Step Loss: 0.040820, Time: 0.072747
2023-06-01 11:42:49,603:INFO: Epoch 8/30 Finished, Train Loss: 0.066055
2023-06-01 11:42:59,065:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.7
2023-06-01 11:43:01,914:INFO: Classfication Metrics:
2023-06-01 11:43:01,914:INFO: f1 score: 0.8349 - precision score: 0.8922 - recall score: 0.7845 - accuracy score: 0.877966
2023-06-01 11:43:01,914:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:43:03,015:INFO: Epoch: 9/30, Step: 1/32, Lr: 0.001447332, Loss: 0.150334, Step Loss: 0.150334, Time: 1.092155
2023-06-01 11:43:03,085:INFO: Epoch: 9/30, Step: 2/32, Lr: 0.001447332, Loss: 0.026584, Step Loss: 0.026584, Time: 0.069650
2023-06-01 11:43:03,163:INFO: Epoch: 9/30, Step: 3/32, Lr: 0.001447332, Loss: 0.146382, Step Loss: 0.146382, Time: 0.077459
2023-06-01 11:43:03,240:INFO: Epoch: 9/30, Step: 4/32, Lr: 0.001447332, Loss: 0.000735, Step Loss: 0.000735, Time: 0.076156
2023-06-01 11:43:03,312:INFO: Epoch: 9/30, Step: 5/32, Lr: 0.001447332, Loss: 0.024005, Step Loss: 0.024005, Time: 0.070991
2023-06-01 11:43:03,387:INFO: Epoch: 9/30, Step: 6/32, Lr: 0.001447332, Loss: 0.142024, Step Loss: 0.142024, Time: 0.074465
2023-06-01 11:43:03,455:INFO: Epoch: 9/30, Step: 7/32, Lr: 0.001447332, Loss: 0.000015, Step Loss: 0.000015, Time: 0.068288
2023-06-01 11:43:03,527:INFO: Epoch: 9/30, Step: 8/32, Lr: 0.001447332, Loss: 0.055109, Step Loss: 0.055109, Time: 0.070887
2023-06-01 11:43:03,608:INFO: Epoch: 9/30, Step: 9/32, Lr: 0.001447332, Loss: 0.000439, Step Loss: 0.000439, Time: 0.080279
2023-06-01 11:43:03,686:INFO: Epoch: 9/30, Step: 10/32, Lr: 0.001447332, Loss: 0.002077, Step Loss: 0.002077, Time: 0.078275
2023-06-01 11:43:03,759:INFO: Epoch: 9/30, Step: 11/32, Lr: 0.001447332, Loss: 0.148580, Step Loss: 0.148580, Time: 0.072371
2023-06-01 11:43:03,844:INFO: Epoch: 9/30, Step: 12/32, Lr: 0.001447332, Loss: 0.000253, Step Loss: 0.000253, Time: 0.084855
2023-06-01 11:43:03,919:INFO: Epoch: 9/30, Step: 13/32, Lr: 0.001447332, Loss: 0.474788, Step Loss: 0.474788, Time: 0.073812
2023-06-01 11:43:03,994:INFO: Epoch: 9/30, Step: 14/32, Lr: 0.001447332, Loss: 0.000241, Step Loss: 0.000241, Time: 0.074937
2023-06-01 11:43:04,068:INFO: Epoch: 9/30, Step: 15/32, Lr: 0.001447332, Loss: 0.000254, Step Loss: 0.000254, Time: 0.072893
2023-06-01 11:43:04,144:INFO: Epoch: 9/30, Step: 16/32, Lr: 0.001447332, Loss: 0.014954, Step Loss: 0.014954, Time: 0.075180
2023-06-01 11:43:04,224:INFO: Epoch: 9/30, Step: 17/32, Lr: 0.001447332, Loss: 0.238996, Step Loss: 0.238996, Time: 0.079953
2023-06-01 11:43:04,312:INFO: Epoch: 9/30, Step: 18/32, Lr: 0.001447332, Loss: 0.007879, Step Loss: 0.007879, Time: 0.087457
2023-06-01 11:43:04,385:INFO: Epoch: 9/30, Step: 19/32, Lr: 0.001447332, Loss: 0.019614, Step Loss: 0.019614, Time: 0.071678
2023-06-01 11:43:04,460:INFO: Epoch: 9/30, Step: 20/32, Lr: 0.001447332, Loss: 0.000652, Step Loss: 0.000652, Time: 0.075182
2023-06-01 11:43:04,531:INFO: Epoch: 9/30, Step: 21/32, Lr: 0.001447332, Loss: 0.218767, Step Loss: 0.218767, Time: 0.070612
2023-06-01 11:43:04,604:INFO: Epoch: 9/30, Step: 22/32, Lr: 0.001447332, Loss: 0.000002, Step Loss: 0.000002, Time: 0.071888
2023-06-01 11:43:04,679:INFO: Epoch: 9/30, Step: 23/32, Lr: 0.001447332, Loss: 0.000606, Step Loss: 0.000606, Time: 0.074204
2023-06-01 11:43:04,755:INFO: Epoch: 9/30, Step: 24/32, Lr: 0.001447332, Loss: 0.000306, Step Loss: 0.000306, Time: 0.075666
2023-06-01 11:43:04,834:INFO: Epoch: 9/30, Step: 25/32, Lr: 0.001447332, Loss: 0.004216, Step Loss: 0.004216, Time: 0.078161
2023-06-01 11:43:04,915:INFO: Epoch: 9/30, Step: 26/32, Lr: 0.001447332, Loss: 0.007873, Step Loss: 0.007873, Time: 0.081018
2023-06-01 11:43:04,988:INFO: Epoch: 9/30, Step: 27/32, Lr: 0.001447332, Loss: 0.101706, Step Loss: 0.101706, Time: 0.072481
2023-06-01 11:43:05,071:INFO: Epoch: 9/30, Step: 28/32, Lr: 0.001447332, Loss: 0.008298, Step Loss: 0.008298, Time: 0.082304
2023-06-01 11:43:05,145:INFO: Epoch: 9/30, Step: 29/32, Lr: 0.001447332, Loss: 0.006758, Step Loss: 0.006758, Time: 0.072646
2023-06-01 11:43:05,219:INFO: Epoch: 9/30, Step: 30/32, Lr: 0.001447332, Loss: 0.127786, Step Loss: 0.127786, Time: 0.074180
2023-06-01 11:43:05,297:INFO: Epoch: 9/30, Step: 31/32, Lr: 0.001447332, Loss: 0.000240, Step Loss: 0.000240, Time: 0.076657
2023-06-01 11:43:05,366:INFO: Epoch: 9/30, Step: 32/32, Lr: 0.001447332, Loss: 0.000709, Step Loss: 0.000709, Time: 0.068701
2023-06-01 11:43:05,501:INFO: Epoch 9/30 Finished, Train Loss: 0.060349
2023-06-01 11:43:12,168:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.8
2023-06-01 11:43:15,087:INFO: Classfication Metrics:
2023-06-01 11:43:15,088:INFO: f1 score: 0.8707 - precision score: 0.8707 - recall score: 0.8707 - accuracy score: 0.898305
2023-06-01 11:43:15,088:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:43:16,210:INFO: Epoch: 10/30, Step: 1/32, Lr: 0.001407230, Loss: 0.000079, Step Loss: 0.000079, Time: 1.099995
2023-06-01 11:43:16,295:INFO: Epoch: 10/30, Step: 2/32, Lr: 0.001407230, Loss: 0.112997, Step Loss: 0.112997, Time: 0.083792
2023-06-01 11:43:16,383:INFO: Epoch: 10/30, Step: 3/32, Lr: 0.001407230, Loss: 0.276615, Step Loss: 0.276615, Time: 0.087799
2023-06-01 11:43:16,460:INFO: Epoch: 10/30, Step: 4/32, Lr: 0.001407230, Loss: 0.000792, Step Loss: 0.000792, Time: 0.075755
2023-06-01 11:43:16,536:INFO: Epoch: 10/30, Step: 5/32, Lr: 0.001407230, Loss: 0.000006, Step Loss: 0.000006, Time: 0.075588
2023-06-01 11:43:16,622:INFO: Epoch: 10/30, Step: 6/32, Lr: 0.001407230, Loss: 0.000314, Step Loss: 0.000314, Time: 0.085236
2023-06-01 11:43:16,701:INFO: Epoch: 10/30, Step: 7/32, Lr: 0.001407230, Loss: 0.000618, Step Loss: 0.000618, Time: 0.078548
2023-06-01 11:43:16,780:INFO: Epoch: 10/30, Step: 8/32, Lr: 0.001407230, Loss: 0.000008, Step Loss: 0.000008, Time: 0.078735
2023-06-01 11:43:17,019:INFO: Epoch: 10/30, Step: 9/32, Lr: 0.001407230, Loss: 0.000140, Step Loss: 0.000140, Time: 0.238884
2023-06-01 11:43:17,095:INFO: Epoch: 10/30, Step: 10/32, Lr: 0.001407230, Loss: 0.098238, Step Loss: 0.098238, Time: 0.075464
2023-06-01 11:43:17,175:INFO: Epoch: 10/30, Step: 11/32, Lr: 0.001407230, Loss: 0.001223, Step Loss: 0.001223, Time: 0.079165
2023-06-01 11:43:17,259:INFO: Epoch: 10/30, Step: 12/32, Lr: 0.001407230, Loss: 0.067235, Step Loss: 0.067235, Time: 0.083167
2023-06-01 11:43:17,336:INFO: Epoch: 10/30, Step: 13/32, Lr: 0.001407230, Loss: 0.129534, Step Loss: 0.129534, Time: 0.075941
2023-06-01 11:43:17,415:INFO: Epoch: 10/30, Step: 14/32, Lr: 0.001407230, Loss: 0.000271, Step Loss: 0.000271, Time: 0.078361
2023-06-01 11:43:17,496:INFO: Epoch: 10/30, Step: 15/32, Lr: 0.001407230, Loss: 0.007983, Step Loss: 0.007983, Time: 0.080595
2023-06-01 11:43:17,575:INFO: Epoch: 10/30, Step: 16/32, Lr: 0.001407230, Loss: 0.004961, Step Loss: 0.004961, Time: 0.078522
2023-06-01 11:43:17,669:INFO: Epoch: 10/30, Step: 17/32, Lr: 0.001407230, Loss: 0.155166, Step Loss: 0.155166, Time: 0.093699
2023-06-01 11:43:17,745:INFO: Epoch: 10/30, Step: 18/32, Lr: 0.001407230, Loss: 0.000717, Step Loss: 0.000717, Time: 0.074730
2023-06-01 11:43:17,814:INFO: Epoch: 10/30, Step: 19/32, Lr: 0.001407230, Loss: 0.001965, Step Loss: 0.001965, Time: 0.069103
2023-06-01 11:43:17,889:INFO: Epoch: 10/30, Step: 20/32, Lr: 0.001407230, Loss: 0.001890, Step Loss: 0.001890, Time: 0.074524
2023-06-01 11:43:17,964:INFO: Epoch: 10/30, Step: 21/32, Lr: 0.001407230, Loss: 0.037382, Step Loss: 0.037382, Time: 0.074434
2023-06-01 11:43:18,041:INFO: Epoch: 10/30, Step: 22/32, Lr: 0.001407230, Loss: 0.001743, Step Loss: 0.001743, Time: 0.075867
2023-06-01 11:43:18,111:INFO: Epoch: 10/30, Step: 23/32, Lr: 0.001407230, Loss: 0.011751, Step Loss: 0.011751, Time: 0.069112
2023-06-01 11:43:18,190:INFO: Epoch: 10/30, Step: 24/32, Lr: 0.001407230, Loss: 0.000985, Step Loss: 0.000985, Time: 0.079134
2023-06-01 11:43:18,282:INFO: Epoch: 10/30, Step: 25/32, Lr: 0.001407230, Loss: 0.016298, Step Loss: 0.016298, Time: 0.091600
2023-06-01 11:43:18,360:INFO: Epoch: 10/30, Step: 26/32, Lr: 0.001407230, Loss: 0.004379, Step Loss: 0.004379, Time: 0.077344
2023-06-01 11:43:18,436:INFO: Epoch: 10/30, Step: 27/32, Lr: 0.001407230, Loss: 0.001069, Step Loss: 0.001069, Time: 0.074640
2023-06-01 11:43:18,512:INFO: Epoch: 10/30, Step: 28/32, Lr: 0.001407230, Loss: 0.000002, Step Loss: 0.000002, Time: 0.075720
2023-06-01 11:43:18,595:INFO: Epoch: 10/30, Step: 29/32, Lr: 0.001407230, Loss: 0.009049, Step Loss: 0.009049, Time: 0.082132
2023-06-01 11:43:18,677:INFO: Epoch: 10/30, Step: 30/32, Lr: 0.001407230, Loss: 0.001583, Step Loss: 0.001583, Time: 0.081327
2023-06-01 11:43:18,756:INFO: Epoch: 10/30, Step: 31/32, Lr: 0.001407230, Loss: 0.016100, Step Loss: 0.016100, Time: 0.078611
2023-06-01 11:43:18,832:INFO: Epoch: 10/30, Step: 32/32, Lr: 0.001407230, Loss: 0.002822, Step Loss: 0.002822, Time: 0.075519
2023-06-01 11:43:18,961:INFO: Epoch 10/30 Finished, Train Loss: 0.030122
2023-06-01 11:43:29,683:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.9
2023-06-01 11:43:32,645:INFO: Classfication Metrics:
2023-06-01 11:43:32,646:INFO: f1 score: 0.8667 - precision score: 0.8387 - recall score: 0.8966 - accuracy score: 0.891525
2023-06-01 11:43:32,646:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:43:33,738:INFO: Epoch: 11/30, Step: 1/32, Lr: 0.001356763, Loss: 0.001367, Step Loss: 0.001367, Time: 1.083663
2023-06-01 11:43:33,820:INFO: Epoch: 11/30, Step: 2/32, Lr: 0.001356763, Loss: 0.005273, Step Loss: 0.005273, Time: 0.081577
2023-06-01 11:43:33,902:INFO: Epoch: 11/30, Step: 3/32, Lr: 0.001356763, Loss: 0.000010, Step Loss: 0.000010, Time: 0.081750
2023-06-01 11:43:33,981:INFO: Epoch: 11/30, Step: 4/32, Lr: 0.001356763, Loss: 0.000195, Step Loss: 0.000195, Time: 0.078160
2023-06-01 11:43:34,060:INFO: Epoch: 11/30, Step: 5/32, Lr: 0.001356763, Loss: 0.002962, Step Loss: 0.002962, Time: 0.078989
2023-06-01 11:43:34,140:INFO: Epoch: 11/30, Step: 6/32, Lr: 0.001356763, Loss: 0.000396, Step Loss: 0.000396, Time: 0.078390
2023-06-01 11:43:34,224:INFO: Epoch: 11/30, Step: 7/32, Lr: 0.001356763, Loss: 0.049220, Step Loss: 0.049220, Time: 0.084228
2023-06-01 11:43:34,299:INFO: Epoch: 11/30, Step: 8/32, Lr: 0.001356763, Loss: 0.000028, Step Loss: 0.000028, Time: 0.073579
2023-06-01 11:43:34,375:INFO: Epoch: 11/30, Step: 9/32, Lr: 0.001356763, Loss: 0.069123, Step Loss: 0.069123, Time: 0.076178
2023-06-01 11:43:34,459:INFO: Epoch: 11/30, Step: 10/32, Lr: 0.001356763, Loss: 0.000025, Step Loss: 0.000025, Time: 0.083379
2023-06-01 11:43:34,537:INFO: Epoch: 11/30, Step: 11/32, Lr: 0.001356763, Loss: 0.000062, Step Loss: 0.000062, Time: 0.077371
2023-06-01 11:43:34,617:INFO: Epoch: 11/30, Step: 12/32, Lr: 0.001356763, Loss: 0.115350, Step Loss: 0.115350, Time: 0.078712
2023-06-01 11:43:34,695:INFO: Epoch: 11/30, Step: 13/32, Lr: 0.001356763, Loss: 0.000018, Step Loss: 0.000018, Time: 0.077725
2023-06-01 11:43:34,770:INFO: Epoch: 11/30, Step: 14/32, Lr: 0.001356763, Loss: 0.010648, Step Loss: 0.010648, Time: 0.074583
2023-06-01 11:43:34,847:INFO: Epoch: 11/30, Step: 15/32, Lr: 0.001356763, Loss: 0.068742, Step Loss: 0.068742, Time: 0.075959
2023-06-01 11:43:34,927:INFO: Epoch: 11/30, Step: 16/32, Lr: 0.001356763, Loss: 0.000037, Step Loss: 0.000037, Time: 0.080275
2023-06-01 11:43:35,010:INFO: Epoch: 11/30, Step: 17/32, Lr: 0.001356763, Loss: 0.000469, Step Loss: 0.000469, Time: 0.082319
2023-06-01 11:43:35,099:INFO: Epoch: 11/30, Step: 18/32, Lr: 0.001356763, Loss: 0.012754, Step Loss: 0.012754, Time: 0.088269
2023-06-01 11:43:35,174:INFO: Epoch: 11/30, Step: 19/32, Lr: 0.001356763, Loss: 0.000056, Step Loss: 0.000056, Time: 0.074517
2023-06-01 11:43:35,267:INFO: Epoch: 11/30, Step: 20/32, Lr: 0.001356763, Loss: 0.000013, Step Loss: 0.000013, Time: 0.092120
2023-06-01 11:43:35,344:INFO: Epoch: 11/30, Step: 21/32, Lr: 0.001356763, Loss: 0.238395, Step Loss: 0.238395, Time: 0.076536
2023-06-01 11:43:35,419:INFO: Epoch: 11/30, Step: 22/32, Lr: 0.001356763, Loss: 0.003427, Step Loss: 0.003427, Time: 0.074170
2023-06-01 11:43:35,494:INFO: Epoch: 11/30, Step: 23/32, Lr: 0.001356763, Loss: 0.023383, Step Loss: 0.023383, Time: 0.074846
2023-06-01 11:43:35,569:INFO: Epoch: 11/30, Step: 24/32, Lr: 0.001356763, Loss: 0.001579, Step Loss: 0.001579, Time: 0.074104
2023-06-01 11:43:35,641:INFO: Epoch: 11/30, Step: 25/32, Lr: 0.001356763, Loss: 0.001309, Step Loss: 0.001309, Time: 0.071586
2023-06-01 11:43:35,724:INFO: Epoch: 11/30, Step: 26/32, Lr: 0.001356763, Loss: 0.124377, Step Loss: 0.124377, Time: 0.082298
2023-06-01 11:43:35,799:INFO: Epoch: 11/30, Step: 27/32, Lr: 0.001356763, Loss: 0.003545, Step Loss: 0.003545, Time: 0.074127
2023-06-01 11:43:35,875:INFO: Epoch: 11/30, Step: 28/32, Lr: 0.001356763, Loss: 0.002084, Step Loss: 0.002084, Time: 0.075314
2023-06-01 11:43:35,944:INFO: Epoch: 11/30, Step: 29/32, Lr: 0.001356763, Loss: 0.000144, Step Loss: 0.000144, Time: 0.068784
2023-06-01 11:43:36,016:INFO: Epoch: 11/30, Step: 30/32, Lr: 0.001356763, Loss: 0.000278, Step Loss: 0.000278, Time: 0.071635
2023-06-01 11:43:36,087:INFO: Epoch: 11/30, Step: 31/32, Lr: 0.001356763, Loss: 0.000845, Step Loss: 0.000845, Time: 0.070679
2023-06-01 11:43:36,159:INFO: Epoch: 11/30, Step: 32/32, Lr: 0.001356763, Loss: 0.000015, Step Loss: 0.000015, Time: 0.070990
2023-06-01 11:43:36,308:INFO: Epoch 11/30 Finished, Train Loss: 0.023004
2023-06-01 11:43:42,981:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10
2023-06-01 11:43:45,898:INFO: Classfication Metrics:
2023-06-01 11:43:45,898:INFO: f1 score: 0.8340 - precision score: 0.7863 - recall score: 0.8879 - accuracy score: 0.861017
2023-06-01 11:43:45,898:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:43:46,983:INFO: Epoch: 12/30, Step: 1/32, Lr: 0.001296726, Loss: 0.132922, Step Loss: 0.132922, Time: 1.060947
2023-06-01 11:43:47,098:INFO: Epoch: 12/30, Step: 2/32, Lr: 0.001296726, Loss: 0.153054, Step Loss: 0.153054, Time: 0.113688
2023-06-01 11:43:47,171:INFO: Epoch: 12/30, Step: 3/32, Lr: 0.001296726, Loss: 0.002833, Step Loss: 0.002833, Time: 0.072412
2023-06-01 11:43:47,250:INFO: Epoch: 12/30, Step: 4/32, Lr: 0.001296726, Loss: 0.001933, Step Loss: 0.001933, Time: 0.078818
2023-06-01 11:43:47,324:INFO: Epoch: 12/30, Step: 5/32, Lr: 0.001296726, Loss: 0.684599, Step Loss: 0.684599, Time: 0.073047
2023-06-01 11:43:47,393:INFO: Epoch: 12/30, Step: 6/32, Lr: 0.001296726, Loss: 0.122920, Step Loss: 0.122920, Time: 0.068710
2023-06-01 11:43:47,467:INFO: Epoch: 12/30, Step: 7/32, Lr: 0.001296726, Loss: 0.004963, Step Loss: 0.004963, Time: 0.073680
2023-06-01 11:43:47,541:INFO: Epoch: 12/30, Step: 8/32, Lr: 0.001296726, Loss: 0.000048, Step Loss: 0.000048, Time: 0.072912
2023-06-01 11:43:47,625:INFO: Epoch: 12/30, Step: 9/32, Lr: 0.001296726, Loss: 0.000015, Step Loss: 0.000015, Time: 0.083654
2023-06-01 11:43:47,703:INFO: Epoch: 12/30, Step: 10/32, Lr: 0.001296726, Loss: 0.066173, Step Loss: 0.066173, Time: 0.077650
2023-06-01 11:43:47,779:INFO: Epoch: 12/30, Step: 11/32, Lr: 0.001296726, Loss: 0.747334, Step Loss: 0.747334, Time: 0.074985
2023-06-01 11:43:47,852:INFO: Epoch: 12/30, Step: 12/32, Lr: 0.001296726, Loss: 0.000703, Step Loss: 0.000703, Time: 0.072527
2023-06-01 11:43:47,927:INFO: Epoch: 12/30, Step: 13/32, Lr: 0.001296726, Loss: 0.003582, Step Loss: 0.003582, Time: 0.074519
2023-06-01 11:43:48,004:INFO: Epoch: 12/30, Step: 14/32, Lr: 0.001296726, Loss: 0.090143, Step Loss: 0.090143, Time: 0.076281
2023-06-01 11:43:48,079:INFO: Epoch: 12/30, Step: 15/32, Lr: 0.001296726, Loss: 0.121591, Step Loss: 0.121591, Time: 0.074900
2023-06-01 11:43:48,160:INFO: Epoch: 12/30, Step: 16/32, Lr: 0.001296726, Loss: 0.253850, Step Loss: 0.253850, Time: 0.079975
2023-06-01 11:43:48,243:INFO: Epoch: 12/30, Step: 17/32, Lr: 0.001296726, Loss: 0.000478, Step Loss: 0.000478, Time: 0.082921
2023-06-01 11:43:48,322:INFO: Epoch: 12/30, Step: 18/32, Lr: 0.001296726, Loss: 0.004372, Step Loss: 0.004372, Time: 0.078849
2023-06-01 11:43:48,401:INFO: Epoch: 12/30, Step: 19/32, Lr: 0.001296726, Loss: 0.000003, Step Loss: 0.000003, Time: 0.077364
2023-06-01 11:43:48,474:INFO: Epoch: 12/30, Step: 20/32, Lr: 0.001296726, Loss: 0.000312, Step Loss: 0.000312, Time: 0.073000
2023-06-01 11:43:48,550:INFO: Epoch: 12/30, Step: 21/32, Lr: 0.001296726, Loss: 0.064664, Step Loss: 0.064664, Time: 0.075555
2023-06-01 11:43:48,626:INFO: Epoch: 12/30, Step: 22/32, Lr: 0.001296726, Loss: 0.000253, Step Loss: 0.000253, Time: 0.075047
2023-06-01 11:43:48,708:INFO: Epoch: 12/30, Step: 23/32, Lr: 0.001296726, Loss: 0.010901, Step Loss: 0.010901, Time: 0.081381
2023-06-01 11:43:48,784:INFO: Epoch: 12/30, Step: 24/32, Lr: 0.001296726, Loss: 0.027863, Step Loss: 0.027863, Time: 0.075934
2023-06-01 11:43:48,854:INFO: Epoch: 12/30, Step: 25/32, Lr: 0.001296726, Loss: 0.133386, Step Loss: 0.133386, Time: 0.068852
2023-06-01 11:43:48,931:INFO: Epoch: 12/30, Step: 26/32, Lr: 0.001296726, Loss: 0.064060, Step Loss: 0.064060, Time: 0.076592
2023-06-01 11:43:49,004:INFO: Epoch: 12/30, Step: 27/32, Lr: 0.001296726, Loss: 0.000251, Step Loss: 0.000251, Time: 0.072651
2023-06-01 11:43:49,080:INFO: Epoch: 12/30, Step: 28/32, Lr: 0.001296726, Loss: 0.211867, Step Loss: 0.211867, Time: 0.075162
2023-06-01 11:43:49,156:INFO: Epoch: 12/30, Step: 29/32, Lr: 0.001296726, Loss: 0.001942, Step Loss: 0.001942, Time: 0.075111
2023-06-01 11:43:49,232:INFO: Epoch: 12/30, Step: 30/32, Lr: 0.001296726, Loss: 0.268018, Step Loss: 0.268018, Time: 0.075820
2023-06-01 11:43:49,311:INFO: Epoch: 12/30, Step: 31/32, Lr: 0.001296726, Loss: 0.093881, Step Loss: 0.093881, Time: 0.078380
2023-06-01 11:43:49,386:INFO: Epoch: 12/30, Step: 32/32, Lr: 0.001296726, Loss: 0.000027, Step Loss: 0.000027, Time: 0.074893
2023-06-01 11:43:49,506:INFO: Epoch 12/30 Finished, Train Loss: 0.102154
2023-06-01 11:44:02,908:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.11
2023-06-01 11:44:05,823:INFO: Classfication Metrics:
2023-06-01 11:44:05,823:INFO: f1 score: 0.8505 - precision score: 0.9286 - recall score: 0.7845 - accuracy score: 0.891525
2023-06-01 11:44:05,823:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:44:06,891:INFO: Epoch: 13/30, Step: 1/32, Lr: 0.001228068, Loss: 0.001715, Step Loss: 0.001715, Time: 1.056831
2023-06-01 11:44:06,967:INFO: Epoch: 13/30, Step: 2/32, Lr: 0.001228068, Loss: 0.000458, Step Loss: 0.000458, Time: 0.075125
2023-06-01 11:44:07,239:INFO: Epoch: 13/30, Step: 3/32, Lr: 0.001228068, Loss: 0.001007, Step Loss: 0.001007, Time: 0.271104
2023-06-01 11:44:07,312:INFO: Epoch: 13/30, Step: 4/32, Lr: 0.001228068, Loss: 0.001349, Step Loss: 0.001349, Time: 0.072802
2023-06-01 11:44:07,387:INFO: Epoch: 13/30, Step: 5/32, Lr: 0.001228068, Loss: 0.001453, Step Loss: 0.001453, Time: 0.073841
2023-06-01 11:44:07,459:INFO: Epoch: 13/30, Step: 6/32, Lr: 0.001228068, Loss: 0.000018, Step Loss: 0.000018, Time: 0.071689
2023-06-01 11:44:07,532:INFO: Epoch: 13/30, Step: 7/32, Lr: 0.001228068, Loss: 0.008775, Step Loss: 0.008775, Time: 0.072391
2023-06-01 11:44:07,606:INFO: Epoch: 13/30, Step: 8/32, Lr: 0.001228068, Loss: 0.003531, Step Loss: 0.003531, Time: 0.074123
2023-06-01 11:44:07,691:INFO: Epoch: 13/30, Step: 9/32, Lr: 0.001228068, Loss: 0.000319, Step Loss: 0.000319, Time: 0.084415
2023-06-01 11:44:07,773:INFO: Epoch: 13/30, Step: 10/32, Lr: 0.001228068, Loss: 0.001854, Step Loss: 0.001854, Time: 0.080663
2023-06-01 11:44:07,852:INFO: Epoch: 13/30, Step: 11/32, Lr: 0.001228068, Loss: 0.000124, Step Loss: 0.000124, Time: 0.078211
2023-06-01 11:44:07,935:INFO: Epoch: 13/30, Step: 12/32, Lr: 0.001228068, Loss: 0.101944, Step Loss: 0.101944, Time: 0.082689
2023-06-01 11:44:08,014:INFO: Epoch: 13/30, Step: 13/32, Lr: 0.001228068, Loss: 0.000401, Step Loss: 0.000401, Time: 0.078709
2023-06-01 11:44:08,096:INFO: Epoch: 13/30, Step: 14/32, Lr: 0.001228068, Loss: 0.047477, Step Loss: 0.047477, Time: 0.081177
2023-06-01 11:44:08,171:INFO: Epoch: 13/30, Step: 15/32, Lr: 0.001228068, Loss: 0.061690, Step Loss: 0.061690, Time: 0.074559
2023-06-01 11:44:08,253:INFO: Epoch: 13/30, Step: 16/32, Lr: 0.001228068, Loss: 0.001855, Step Loss: 0.001855, Time: 0.081176
2023-06-01 11:44:08,335:INFO: Epoch: 13/30, Step: 17/32, Lr: 0.001228068, Loss: 0.000079, Step Loss: 0.000079, Time: 0.082237
2023-06-01 11:44:08,414:INFO: Epoch: 13/30, Step: 18/32, Lr: 0.001228068, Loss: 0.000271, Step Loss: 0.000271, Time: 0.078296
2023-06-01 11:44:08,484:INFO: Epoch: 13/30, Step: 19/32, Lr: 0.001228068, Loss: 0.000033, Step Loss: 0.000033, Time: 0.068637
2023-06-01 11:44:08,553:INFO: Epoch: 13/30, Step: 20/32, Lr: 0.001228068, Loss: 0.000235, Step Loss: 0.000235, Time: 0.069026
2023-06-01 11:44:08,627:INFO: Epoch: 13/30, Step: 21/32, Lr: 0.001228068, Loss: 0.050123, Step Loss: 0.050123, Time: 0.073635
2023-06-01 11:44:08,697:INFO: Epoch: 13/30, Step: 22/32, Lr: 0.001228068, Loss: 0.000332, Step Loss: 0.000332, Time: 0.068868
2023-06-01 11:44:08,774:INFO: Epoch: 13/30, Step: 23/32, Lr: 0.001228068, Loss: 0.000030, Step Loss: 0.000030, Time: 0.076136
2023-06-01 11:44:08,853:INFO: Epoch: 13/30, Step: 24/32, Lr: 0.001228068, Loss: 0.000039, Step Loss: 0.000039, Time: 0.078545
2023-06-01 11:44:08,939:INFO: Epoch: 13/30, Step: 25/32, Lr: 0.001228068, Loss: 0.000824, Step Loss: 0.000824, Time: 0.085791
2023-06-01 11:44:09,011:INFO: Epoch: 13/30, Step: 26/32, Lr: 0.001228068, Loss: 0.007146, Step Loss: 0.007146, Time: 0.071486
2023-06-01 11:44:09,083:INFO: Epoch: 13/30, Step: 27/32, Lr: 0.001228068, Loss: 0.011826, Step Loss: 0.011826, Time: 0.071805
2023-06-01 11:44:09,156:INFO: Epoch: 13/30, Step: 28/32, Lr: 0.001228068, Loss: 0.032896, Step Loss: 0.032896, Time: 0.072048
2023-06-01 11:44:09,235:INFO: Epoch: 13/30, Step: 29/32, Lr: 0.001228068, Loss: 0.000139, Step Loss: 0.000139, Time: 0.079302
2023-06-01 11:44:09,312:INFO: Epoch: 13/30, Step: 30/32, Lr: 0.001228068, Loss: 0.082862, Step Loss: 0.082862, Time: 0.075993
2023-06-01 11:44:09,389:INFO: Epoch: 13/30, Step: 31/32, Lr: 0.001228068, Loss: 0.183050, Step Loss: 0.183050, Time: 0.076998
2023-06-01 11:44:09,467:INFO: Epoch: 13/30, Step: 32/32, Lr: 0.001228068, Loss: 0.002247, Step Loss: 0.002247, Time: 0.077947
2023-06-01 11:44:09,599:INFO: Epoch 13/30 Finished, Train Loss: 0.018941
2023-06-01 11:44:15,632:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.12
2023-06-01 11:44:18,488:INFO: Classfication Metrics:
2023-06-01 11:44:18,488:INFO: f1 score: 0.8707 - precision score: 0.8707 - recall score: 0.8707 - accuracy score: 0.898305
2023-06-01 11:44:18,489:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:44:19,534:INFO: Epoch: 14/30, Step: 1/32, Lr: 0.001151870, Loss: 0.000024, Step Loss: 0.000024, Time: 1.021130
2023-06-01 11:44:19,615:INFO: Epoch: 14/30, Step: 2/32, Lr: 0.001151870, Loss: 0.000343, Step Loss: 0.000343, Time: 0.079826
2023-06-01 11:44:19,714:INFO: Epoch: 14/30, Step: 3/32, Lr: 0.001151870, Loss: 0.000007, Step Loss: 0.000007, Time: 0.098770
2023-06-01 11:44:19,824:INFO: Epoch: 14/30, Step: 4/32, Lr: 0.001151870, Loss: 0.006331, Step Loss: 0.006331, Time: 0.109684
2023-06-01 11:44:19,899:INFO: Epoch: 14/30, Step: 5/32, Lr: 0.001151870, Loss: 0.000016, Step Loss: 0.000016, Time: 0.074203
2023-06-01 11:44:19,978:INFO: Epoch: 14/30, Step: 6/32, Lr: 0.001151870, Loss: 0.007451, Step Loss: 0.007451, Time: 0.078628
2023-06-01 11:44:20,059:INFO: Epoch: 14/30, Step: 7/32, Lr: 0.001151870, Loss: 0.000018, Step Loss: 0.000018, Time: 0.079749
2023-06-01 11:44:20,137:INFO: Epoch: 14/30, Step: 8/32, Lr: 0.001151870, Loss: 0.000694, Step Loss: 0.000694, Time: 0.078089
2023-06-01 11:44:20,215:INFO: Epoch: 14/30, Step: 9/32, Lr: 0.001151870, Loss: 0.000289, Step Loss: 0.000289, Time: 0.077361
2023-06-01 11:44:20,301:INFO: Epoch: 14/30, Step: 10/32, Lr: 0.001151870, Loss: 0.000142, Step Loss: 0.000142, Time: 0.084936
2023-06-01 11:44:20,393:INFO: Epoch: 14/30, Step: 11/32, Lr: 0.001151870, Loss: 0.000102, Step Loss: 0.000102, Time: 0.092240
2023-06-01 11:44:20,471:INFO: Epoch: 14/30, Step: 12/32, Lr: 0.001151870, Loss: 0.000007, Step Loss: 0.000007, Time: 0.077585
2023-06-01 11:44:20,550:INFO: Epoch: 14/30, Step: 13/32, Lr: 0.001151870, Loss: 0.000351, Step Loss: 0.000351, Time: 0.078641
2023-06-01 11:44:20,625:INFO: Epoch: 14/30, Step: 14/32, Lr: 0.001151870, Loss: 0.000055, Step Loss: 0.000055, Time: 0.074679
2023-06-01 11:44:20,707:INFO: Epoch: 14/30, Step: 15/32, Lr: 0.001151870, Loss: 0.000160, Step Loss: 0.000160, Time: 0.080896
2023-06-01 11:44:20,787:INFO: Epoch: 14/30, Step: 16/32, Lr: 0.001151870, Loss: 0.000482, Step Loss: 0.000482, Time: 0.079913
2023-06-01 11:44:20,866:INFO: Epoch: 14/30, Step: 17/32, Lr: 0.001151870, Loss: 0.000031, Step Loss: 0.000031, Time: 0.078088
2023-06-01 11:44:20,947:INFO: Epoch: 14/30, Step: 18/32, Lr: 0.001151870, Loss: 0.000476, Step Loss: 0.000476, Time: 0.080839
2023-06-01 11:44:21,035:INFO: Epoch: 14/30, Step: 19/32, Lr: 0.001151870, Loss: 0.000001, Step Loss: 0.000001, Time: 0.086834
2023-06-01 11:44:21,107:INFO: Epoch: 14/30, Step: 20/32, Lr: 0.001151870, Loss: 0.000294, Step Loss: 0.000294, Time: 0.072080
2023-06-01 11:44:21,189:INFO: Epoch: 14/30, Step: 21/32, Lr: 0.001151870, Loss: 0.000099, Step Loss: 0.000099, Time: 0.080919
2023-06-01 11:44:21,267:INFO: Epoch: 14/30, Step: 22/32, Lr: 0.001151870, Loss: 0.000016, Step Loss: 0.000016, Time: 0.077749
2023-06-01 11:44:21,342:INFO: Epoch: 14/30, Step: 23/32, Lr: 0.001151870, Loss: 0.000813, Step Loss: 0.000813, Time: 0.074461
2023-06-01 11:44:21,434:INFO: Epoch: 14/30, Step: 24/32, Lr: 0.001151870, Loss: 0.000028, Step Loss: 0.000028, Time: 0.092311
2023-06-01 11:44:21,507:INFO: Epoch: 14/30, Step: 25/32, Lr: 0.001151870, Loss: 0.000002, Step Loss: 0.000002, Time: 0.072206
2023-06-01 11:44:21,584:INFO: Epoch: 14/30, Step: 26/32, Lr: 0.001151870, Loss: 0.001239, Step Loss: 0.001239, Time: 0.076587
2023-06-01 11:44:21,677:INFO: Epoch: 14/30, Step: 27/32, Lr: 0.001151870, Loss: 0.000012, Step Loss: 0.000012, Time: 0.093210
2023-06-01 11:44:21,751:INFO: Epoch: 14/30, Step: 28/32, Lr: 0.001151870, Loss: 0.000211, Step Loss: 0.000211, Time: 0.073201
2023-06-01 11:44:21,835:INFO: Epoch: 14/30, Step: 29/32, Lr: 0.001151870, Loss: 0.000070, Step Loss: 0.000070, Time: 0.083673
2023-06-01 11:44:21,905:INFO: Epoch: 14/30, Step: 30/32, Lr: 0.001151870, Loss: 0.007214, Step Loss: 0.007214, Time: 0.069496
2023-06-01 11:44:21,984:INFO: Epoch: 14/30, Step: 31/32, Lr: 0.001151870, Loss: 0.000008, Step Loss: 0.000008, Time: 0.078159
2023-06-01 11:44:22,065:INFO: Epoch: 14/30, Step: 32/32, Lr: 0.001151870, Loss: 0.000001, Step Loss: 0.000001, Time: 0.079857
2023-06-01 11:44:22,195:INFO: Epoch 14/30 Finished, Train Loss: 0.000843
2023-06-01 11:44:30,005:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.13
2023-06-01 11:44:32,867:INFO: Classfication Metrics:
2023-06-01 11:44:32,867:INFO: f1 score: 0.8761 - precision score: 0.9000 - recall score: 0.8534 - accuracy score: 0.905085
2023-06-01 11:44:32,867:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:44:33,836:INFO: Epoch: 15/30, Step: 1/32, Lr: 0.001069334, Loss: 0.000490, Step Loss: 0.000490, Time: 0.941562
2023-06-01 11:44:34,018:INFO: Epoch: 15/30, Step: 2/32, Lr: 0.001069334, Loss: 0.000005, Step Loss: 0.000005, Time: 0.182278
2023-06-01 11:44:34,091:INFO: Epoch: 15/30, Step: 3/32, Lr: 0.001069334, Loss: 0.012832, Step Loss: 0.012832, Time: 0.072440
2023-06-01 11:44:34,165:INFO: Epoch: 15/30, Step: 4/32, Lr: 0.001069334, Loss: 0.000121, Step Loss: 0.000121, Time: 0.072607
2023-06-01 11:44:34,237:INFO: Epoch: 15/30, Step: 5/32, Lr: 0.001069334, Loss: 0.000269, Step Loss: 0.000269, Time: 0.071777
2023-06-01 11:44:34,310:INFO: Epoch: 15/30, Step: 6/32, Lr: 0.001069334, Loss: 0.000005, Step Loss: 0.000005, Time: 0.072469
2023-06-01 11:44:34,384:INFO: Epoch: 15/30, Step: 7/32, Lr: 0.001069334, Loss: 0.001300, Step Loss: 0.001300, Time: 0.073598
2023-06-01 11:44:34,458:INFO: Epoch: 15/30, Step: 8/32, Lr: 0.001069334, Loss: 0.000050, Step Loss: 0.000050, Time: 0.073394
2023-06-01 11:44:34,554:INFO: Epoch: 15/30, Step: 9/32, Lr: 0.001069334, Loss: 0.005054, Step Loss: 0.005054, Time: 0.094843
2023-06-01 11:44:34,628:INFO: Epoch: 15/30, Step: 10/32, Lr: 0.001069334, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073558
2023-06-01 11:44:34,700:INFO: Epoch: 15/30, Step: 11/32, Lr: 0.001069334, Loss: 0.000139, Step Loss: 0.000139, Time: 0.071584
2023-06-01 11:44:34,772:INFO: Epoch: 15/30, Step: 12/32, Lr: 0.001069334, Loss: 0.000016, Step Loss: 0.000016, Time: 0.071960
2023-06-01 11:44:34,847:INFO: Epoch: 15/30, Step: 13/32, Lr: 0.001069334, Loss: 0.000003, Step Loss: 0.000003, Time: 0.073875
2023-06-01 11:44:34,920:INFO: Epoch: 15/30, Step: 14/32, Lr: 0.001069334, Loss: 0.000009, Step Loss: 0.000009, Time: 0.072579
2023-06-01 11:44:35,000:INFO: Epoch: 15/30, Step: 15/32, Lr: 0.001069334, Loss: 0.000469, Step Loss: 0.000469, Time: 0.078887
2023-06-01 11:44:35,079:INFO: Epoch: 15/30, Step: 16/32, Lr: 0.001069334, Loss: 0.000069, Step Loss: 0.000069, Time: 0.078528
2023-06-01 11:44:35,172:INFO: Epoch: 15/30, Step: 17/32, Lr: 0.001069334, Loss: 0.012248, Step Loss: 0.012248, Time: 0.092935
2023-06-01 11:44:35,247:INFO: Epoch: 15/30, Step: 18/32, Lr: 0.001069334, Loss: 0.000811, Step Loss: 0.000811, Time: 0.074118
2023-06-01 11:44:35,320:INFO: Epoch: 15/30, Step: 19/32, Lr: 0.001069334, Loss: 0.002972, Step Loss: 0.002972, Time: 0.072315
2023-06-01 11:44:35,393:INFO: Epoch: 15/30, Step: 20/32, Lr: 0.001069334, Loss: 0.000236, Step Loss: 0.000236, Time: 0.072521
2023-06-01 11:44:35,467:INFO: Epoch: 15/30, Step: 21/32, Lr: 0.001069334, Loss: 0.000002, Step Loss: 0.000002, Time: 0.073636
2023-06-01 11:44:35,540:INFO: Epoch: 15/30, Step: 22/32, Lr: 0.001069334, Loss: 0.002876, Step Loss: 0.002876, Time: 0.071896
2023-06-01 11:44:35,609:INFO: Epoch: 15/30, Step: 23/32, Lr: 0.001069334, Loss: 0.029108, Step Loss: 0.029108, Time: 0.068833
2023-06-01 11:44:35,687:INFO: Epoch: 15/30, Step: 24/32, Lr: 0.001069334, Loss: 0.000024, Step Loss: 0.000024, Time: 0.077163
2023-06-01 11:44:35,770:INFO: Epoch: 15/30, Step: 25/32, Lr: 0.001069334, Loss: 0.000165, Step Loss: 0.000165, Time: 0.082677
2023-06-01 11:44:35,852:INFO: Epoch: 15/30, Step: 26/32, Lr: 0.001069334, Loss: 0.000072, Step Loss: 0.000072, Time: 0.081782
2023-06-01 11:44:35,936:INFO: Epoch: 15/30, Step: 27/32, Lr: 0.001069334, Loss: 0.000002, Step Loss: 0.000002, Time: 0.083228
2023-06-01 11:44:36,011:INFO: Epoch: 15/30, Step: 28/32, Lr: 0.001069334, Loss: 0.000041, Step Loss: 0.000041, Time: 0.074876
2023-06-01 11:44:36,084:INFO: Epoch: 15/30, Step: 29/32, Lr: 0.001069334, Loss: 0.000011, Step Loss: 0.000011, Time: 0.072825
2023-06-01 11:44:36,164:INFO: Epoch: 15/30, Step: 30/32, Lr: 0.001069334, Loss: 0.000277, Step Loss: 0.000277, Time: 0.079237
2023-06-01 11:44:36,239:INFO: Epoch: 15/30, Step: 31/32, Lr: 0.001069334, Loss: 0.002383, Step Loss: 0.002383, Time: 0.074970
2023-06-01 11:44:36,322:INFO: Epoch: 15/30, Step: 32/32, Lr: 0.001069334, Loss: 0.000350, Step Loss: 0.000350, Time: 0.082445
2023-06-01 11:44:36,472:INFO: Epoch 15/30 Finished, Train Loss: 0.002263
2023-06-01 11:44:47,391:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.14
2023-06-01 11:44:50,240:INFO: Classfication Metrics:
2023-06-01 11:44:50,240:INFO: f1 score: 0.8776 - precision score: 0.8595 - recall score: 0.8966 - accuracy score: 0.901695
2023-06-01 11:44:50,240:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:44:51,340:INFO: Epoch: 16/30, Step: 1/32, Lr: 0.000981763, Loss: 0.000037, Step Loss: 0.000037, Time: 1.090824
2023-06-01 11:44:51,416:INFO: Epoch: 16/30, Step: 2/32, Lr: 0.000981763, Loss: 0.000091, Step Loss: 0.000091, Time: 0.076268
2023-06-01 11:44:51,498:INFO: Epoch: 16/30, Step: 3/32, Lr: 0.000981763, Loss: 0.003088, Step Loss: 0.003088, Time: 0.080932
2023-06-01 11:44:51,577:INFO: Epoch: 16/30, Step: 4/32, Lr: 0.000981763, Loss: 0.000047, Step Loss: 0.000047, Time: 0.079000
2023-06-01 11:44:51,652:INFO: Epoch: 16/30, Step: 5/32, Lr: 0.000981763, Loss: 0.002216, Step Loss: 0.002216, Time: 0.073919
2023-06-01 11:44:51,731:INFO: Epoch: 16/30, Step: 6/32, Lr: 0.000981763, Loss: 0.000344, Step Loss: 0.000344, Time: 0.078310
2023-06-01 11:44:51,810:INFO: Epoch: 16/30, Step: 7/32, Lr: 0.000981763, Loss: 0.000008, Step Loss: 0.000008, Time: 0.078997
2023-06-01 11:44:51,893:INFO: Epoch: 16/30, Step: 8/32, Lr: 0.000981763, Loss: 0.000091, Step Loss: 0.000091, Time: 0.082304
2023-06-01 11:44:51,984:INFO: Epoch: 16/30, Step: 9/32, Lr: 0.000981763, Loss: 0.000123, Step Loss: 0.000123, Time: 0.090271
2023-06-01 11:44:52,056:INFO: Epoch: 16/30, Step: 10/32, Lr: 0.000981763, Loss: 0.000559, Step Loss: 0.000559, Time: 0.071682
2023-06-01 11:44:52,132:INFO: Epoch: 16/30, Step: 11/32, Lr: 0.000981763, Loss: 0.000002, Step Loss: 0.000002, Time: 0.075072
2023-06-01 11:44:52,211:INFO: Epoch: 16/30, Step: 12/32, Lr: 0.000981763, Loss: 0.000035, Step Loss: 0.000035, Time: 0.078670
2023-06-01 11:44:52,287:INFO: Epoch: 16/30, Step: 13/32, Lr: 0.000981763, Loss: 0.000567, Step Loss: 0.000567, Time: 0.075342
2023-06-01 11:44:52,366:INFO: Epoch: 16/30, Step: 14/32, Lr: 0.000981763, Loss: 0.000102, Step Loss: 0.000102, Time: 0.077997
2023-06-01 11:44:52,451:INFO: Epoch: 16/30, Step: 15/32, Lr: 0.000981763, Loss: 0.002315, Step Loss: 0.002315, Time: 0.084365
2023-06-01 11:44:52,527:INFO: Epoch: 16/30, Step: 16/32, Lr: 0.000981763, Loss: 0.001298, Step Loss: 0.001298, Time: 0.075551
2023-06-01 11:44:52,607:INFO: Epoch: 16/30, Step: 17/32, Lr: 0.000981763, Loss: 0.000003, Step Loss: 0.000003, Time: 0.079607
2023-06-01 11:44:52,683:INFO: Epoch: 16/30, Step: 18/32, Lr: 0.000981763, Loss: 0.000239, Step Loss: 0.000239, Time: 0.075501
2023-06-01 11:44:52,767:INFO: Epoch: 16/30, Step: 19/32, Lr: 0.000981763, Loss: 0.000010, Step Loss: 0.000010, Time: 0.083503
2023-06-01 11:44:52,841:INFO: Epoch: 16/30, Step: 20/32, Lr: 0.000981763, Loss: 0.000787, Step Loss: 0.000787, Time: 0.073233
2023-06-01 11:44:52,910:INFO: Epoch: 16/30, Step: 21/32, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068622
2023-06-01 11:44:53,001:INFO: Epoch: 16/30, Step: 22/32, Lr: 0.000981763, Loss: 0.000031, Step Loss: 0.000031, Time: 0.089823
2023-06-01 11:44:53,080:INFO: Epoch: 16/30, Step: 23/32, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.078645
2023-06-01 11:44:53,154:INFO: Epoch: 16/30, Step: 24/32, Lr: 0.000981763, Loss: 0.000148, Step Loss: 0.000148, Time: 0.073672
2023-06-01 11:44:53,235:INFO: Epoch: 16/30, Step: 25/32, Lr: 0.000981763, Loss: 0.002038, Step Loss: 0.002038, Time: 0.081095
2023-06-01 11:44:53,316:INFO: Epoch: 16/30, Step: 26/32, Lr: 0.000981763, Loss: 0.000010, Step Loss: 0.000010, Time: 0.080625
2023-06-01 11:44:53,388:INFO: Epoch: 16/30, Step: 27/32, Lr: 0.000981763, Loss: 0.000102, Step Loss: 0.000102, Time: 0.071350
2023-06-01 11:44:53,464:INFO: Epoch: 16/30, Step: 28/32, Lr: 0.000981763, Loss: 0.000013, Step Loss: 0.000013, Time: 0.075554
2023-06-01 11:44:53,546:INFO: Epoch: 16/30, Step: 29/32, Lr: 0.000981763, Loss: 0.000004, Step Loss: 0.000004, Time: 0.081547
2023-06-01 11:44:53,618:INFO: Epoch: 16/30, Step: 30/32, Lr: 0.000981763, Loss: 0.000002, Step Loss: 0.000002, Time: 0.072273
2023-06-01 11:44:53,691:INFO: Epoch: 16/30, Step: 31/32, Lr: 0.000981763, Loss: 0.000021, Step Loss: 0.000021, Time: 0.072457
2023-06-01 11:44:53,773:INFO: Epoch: 16/30, Step: 32/32, Lr: 0.000981763, Loss: 0.000037, Step Loss: 0.000037, Time: 0.081867
2023-06-01 11:44:53,903:INFO: Epoch 16/30 Finished, Train Loss: 0.000449
2023-06-01 11:45:00,901:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15
2023-06-01 11:45:03,780:INFO: Classfication Metrics:
2023-06-01 11:45:03,780:INFO: f1 score: 0.8722 - precision score: 0.8919 - recall score: 0.8534 - accuracy score: 0.901695
2023-06-01 11:45:03,780:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:45:04,929:INFO: Epoch: 17/30, Step: 1/32, Lr: 0.000890536, Loss: 0.000121, Step Loss: 0.000121, Time: 1.140539
2023-06-01 11:45:05,004:INFO: Epoch: 17/30, Step: 2/32, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074577
2023-06-01 11:45:05,083:INFO: Epoch: 17/30, Step: 3/32, Lr: 0.000890536, Loss: 0.000209, Step Loss: 0.000209, Time: 0.077646
2023-06-01 11:45:05,157:INFO: Epoch: 17/30, Step: 4/32, Lr: 0.000890536, Loss: 0.000151, Step Loss: 0.000151, Time: 0.074337
2023-06-01 11:45:05,232:INFO: Epoch: 17/30, Step: 5/32, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074258
2023-06-01 11:45:05,315:INFO: Epoch: 17/30, Step: 6/32, Lr: 0.000890536, Loss: 0.000053, Step Loss: 0.000053, Time: 0.082084
2023-06-01 11:45:05,390:INFO: Epoch: 17/30, Step: 7/32, Lr: 0.000890536, Loss: 0.000098, Step Loss: 0.000098, Time: 0.074010
2023-06-01 11:45:05,475:INFO: Epoch: 17/30, Step: 8/32, Lr: 0.000890536, Loss: 0.000310, Step Loss: 0.000310, Time: 0.084698
2023-06-01 11:45:05,568:INFO: Epoch: 17/30, Step: 9/32, Lr: 0.000890536, Loss: 0.000003, Step Loss: 0.000003, Time: 0.092676
2023-06-01 11:45:05,645:INFO: Epoch: 17/30, Step: 10/32, Lr: 0.000890536, Loss: 0.000049, Step Loss: 0.000049, Time: 0.075932
2023-06-01 11:45:05,726:INFO: Epoch: 17/30, Step: 11/32, Lr: 0.000890536, Loss: 0.001262, Step Loss: 0.001262, Time: 0.081118
2023-06-01 11:45:05,800:INFO: Epoch: 17/30, Step: 12/32, Lr: 0.000890536, Loss: 0.000053, Step Loss: 0.000053, Time: 0.073044
2023-06-01 11:45:05,879:INFO: Epoch: 17/30, Step: 13/32, Lr: 0.000890536, Loss: 0.000078, Step Loss: 0.000078, Time: 0.078722
2023-06-01 11:45:05,956:INFO: Epoch: 17/30, Step: 14/32, Lr: 0.000890536, Loss: 0.040010, Step Loss: 0.040010, Time: 0.075992
2023-06-01 11:45:06,039:INFO: Epoch: 17/30, Step: 15/32, Lr: 0.000890536, Loss: 0.000017, Step Loss: 0.000017, Time: 0.082613
2023-06-01 11:45:06,127:INFO: Epoch: 17/30, Step: 16/32, Lr: 0.000890536, Loss: 0.001294, Step Loss: 0.001294, Time: 0.086981
2023-06-01 11:45:06,206:INFO: Epoch: 17/30, Step: 17/32, Lr: 0.000890536, Loss: 0.000002, Step Loss: 0.000002, Time: 0.078940
2023-06-01 11:45:06,296:INFO: Epoch: 17/30, Step: 18/32, Lr: 0.000890536, Loss: 0.000034, Step Loss: 0.000034, Time: 0.089628
2023-06-01 11:45:06,371:INFO: Epoch: 17/30, Step: 19/32, Lr: 0.000890536, Loss: 0.000018, Step Loss: 0.000018, Time: 0.074131
2023-06-01 11:45:06,444:INFO: Epoch: 17/30, Step: 20/32, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.072904
2023-06-01 11:45:06,517:INFO: Epoch: 17/30, Step: 21/32, Lr: 0.000890536, Loss: 0.000003, Step Loss: 0.000003, Time: 0.072399
2023-06-01 11:45:06,595:INFO: Epoch: 17/30, Step: 22/32, Lr: 0.000890536, Loss: 0.000045, Step Loss: 0.000045, Time: 0.076557
2023-06-01 11:45:06,669:INFO: Epoch: 17/30, Step: 23/32, Lr: 0.000890536, Loss: 0.000179, Step Loss: 0.000179, Time: 0.074091
2023-06-01 11:45:06,758:INFO: Epoch: 17/30, Step: 24/32, Lr: 0.000890536, Loss: 0.000340, Step Loss: 0.000340, Time: 0.087734
2023-06-01 11:45:06,836:INFO: Epoch: 17/30, Step: 25/32, Lr: 0.000890536, Loss: 0.014643, Step Loss: 0.014643, Time: 0.077358
2023-06-01 11:45:06,913:INFO: Epoch: 17/30, Step: 26/32, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076756
2023-06-01 11:45:06,991:INFO: Epoch: 17/30, Step: 27/32, Lr: 0.000890536, Loss: 0.000362, Step Loss: 0.000362, Time: 0.077187
2023-06-01 11:45:07,061:INFO: Epoch: 17/30, Step: 28/32, Lr: 0.000890536, Loss: 0.006120, Step Loss: 0.006120, Time: 0.069248
2023-06-01 11:45:07,142:INFO: Epoch: 17/30, Step: 29/32, Lr: 0.000890536, Loss: 0.001824, Step Loss: 0.001824, Time: 0.080883
2023-06-01 11:45:07,224:INFO: Epoch: 17/30, Step: 30/32, Lr: 0.000890536, Loss: 0.000008, Step Loss: 0.000008, Time: 0.080901
2023-06-01 11:45:07,296:INFO: Epoch: 17/30, Step: 31/32, Lr: 0.000890536, Loss: 0.090579, Step Loss: 0.090579, Time: 0.072193
2023-06-01 11:45:07,379:INFO: Epoch: 17/30, Step: 32/32, Lr: 0.000890536, Loss: 0.000033, Step Loss: 0.000033, Time: 0.082211
2023-06-01 11:45:07,518:INFO: Epoch 17/30 Finished, Train Loss: 0.004934
2023-06-01 11:45:15,421:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.16
2023-06-01 11:45:18,249:INFO: Classfication Metrics:
2023-06-01 11:45:18,249:INFO: f1 score: 0.8700 - precision score: 0.9065 - recall score: 0.8362 - accuracy score: 0.901695
2023-06-01 11:45:18,249:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:45:19,297:INFO: Epoch: 18/30, Step: 1/32, Lr: 0.000797093, Loss: 0.000001, Step Loss: 0.000001, Time: 1.038909
2023-06-01 11:45:19,424:INFO: Epoch: 18/30, Step: 2/32, Lr: 0.000797093, Loss: 0.000026, Step Loss: 0.000026, Time: 0.126464
2023-06-01 11:45:19,508:INFO: Epoch: 18/30, Step: 3/32, Lr: 0.000797093, Loss: 0.006459, Step Loss: 0.006459, Time: 0.083407
2023-06-01 11:45:19,584:INFO: Epoch: 18/30, Step: 4/32, Lr: 0.000797093, Loss: 0.000008, Step Loss: 0.000008, Time: 0.075586
2023-06-01 11:45:19,664:INFO: Epoch: 18/30, Step: 5/32, Lr: 0.000797093, Loss: 0.000046, Step Loss: 0.000046, Time: 0.079104
2023-06-01 11:45:19,742:INFO: Epoch: 18/30, Step: 6/32, Lr: 0.000797093, Loss: 0.034512, Step Loss: 0.034512, Time: 0.077204
2023-06-01 11:45:19,824:INFO: Epoch: 18/30, Step: 7/32, Lr: 0.000797093, Loss: 0.000658, Step Loss: 0.000658, Time: 0.081572
2023-06-01 11:45:19,900:INFO: Epoch: 18/30, Step: 8/32, Lr: 0.000797093, Loss: 0.000037, Step Loss: 0.000037, Time: 0.075213
2023-06-01 11:45:19,977:INFO: Epoch: 18/30, Step: 9/32, Lr: 0.000797093, Loss: 0.007957, Step Loss: 0.007957, Time: 0.076345
2023-06-01 11:45:20,051:INFO: Epoch: 18/30, Step: 10/32, Lr: 0.000797093, Loss: 0.000487, Step Loss: 0.000487, Time: 0.073861
2023-06-01 11:45:20,128:INFO: Epoch: 18/30, Step: 11/32, Lr: 0.000797093, Loss: 0.000066, Step Loss: 0.000066, Time: 0.076271
2023-06-01 11:45:20,214:INFO: Epoch: 18/30, Step: 12/32, Lr: 0.000797093, Loss: 0.000001, Step Loss: 0.000001, Time: 0.085258
2023-06-01 11:45:20,294:INFO: Epoch: 18/30, Step: 13/32, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079405
2023-06-01 11:45:20,367:INFO: Epoch: 18/30, Step: 14/32, Lr: 0.000797093, Loss: 0.017652, Step Loss: 0.017652, Time: 0.072778
2023-06-01 11:45:20,436:INFO: Epoch: 18/30, Step: 15/32, Lr: 0.000797093, Loss: 0.000246, Step Loss: 0.000246, Time: 0.068076
2023-06-01 11:45:20,505:INFO: Epoch: 18/30, Step: 16/32, Lr: 0.000797093, Loss: 0.002152, Step Loss: 0.002152, Time: 0.069186
2023-06-01 11:45:20,593:INFO: Epoch: 18/30, Step: 17/32, Lr: 0.000797093, Loss: 0.000009, Step Loss: 0.000009, Time: 0.086740
2023-06-01 11:45:20,670:INFO: Epoch: 18/30, Step: 18/32, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076800
2023-06-01 11:45:20,756:INFO: Epoch: 18/30, Step: 19/32, Lr: 0.000797093, Loss: 0.119967, Step Loss: 0.119967, Time: 0.085622
2023-06-01 11:45:20,829:INFO: Epoch: 18/30, Step: 20/32, Lr: 0.000797093, Loss: 0.000004, Step Loss: 0.000004, Time: 0.071763
2023-06-01 11:45:20,902:INFO: Epoch: 18/30, Step: 21/32, Lr: 0.000797093, Loss: 0.000028, Step Loss: 0.000028, Time: 0.073170
2023-06-01 11:45:20,983:INFO: Epoch: 18/30, Step: 22/32, Lr: 0.000797093, Loss: 0.000122, Step Loss: 0.000122, Time: 0.080515
2023-06-01 11:45:21,062:INFO: Epoch: 18/30, Step: 23/32, Lr: 0.000797093, Loss: 0.034368, Step Loss: 0.034368, Time: 0.077760
2023-06-01 11:45:21,139:INFO: Epoch: 18/30, Step: 24/32, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076498
2023-06-01 11:45:21,223:INFO: Epoch: 18/30, Step: 25/32, Lr: 0.000797093, Loss: 0.000295, Step Loss: 0.000295, Time: 0.083198
2023-06-01 11:45:21,300:INFO: Epoch: 18/30, Step: 26/32, Lr: 0.000797093, Loss: 0.001390, Step Loss: 0.001390, Time: 0.076923
2023-06-01 11:45:21,376:INFO: Epoch: 18/30, Step: 27/32, Lr: 0.000797093, Loss: 0.060930, Step Loss: 0.060930, Time: 0.075531
2023-06-01 11:45:21,455:INFO: Epoch: 18/30, Step: 28/32, Lr: 0.000797093, Loss: 0.000230, Step Loss: 0.000230, Time: 0.078603
2023-06-01 11:45:21,525:INFO: Epoch: 18/30, Step: 29/32, Lr: 0.000797093, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069276
2023-06-01 11:45:21,602:INFO: Epoch: 18/30, Step: 30/32, Lr: 0.000797093, Loss: 0.000132, Step Loss: 0.000132, Time: 0.075985
2023-06-01 11:45:21,676:INFO: Epoch: 18/30, Step: 31/32, Lr: 0.000797093, Loss: 0.000563, Step Loss: 0.000563, Time: 0.073731
2023-06-01 11:45:21,756:INFO: Epoch: 18/30, Step: 32/32, Lr: 0.000797093, Loss: 0.000225, Step Loss: 0.000225, Time: 0.079347
2023-06-01 11:45:21,886:INFO: Epoch 18/30 Finished, Train Loss: 0.009018
2023-06-01 11:45:29,173:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.17
2023-06-01 11:45:32,013:INFO: Classfication Metrics:
2023-06-01 11:45:32,013:INFO: f1 score: 0.8811 - precision score: 0.9009 - recall score: 0.8621 - accuracy score: 0.908475
2023-06-01 11:45:32,013:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:45:33,001:INFO: Epoch: 19/30, Step: 1/32, Lr: 0.000702907, Loss: 0.000722, Step Loss: 0.000722, Time: 0.966593
2023-06-01 11:45:33,084:INFO: Epoch: 19/30, Step: 2/32, Lr: 0.000702907, Loss: 0.000082, Step Loss: 0.000082, Time: 0.082076
2023-06-01 11:45:33,168:INFO: Epoch: 19/30, Step: 3/32, Lr: 0.000702907, Loss: 0.000281, Step Loss: 0.000281, Time: 0.083848
2023-06-01 11:45:33,243:INFO: Epoch: 19/30, Step: 4/32, Lr: 0.000702907, Loss: 0.000016, Step Loss: 0.000016, Time: 0.073753
2023-06-01 11:45:33,320:INFO: Epoch: 19/30, Step: 5/32, Lr: 0.000702907, Loss: 0.006287, Step Loss: 0.006287, Time: 0.076911
2023-06-01 11:45:33,404:INFO: Epoch: 19/30, Step: 6/32, Lr: 0.000702907, Loss: 0.000583, Step Loss: 0.000583, Time: 0.083620
2023-06-01 11:45:33,484:INFO: Epoch: 19/30, Step: 7/32, Lr: 0.000702907, Loss: 0.035563, Step Loss: 0.035563, Time: 0.078687
2023-06-01 11:45:33,561:INFO: Epoch: 19/30, Step: 8/32, Lr: 0.000702907, Loss: 0.000106, Step Loss: 0.000106, Time: 0.076967
2023-06-01 11:45:33,644:INFO: Epoch: 19/30, Step: 9/32, Lr: 0.000702907, Loss: 0.001475, Step Loss: 0.001475, Time: 0.082328
2023-06-01 11:45:33,734:INFO: Epoch: 19/30, Step: 10/32, Lr: 0.000702907, Loss: 0.000305, Step Loss: 0.000305, Time: 0.088860
2023-06-01 11:45:33,808:INFO: Epoch: 19/30, Step: 11/32, Lr: 0.000702907, Loss: 0.094712, Step Loss: 0.094712, Time: 0.074292
2023-06-01 11:45:33,888:INFO: Epoch: 19/30, Step: 12/32, Lr: 0.000702907, Loss: 0.000017, Step Loss: 0.000017, Time: 0.079350
2023-06-01 11:45:33,969:INFO: Epoch: 19/30, Step: 13/32, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.080574
2023-06-01 11:45:34,052:INFO: Epoch: 19/30, Step: 14/32, Lr: 0.000702907, Loss: 0.000003, Step Loss: 0.000003, Time: 0.081886
2023-06-01 11:45:34,131:INFO: Epoch: 19/30, Step: 15/32, Lr: 0.000702907, Loss: 0.000013, Step Loss: 0.000013, Time: 0.078150
2023-06-01 11:45:34,212:INFO: Epoch: 19/30, Step: 16/32, Lr: 0.000702907, Loss: 0.000027, Step Loss: 0.000027, Time: 0.080938
2023-06-01 11:45:34,307:INFO: Epoch: 19/30, Step: 17/32, Lr: 0.000702907, Loss: 0.000190, Step Loss: 0.000190, Time: 0.093956
2023-06-01 11:45:34,384:INFO: Epoch: 19/30, Step: 18/32, Lr: 0.000702907, Loss: 0.000004, Step Loss: 0.000004, Time: 0.077234
2023-06-01 11:45:34,463:INFO: Epoch: 19/30, Step: 19/32, Lr: 0.000702907, Loss: 0.019718, Step Loss: 0.019718, Time: 0.078417
2023-06-01 11:45:34,542:INFO: Epoch: 19/30, Step: 20/32, Lr: 0.000702907, Loss: 0.000006, Step Loss: 0.000006, Time: 0.078562
2023-06-01 11:45:34,616:INFO: Epoch: 19/30, Step: 21/32, Lr: 0.000702907, Loss: 0.038146, Step Loss: 0.038146, Time: 0.072984
2023-06-01 11:45:34,695:INFO: Epoch: 19/30, Step: 22/32, Lr: 0.000702907, Loss: 0.000021, Step Loss: 0.000021, Time: 0.078008
2023-06-01 11:45:34,775:INFO: Epoch: 19/30, Step: 23/32, Lr: 0.000702907, Loss: 0.000010, Step Loss: 0.000010, Time: 0.080316
2023-06-01 11:45:34,857:INFO: Epoch: 19/30, Step: 24/32, Lr: 0.000702907, Loss: 0.000558, Step Loss: 0.000558, Time: 0.080805
2023-06-01 11:45:34,931:INFO: Epoch: 19/30, Step: 25/32, Lr: 0.000702907, Loss: 0.000004, Step Loss: 0.000004, Time: 0.073602
2023-06-01 11:45:35,006:INFO: Epoch: 19/30, Step: 26/32, Lr: 0.000702907, Loss: 0.000022, Step Loss: 0.000022, Time: 0.074645
2023-06-01 11:45:35,084:INFO: Epoch: 19/30, Step: 27/32, Lr: 0.000702907, Loss: 0.000677, Step Loss: 0.000677, Time: 0.077204
2023-06-01 11:45:35,158:INFO: Epoch: 19/30, Step: 28/32, Lr: 0.000702907, Loss: 0.000059, Step Loss: 0.000059, Time: 0.073890
2023-06-01 11:45:35,238:INFO: Epoch: 19/30, Step: 29/32, Lr: 0.000702907, Loss: 0.000398, Step Loss: 0.000398, Time: 0.079290
2023-06-01 11:45:35,319:INFO: Epoch: 19/30, Step: 30/32, Lr: 0.000702907, Loss: 0.000001, Step Loss: 0.000001, Time: 0.079908
2023-06-01 11:45:35,393:INFO: Epoch: 19/30, Step: 31/32, Lr: 0.000702907, Loss: 0.000544, Step Loss: 0.000544, Time: 0.073847
2023-06-01 11:45:35,469:INFO: Epoch: 19/30, Step: 32/32, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074868
2023-06-01 11:45:35,603:INFO: Epoch 19/30 Finished, Train Loss: 0.006267
2023-06-01 11:45:42,641:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.18
2023-06-01 11:45:45,495:INFO: Classfication Metrics:
2023-06-01 11:45:45,496:INFO: f1 score: 0.8678 - precision score: 0.8333 - recall score: 0.9052 - accuracy score: 0.891525
2023-06-01 11:45:45,496:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:45:46,556:INFO: Epoch: 20/30, Step: 1/32, Lr: 0.000609464, Loss: 0.000036, Step Loss: 0.000036, Time: 1.051669
2023-06-01 11:45:46,671:INFO: Epoch: 20/30, Step: 2/32, Lr: 0.000609464, Loss: 0.004351, Step Loss: 0.004351, Time: 0.114651
2023-06-01 11:45:46,740:INFO: Epoch: 20/30, Step: 3/32, Lr: 0.000609464, Loss: 0.000015, Step Loss: 0.000015, Time: 0.068947
2023-06-01 11:45:46,815:INFO: Epoch: 20/30, Step: 4/32, Lr: 0.000609464, Loss: 0.001345, Step Loss: 0.001345, Time: 0.074173
2023-06-01 11:45:46,889:INFO: Epoch: 20/30, Step: 5/32, Lr: 0.000609464, Loss: 0.000062, Step Loss: 0.000062, Time: 0.073097
2023-06-01 11:45:46,963:INFO: Epoch: 20/30, Step: 6/32, Lr: 0.000609464, Loss: 0.001647, Step Loss: 0.001647, Time: 0.073867
2023-06-01 11:45:47,036:INFO: Epoch: 20/30, Step: 7/32, Lr: 0.000609464, Loss: 0.000074, Step Loss: 0.000074, Time: 0.072518
2023-06-01 11:45:47,112:INFO: Epoch: 20/30, Step: 8/32, Lr: 0.000609464, Loss: 0.000004, Step Loss: 0.000004, Time: 0.075142
2023-06-01 11:45:47,200:INFO: Epoch: 20/30, Step: 9/32, Lr: 0.000609464, Loss: 0.000008, Step Loss: 0.000008, Time: 0.087396
2023-06-01 11:45:47,275:INFO: Epoch: 20/30, Step: 10/32, Lr: 0.000609464, Loss: 0.000017, Step Loss: 0.000017, Time: 0.074224
2023-06-01 11:45:47,352:INFO: Epoch: 20/30, Step: 11/32, Lr: 0.000609464, Loss: 0.002365, Step Loss: 0.002365, Time: 0.077005
2023-06-01 11:45:47,427:INFO: Epoch: 20/30, Step: 12/32, Lr: 0.000609464, Loss: 0.001348, Step Loss: 0.001348, Time: 0.074434
2023-06-01 11:45:47,497:INFO: Epoch: 20/30, Step: 13/32, Lr: 0.000609464, Loss: 0.000122, Step Loss: 0.000122, Time: 0.069376
2023-06-01 11:45:47,572:INFO: Epoch: 20/30, Step: 14/32, Lr: 0.000609464, Loss: 0.000007, Step Loss: 0.000007, Time: 0.073911
2023-06-01 11:45:47,646:INFO: Epoch: 20/30, Step: 15/32, Lr: 0.000609464, Loss: 0.000435, Step Loss: 0.000435, Time: 0.073105
2023-06-01 11:45:47,723:INFO: Epoch: 20/30, Step: 16/32, Lr: 0.000609464, Loss: 0.000002, Step Loss: 0.000002, Time: 0.076933
2023-06-01 11:45:47,812:INFO: Epoch: 20/30, Step: 17/32, Lr: 0.000609464, Loss: 0.001309, Step Loss: 0.001309, Time: 0.088074
2023-06-01 11:45:47,891:INFO: Epoch: 20/30, Step: 18/32, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079077
2023-06-01 11:45:47,964:INFO: Epoch: 20/30, Step: 19/32, Lr: 0.000609464, Loss: 0.001674, Step Loss: 0.001674, Time: 0.072347
2023-06-01 11:45:48,039:INFO: Epoch: 20/30, Step: 20/32, Lr: 0.000609464, Loss: 0.000299, Step Loss: 0.000299, Time: 0.074502
2023-06-01 11:45:48,115:INFO: Epoch: 20/30, Step: 21/32, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074584
2023-06-01 11:45:48,192:INFO: Epoch: 20/30, Step: 22/32, Lr: 0.000609464, Loss: 0.000006, Step Loss: 0.000006, Time: 0.077005
2023-06-01 11:45:48,272:INFO: Epoch: 20/30, Step: 23/32, Lr: 0.000609464, Loss: 0.003747, Step Loss: 0.003747, Time: 0.079041
2023-06-01 11:45:48,347:INFO: Epoch: 20/30, Step: 24/32, Lr: 0.000609464, Loss: 0.000036, Step Loss: 0.000036, Time: 0.074852
2023-06-01 11:45:48,424:INFO: Epoch: 20/30, Step: 25/32, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075988
2023-06-01 11:45:48,505:INFO: Epoch: 20/30, Step: 26/32, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.080677
2023-06-01 11:45:48,580:INFO: Epoch: 20/30, Step: 27/32, Lr: 0.000609464, Loss: 0.000067, Step Loss: 0.000067, Time: 0.074341
2023-06-01 11:45:48,660:INFO: Epoch: 20/30, Step: 28/32, Lr: 0.000609464, Loss: 0.000009, Step Loss: 0.000009, Time: 0.079566
2023-06-01 11:45:48,742:INFO: Epoch: 20/30, Step: 29/32, Lr: 0.000609464, Loss: 0.000037, Step Loss: 0.000037, Time: 0.081383
2023-06-01 11:45:48,827:INFO: Epoch: 20/30, Step: 30/32, Lr: 0.000609464, Loss: 0.000006, Step Loss: 0.000006, Time: 0.083773
2023-06-01 11:45:48,903:INFO: Epoch: 20/30, Step: 31/32, Lr: 0.000609464, Loss: 0.000033, Step Loss: 0.000033, Time: 0.076010
2023-06-01 11:45:48,979:INFO: Epoch: 20/30, Step: 32/32, Lr: 0.000609464, Loss: 0.000010, Step Loss: 0.000010, Time: 0.075262
2023-06-01 11:45:49,134:INFO: Epoch 20/30 Finished, Train Loss: 0.000596
2023-06-01 11:46:02,319:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19
2023-06-01 11:46:05,198:INFO: Classfication Metrics:
2023-06-01 11:46:05,198:INFO: f1 score: 0.8621 - precision score: 0.8621 - recall score: 0.8621 - accuracy score: 0.891525
2023-06-01 11:46:05,198:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:46:06,146:INFO: Epoch: 21/30, Step: 1/32, Lr: 0.000518237, Loss: 0.000031, Step Loss: 0.000031, Time: 0.924238
2023-06-01 11:46:06,266:INFO: Epoch: 21/30, Step: 2/32, Lr: 0.000518237, Loss: 0.000608, Step Loss: 0.000608, Time: 0.120265
2023-06-01 11:46:06,340:INFO: Epoch: 21/30, Step: 3/32, Lr: 0.000518237, Loss: 0.000395, Step Loss: 0.000395, Time: 0.072778
2023-06-01 11:46:06,419:INFO: Epoch: 21/30, Step: 4/32, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.079037
2023-06-01 11:46:06,498:INFO: Epoch: 21/30, Step: 5/32, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078806
2023-06-01 11:46:06,578:INFO: Epoch: 21/30, Step: 6/32, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079254
2023-06-01 11:46:06,655:INFO: Epoch: 21/30, Step: 7/32, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076111
2023-06-01 11:46:06,731:INFO: Epoch: 21/30, Step: 8/32, Lr: 0.000518237, Loss: 0.045401, Step Loss: 0.045401, Time: 0.075722
2023-06-01 11:46:06,911:INFO: Epoch: 21/30, Step: 9/32, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.180426
2023-06-01 11:46:06,991:INFO: Epoch: 21/30, Step: 10/32, Lr: 0.000518237, Loss: 0.000012, Step Loss: 0.000012, Time: 0.078864
2023-06-01 11:46:07,064:INFO: Epoch: 21/30, Step: 11/32, Lr: 0.000518237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.072480
2023-06-01 11:46:07,139:INFO: Epoch: 21/30, Step: 12/32, Lr: 0.000518237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.074774
2023-06-01 11:46:07,212:INFO: Epoch: 21/30, Step: 13/32, Lr: 0.000518237, Loss: 0.000072, Step Loss: 0.000072, Time: 0.072492
2023-06-01 11:46:07,284:INFO: Epoch: 21/30, Step: 14/32, Lr: 0.000518237, Loss: 0.000004, Step Loss: 0.000004, Time: 0.071277
2023-06-01 11:46:07,357:INFO: Epoch: 21/30, Step: 15/32, Lr: 0.000518237, Loss: 0.000012, Step Loss: 0.000012, Time: 0.072949
2023-06-01 11:46:07,437:INFO: Epoch: 21/30, Step: 16/32, Lr: 0.000518237, Loss: 0.000342, Step Loss: 0.000342, Time: 0.079751
2023-06-01 11:46:07,533:INFO: Epoch: 21/30, Step: 17/32, Lr: 0.000518237, Loss: 0.000069, Step Loss: 0.000069, Time: 0.094911
2023-06-01 11:46:07,614:INFO: Epoch: 21/30, Step: 18/32, Lr: 0.000518237, Loss: 0.000242, Step Loss: 0.000242, Time: 0.080515
2023-06-01 11:46:07,688:INFO: Epoch: 21/30, Step: 19/32, Lr: 0.000518237, Loss: 0.000103, Step Loss: 0.000103, Time: 0.073755
2023-06-01 11:46:07,760:INFO: Epoch: 21/30, Step: 20/32, Lr: 0.000518237, Loss: 0.004574, Step Loss: 0.004574, Time: 0.071058
2023-06-01 11:46:07,833:INFO: Epoch: 21/30, Step: 21/32, Lr: 0.000518237, Loss: 0.095268, Step Loss: 0.095268, Time: 0.073143
2023-06-01 11:46:07,915:INFO: Epoch: 21/30, Step: 22/32, Lr: 0.000518237, Loss: 0.001113, Step Loss: 0.001113, Time: 0.081275
2023-06-01 11:46:07,991:INFO: Epoch: 21/30, Step: 23/32, Lr: 0.000518237, Loss: 0.000277, Step Loss: 0.000277, Time: 0.075321
2023-06-01 11:46:08,069:INFO: Epoch: 21/30, Step: 24/32, Lr: 0.000518237, Loss: 0.000281, Step Loss: 0.000281, Time: 0.076966
2023-06-01 11:46:08,160:INFO: Epoch: 21/30, Step: 25/32, Lr: 0.000518237, Loss: 0.000012, Step Loss: 0.000012, Time: 0.091235
2023-06-01 11:46:08,243:INFO: Epoch: 21/30, Step: 26/32, Lr: 0.000518237, Loss: 0.001884, Step Loss: 0.001884, Time: 0.082404
2023-06-01 11:46:08,328:INFO: Epoch: 21/30, Step: 27/32, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.083818
2023-06-01 11:46:08,407:INFO: Epoch: 21/30, Step: 28/32, Lr: 0.000518237, Loss: 0.000047, Step Loss: 0.000047, Time: 0.078518
2023-06-01 11:46:08,476:INFO: Epoch: 21/30, Step: 29/32, Lr: 0.000518237, Loss: 0.000052, Step Loss: 0.000052, Time: 0.068819
2023-06-01 11:46:08,548:INFO: Epoch: 21/30, Step: 30/32, Lr: 0.000518237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.070926
2023-06-01 11:46:08,617:INFO: Epoch: 21/30, Step: 31/32, Lr: 0.000518237, Loss: 0.000170, Step Loss: 0.000170, Time: 0.068739
2023-06-01 11:46:08,700:INFO: Epoch: 21/30, Step: 32/32, Lr: 0.000518237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.082494
2023-06-01 11:46:08,841:INFO: Epoch 21/30 Finished, Train Loss: 0.004718
2023-06-01 11:46:15,549:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20
2023-06-01 11:46:18,421:INFO: Classfication Metrics:
2023-06-01 11:46:18,422:INFO: f1 score: 0.8766 - precision score: 0.8655 - recall score: 0.8879 - accuracy score: 0.901695
2023-06-01 11:46:18,422:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:46:19,619:INFO: Epoch: 22/30, Step: 1/32, Lr: 0.000430666, Loss: 0.000010, Step Loss: 0.000010, Time: 1.187783
2023-06-01 11:46:19,700:INFO: Epoch: 22/30, Step: 2/32, Lr: 0.000430666, Loss: 0.000014, Step Loss: 0.000014, Time: 0.081099
2023-06-01 11:46:19,777:INFO: Epoch: 22/30, Step: 3/32, Lr: 0.000430666, Loss: 0.000012, Step Loss: 0.000012, Time: 0.075503
2023-06-01 11:46:19,848:INFO: Epoch: 22/30, Step: 4/32, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070750
2023-06-01 11:46:19,924:INFO: Epoch: 22/30, Step: 5/32, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075552
2023-06-01 11:46:20,002:INFO: Epoch: 22/30, Step: 6/32, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.077716
2023-06-01 11:46:20,079:INFO: Epoch: 22/30, Step: 7/32, Lr: 0.000430666, Loss: 0.000306, Step Loss: 0.000306, Time: 0.075873
2023-06-01 11:46:20,156:INFO: Epoch: 22/30, Step: 8/32, Lr: 0.000430666, Loss: 0.000067, Step Loss: 0.000067, Time: 0.076380
2023-06-01 11:46:20,244:INFO: Epoch: 22/30, Step: 9/32, Lr: 0.000430666, Loss: 0.000006, Step Loss: 0.000006, Time: 0.087947
2023-06-01 11:46:20,315:INFO: Epoch: 22/30, Step: 10/32, Lr: 0.000430666, Loss: 0.000012, Step Loss: 0.000012, Time: 0.070553
2023-06-01 11:46:20,391:INFO: Epoch: 22/30, Step: 11/32, Lr: 0.000430666, Loss: 0.000067, Step Loss: 0.000067, Time: 0.075789
2023-06-01 11:46:20,470:INFO: Epoch: 22/30, Step: 12/32, Lr: 0.000430666, Loss: 0.027183, Step Loss: 0.027183, Time: 0.077735
2023-06-01 11:46:20,544:INFO: Epoch: 22/30, Step: 13/32, Lr: 0.000430666, Loss: 0.000387, Step Loss: 0.000387, Time: 0.074132
2023-06-01 11:46:20,623:INFO: Epoch: 22/30, Step: 14/32, Lr: 0.000430666, Loss: 0.009479, Step Loss: 0.009479, Time: 0.078395
2023-06-01 11:46:20,700:INFO: Epoch: 22/30, Step: 15/32, Lr: 0.000430666, Loss: 0.004082, Step Loss: 0.004082, Time: 0.075723
2023-06-01 11:46:20,775:INFO: Epoch: 22/30, Step: 16/32, Lr: 0.000430666, Loss: 0.000002, Step Loss: 0.000002, Time: 0.074508
2023-06-01 11:46:20,861:INFO: Epoch: 22/30, Step: 17/32, Lr: 0.000430666, Loss: 0.003875, Step Loss: 0.003875, Time: 0.085762
2023-06-01 11:46:20,935:INFO: Epoch: 22/30, Step: 18/32, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073353
2023-06-01 11:46:21,014:INFO: Epoch: 22/30, Step: 19/32, Lr: 0.000430666, Loss: 0.000013, Step Loss: 0.000013, Time: 0.078989
2023-06-01 11:46:21,088:INFO: Epoch: 22/30, Step: 20/32, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.072935
2023-06-01 11:46:21,157:INFO: Epoch: 22/30, Step: 21/32, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068933
2023-06-01 11:46:21,232:INFO: Epoch: 22/30, Step: 22/32, Lr: 0.000430666, Loss: 0.000011, Step Loss: 0.000011, Time: 0.073752
2023-06-01 11:46:21,315:INFO: Epoch: 22/30, Step: 23/32, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.082464
2023-06-01 11:46:21,388:INFO: Epoch: 22/30, Step: 24/32, Lr: 0.000430666, Loss: 0.000010, Step Loss: 0.000010, Time: 0.072876
2023-06-01 11:46:21,472:INFO: Epoch: 22/30, Step: 25/32, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.083743
2023-06-01 11:46:21,542:INFO: Epoch: 22/30, Step: 26/32, Lr: 0.000430666, Loss: 0.000102, Step Loss: 0.000102, Time: 0.068769
2023-06-01 11:46:21,611:INFO: Epoch: 22/30, Step: 27/32, Lr: 0.000430666, Loss: 0.000023, Step Loss: 0.000023, Time: 0.069062
2023-06-01 11:46:21,688:INFO: Epoch: 22/30, Step: 28/32, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075862
2023-06-01 11:46:21,763:INFO: Epoch: 22/30, Step: 29/32, Lr: 0.000430666, Loss: 0.000135, Step Loss: 0.000135, Time: 0.074356
2023-06-01 11:46:21,840:INFO: Epoch: 22/30, Step: 30/32, Lr: 0.000430666, Loss: 0.000004, Step Loss: 0.000004, Time: 0.076287
2023-06-01 11:46:21,919:INFO: Epoch: 22/30, Step: 31/32, Lr: 0.000430666, Loss: 0.000058, Step Loss: 0.000058, Time: 0.078717
2023-06-01 11:46:21,993:INFO: Epoch: 22/30, Step: 32/32, Lr: 0.000430666, Loss: 0.001574, Step Loss: 0.001574, Time: 0.073248
2023-06-01 11:46:22,124:INFO: Epoch 22/30 Finished, Train Loss: 0.001482
2023-06-01 11:46:30,649:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.21
2023-06-01 11:46:33,502:INFO: Classfication Metrics:
2023-06-01 11:46:33,503:INFO: f1 score: 0.8493 - precision score: 0.9029 - recall score: 0.8017 - accuracy score: 0.888136
2023-06-01 11:46:33,503:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:46:34,642:INFO: Epoch: 23/30, Step: 1/32, Lr: 0.000348130, Loss: 0.000001, Step Loss: 0.000001, Time: 1.116252
2023-06-01 11:46:34,734:INFO: Epoch: 23/30, Step: 2/32, Lr: 0.000348130, Loss: 0.000005, Step Loss: 0.000005, Time: 0.091381
2023-06-01 11:46:34,804:INFO: Epoch: 23/30, Step: 3/32, Lr: 0.000348130, Loss: 0.002305, Step Loss: 0.002305, Time: 0.069600
2023-06-01 11:46:34,874:INFO: Epoch: 23/30, Step: 4/32, Lr: 0.000348130, Loss: 0.000008, Step Loss: 0.000008, Time: 0.069398
2023-06-01 11:46:34,947:INFO: Epoch: 23/30, Step: 5/32, Lr: 0.000348130, Loss: 0.000080, Step Loss: 0.000080, Time: 0.071995
2023-06-01 11:46:35,022:INFO: Epoch: 23/30, Step: 6/32, Lr: 0.000348130, Loss: 0.000195, Step Loss: 0.000195, Time: 0.074518
2023-06-01 11:46:35,096:INFO: Epoch: 23/30, Step: 7/32, Lr: 0.000348130, Loss: 0.001872, Step Loss: 0.001872, Time: 0.073579
2023-06-01 11:46:35,171:INFO: Epoch: 23/30, Step: 8/32, Lr: 0.000348130, Loss: 0.000015, Step Loss: 0.000015, Time: 0.074359
2023-06-01 11:46:35,253:INFO: Epoch: 23/30, Step: 9/32, Lr: 0.000348130, Loss: 0.000002, Step Loss: 0.000002, Time: 0.081734
2023-06-01 11:46:35,337:INFO: Epoch: 23/30, Step: 10/32, Lr: 0.000348130, Loss: 0.000088, Step Loss: 0.000088, Time: 0.082516
2023-06-01 11:46:35,414:INFO: Epoch: 23/30, Step: 11/32, Lr: 0.000348130, Loss: 0.000224, Step Loss: 0.000224, Time: 0.077151
2023-06-01 11:46:35,488:INFO: Epoch: 23/30, Step: 12/32, Lr: 0.000348130, Loss: 0.000008, Step Loss: 0.000008, Time: 0.073600
2023-06-01 11:46:35,558:INFO: Epoch: 23/30, Step: 13/32, Lr: 0.000348130, Loss: 0.000132, Step Loss: 0.000132, Time: 0.069186
2023-06-01 11:46:35,628:INFO: Epoch: 23/30, Step: 14/32, Lr: 0.000348130, Loss: 0.000010, Step Loss: 0.000010, Time: 0.068825
2023-06-01 11:46:35,707:INFO: Epoch: 23/30, Step: 15/32, Lr: 0.000348130, Loss: 0.000003, Step Loss: 0.000003, Time: 0.078568
2023-06-01 11:46:35,781:INFO: Epoch: 23/30, Step: 16/32, Lr: 0.000348130, Loss: 0.000005, Step Loss: 0.000005, Time: 0.073483
2023-06-01 11:46:35,867:INFO: Epoch: 23/30, Step: 17/32, Lr: 0.000348130, Loss: 0.000002, Step Loss: 0.000002, Time: 0.085514
2023-06-01 11:46:35,945:INFO: Epoch: 23/30, Step: 18/32, Lr: 0.000348130, Loss: 0.000437, Step Loss: 0.000437, Time: 0.077251
2023-06-01 11:46:36,019:INFO: Epoch: 23/30, Step: 19/32, Lr: 0.000348130, Loss: 0.003217, Step Loss: 0.003217, Time: 0.073981
2023-06-01 11:46:36,098:INFO: Epoch: 23/30, Step: 20/32, Lr: 0.000348130, Loss: 0.001110, Step Loss: 0.001110, Time: 0.077869
2023-06-01 11:46:36,179:INFO: Epoch: 23/30, Step: 21/32, Lr: 0.000348130, Loss: 0.000002, Step Loss: 0.000002, Time: 0.080378
2023-06-01 11:46:36,259:INFO: Epoch: 23/30, Step: 22/32, Lr: 0.000348130, Loss: 0.000947, Step Loss: 0.000947, Time: 0.079717
2023-06-01 11:46:36,336:INFO: Epoch: 23/30, Step: 23/32, Lr: 0.000348130, Loss: 0.000045, Step Loss: 0.000045, Time: 0.076320
2023-06-01 11:46:36,420:INFO: Epoch: 23/30, Step: 24/32, Lr: 0.000348130, Loss: 0.000003, Step Loss: 0.000003, Time: 0.083536
2023-06-01 11:46:36,503:INFO: Epoch: 23/30, Step: 25/32, Lr: 0.000348130, Loss: 0.000001, Step Loss: 0.000001, Time: 0.082639
2023-06-01 11:46:36,579:INFO: Epoch: 23/30, Step: 26/32, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074569
2023-06-01 11:46:36,662:INFO: Epoch: 23/30, Step: 27/32, Lr: 0.000348130, Loss: 0.000178, Step Loss: 0.000178, Time: 0.082866
2023-06-01 11:46:36,741:INFO: Epoch: 23/30, Step: 28/32, Lr: 0.000348130, Loss: 0.000035, Step Loss: 0.000035, Time: 0.078083
2023-06-01 11:46:36,811:INFO: Epoch: 23/30, Step: 29/32, Lr: 0.000348130, Loss: 0.000014, Step Loss: 0.000014, Time: 0.069919
2023-06-01 11:46:36,888:INFO: Epoch: 23/30, Step: 30/32, Lr: 0.000348130, Loss: 0.000011, Step Loss: 0.000011, Time: 0.075802
2023-06-01 11:46:36,973:INFO: Epoch: 23/30, Step: 31/32, Lr: 0.000348130, Loss: 0.000027, Step Loss: 0.000027, Time: 0.084546
2023-06-01 11:46:37,046:INFO: Epoch: 23/30, Step: 32/32, Lr: 0.000348130, Loss: 0.000041, Step Loss: 0.000041, Time: 0.072942
2023-06-01 11:46:37,172:INFO: Epoch 23/30 Finished, Train Loss: 0.000344
2023-06-01 11:46:44,721:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.22
2023-06-01 11:46:47,562:INFO: Classfication Metrics:
2023-06-01 11:46:47,562:INFO: f1 score: 0.8571 - precision score: 0.8889 - recall score: 0.8276 - accuracy score: 0.891525
2023-06-01 11:46:47,562:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:46:48,616:INFO: Epoch: 24/30, Step: 1/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 1.045676
2023-06-01 11:46:48,705:INFO: Epoch: 24/30, Step: 2/32, Lr: 0.000271932, Loss: 0.000004, Step Loss: 0.000004, Time: 0.088085
2023-06-01 11:46:48,785:INFO: Epoch: 24/30, Step: 3/32, Lr: 0.000271932, Loss: 0.000008, Step Loss: 0.000008, Time: 0.079001
2023-06-01 11:46:48,860:INFO: Epoch: 24/30, Step: 4/32, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.074238
2023-06-01 11:46:48,939:INFO: Epoch: 24/30, Step: 5/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079056
2023-06-01 11:46:49,014:INFO: Epoch: 24/30, Step: 6/32, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.074106
2023-06-01 11:46:49,089:INFO: Epoch: 24/30, Step: 7/32, Lr: 0.000271932, Loss: 0.000311, Step Loss: 0.000311, Time: 0.074374
2023-06-01 11:46:49,165:INFO: Epoch: 24/30, Step: 8/32, Lr: 0.000271932, Loss: 0.001296, Step Loss: 0.001296, Time: 0.075157
2023-06-01 11:46:49,244:INFO: Epoch: 24/30, Step: 9/32, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.079087
2023-06-01 11:46:49,336:INFO: Epoch: 24/30, Step: 10/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.091180
2023-06-01 11:46:49,418:INFO: Epoch: 24/30, Step: 11/32, Lr: 0.000271932, Loss: 0.000021, Step Loss: 0.000021, Time: 0.081738
2023-06-01 11:46:49,490:INFO: Epoch: 24/30, Step: 12/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071385
2023-06-01 11:46:49,569:INFO: Epoch: 24/30, Step: 13/32, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.079226
2023-06-01 11:46:49,646:INFO: Epoch: 24/30, Step: 14/32, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.076660
2023-06-01 11:46:49,718:INFO: Epoch: 24/30, Step: 15/32, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071233
2023-06-01 11:46:49,797:INFO: Epoch: 24/30, Step: 16/32, Lr: 0.000271932, Loss: 0.000021, Step Loss: 0.000021, Time: 0.078439
2023-06-01 11:46:49,875:INFO: Epoch: 24/30, Step: 17/32, Lr: 0.000271932, Loss: 0.000010, Step Loss: 0.000010, Time: 0.077860
2023-06-01 11:46:49,960:INFO: Epoch: 24/30, Step: 18/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.084853
2023-06-01 11:46:50,038:INFO: Epoch: 24/30, Step: 19/32, Lr: 0.000271932, Loss: 0.000041, Step Loss: 0.000041, Time: 0.077592
2023-06-01 11:46:50,124:INFO: Epoch: 24/30, Step: 20/32, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.085624
2023-06-01 11:46:50,209:INFO: Epoch: 24/30, Step: 21/32, Lr: 0.000271932, Loss: 0.008255, Step Loss: 0.008255, Time: 0.084351
2023-06-01 11:46:50,282:INFO: Epoch: 24/30, Step: 22/32, Lr: 0.000271932, Loss: 0.000015, Step Loss: 0.000015, Time: 0.072787
2023-06-01 11:46:50,356:INFO: Epoch: 24/30, Step: 23/32, Lr: 0.000271932, Loss: 0.000010, Step Loss: 0.000010, Time: 0.073576
2023-06-01 11:46:50,426:INFO: Epoch: 24/30, Step: 24/32, Lr: 0.000271932, Loss: 0.000207, Step Loss: 0.000207, Time: 0.069377
2023-06-01 11:46:50,498:INFO: Epoch: 24/30, Step: 25/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071352
2023-06-01 11:46:50,583:INFO: Epoch: 24/30, Step: 26/32, Lr: 0.000271932, Loss: 0.000006, Step Loss: 0.000006, Time: 0.084523
2023-06-01 11:46:50,656:INFO: Epoch: 24/30, Step: 27/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072979
2023-06-01 11:46:50,737:INFO: Epoch: 24/30, Step: 28/32, Lr: 0.000271932, Loss: 0.011173, Step Loss: 0.011173, Time: 0.080501
2023-06-01 11:46:50,814:INFO: Epoch: 24/30, Step: 29/32, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076318
2023-06-01 11:46:50,885:INFO: Epoch: 24/30, Step: 30/32, Lr: 0.000271932, Loss: 0.000014, Step Loss: 0.000014, Time: 0.071127
2023-06-01 11:46:50,954:INFO: Epoch: 24/30, Step: 31/32, Lr: 0.000271932, Loss: 0.000013, Step Loss: 0.000013, Time: 0.067935
2023-06-01 11:46:51,040:INFO: Epoch: 24/30, Step: 32/32, Lr: 0.000271932, Loss: 0.000005, Step Loss: 0.000005, Time: 0.086285
2023-06-01 11:46:51,201:INFO: Epoch 24/30 Finished, Train Loss: 0.000669
2023-06-01 11:46:58,951:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.23
2023-06-01 11:47:01,939:INFO: Classfication Metrics:
2023-06-01 11:47:01,939:INFO: f1 score: 0.8734 - precision score: 0.8850 - recall score: 0.8621 - accuracy score: 0.901695
2023-06-01 11:47:01,939:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:47:03,113:INFO: Epoch: 25/30, Step: 1/32, Lr: 0.000203274, Loss: 0.000047, Step Loss: 0.000047, Time: 1.165320
2023-06-01 11:47:03,187:INFO: Epoch: 25/30, Step: 2/32, Lr: 0.000203274, Loss: 0.000072, Step Loss: 0.000072, Time: 0.073119
2023-06-01 11:47:03,254:INFO: Epoch: 25/30, Step: 3/32, Lr: 0.000203274, Loss: 0.000189, Step Loss: 0.000189, Time: 0.067653
2023-06-01 11:47:03,342:INFO: Epoch: 25/30, Step: 4/32, Lr: 0.000203274, Loss: 0.000054, Step Loss: 0.000054, Time: 0.087098
2023-06-01 11:47:03,424:INFO: Epoch: 25/30, Step: 5/32, Lr: 0.000203274, Loss: 0.000176, Step Loss: 0.000176, Time: 0.081099
2023-06-01 11:47:03,498:INFO: Epoch: 25/30, Step: 6/32, Lr: 0.000203274, Loss: 0.000005, Step Loss: 0.000005, Time: 0.073689
2023-06-01 11:47:03,571:INFO: Epoch: 25/30, Step: 7/32, Lr: 0.000203274, Loss: 0.000002, Step Loss: 0.000002, Time: 0.072002
2023-06-01 11:47:03,654:INFO: Epoch: 25/30, Step: 8/32, Lr: 0.000203274, Loss: 0.000011, Step Loss: 0.000011, Time: 0.083387
2023-06-01 11:47:03,748:INFO: Epoch: 25/30, Step: 9/32, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.093412
2023-06-01 11:47:03,829:INFO: Epoch: 25/30, Step: 10/32, Lr: 0.000203274, Loss: 0.000002, Step Loss: 0.000002, Time: 0.079788
2023-06-01 11:47:03,904:INFO: Epoch: 25/30, Step: 11/32, Lr: 0.000203274, Loss: 0.000082, Step Loss: 0.000082, Time: 0.074745
2023-06-01 11:47:03,999:INFO: Epoch: 25/30, Step: 12/32, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.094400
2023-06-01 11:47:04,071:INFO: Epoch: 25/30, Step: 13/32, Lr: 0.000203274, Loss: 0.000003, Step Loss: 0.000003, Time: 0.071311
2023-06-01 11:47:04,149:INFO: Epoch: 25/30, Step: 14/32, Lr: 0.000203274, Loss: 0.001048, Step Loss: 0.001048, Time: 0.078147
2023-06-01 11:47:04,224:INFO: Epoch: 25/30, Step: 15/32, Lr: 0.000203274, Loss: 0.000004, Step Loss: 0.000004, Time: 0.073926
2023-06-01 11:47:04,298:INFO: Epoch: 25/30, Step: 16/32, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073941
2023-06-01 11:47:04,386:INFO: Epoch: 25/30, Step: 17/32, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.087332
2023-06-01 11:47:04,458:INFO: Epoch: 25/30, Step: 18/32, Lr: 0.000203274, Loss: 0.000004, Step Loss: 0.000004, Time: 0.072061
2023-06-01 11:47:04,533:INFO: Epoch: 25/30, Step: 19/32, Lr: 0.000203274, Loss: 0.000002, Step Loss: 0.000002, Time: 0.074194
2023-06-01 11:47:04,623:INFO: Epoch: 25/30, Step: 20/32, Lr: 0.000203274, Loss: 0.000145, Step Loss: 0.000145, Time: 0.089637
2023-06-01 11:47:04,700:INFO: Epoch: 25/30, Step: 21/32, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.076366
2023-06-01 11:47:04,776:INFO: Epoch: 25/30, Step: 22/32, Lr: 0.000203274, Loss: 0.000020, Step Loss: 0.000020, Time: 0.074939
2023-06-01 11:47:04,851:INFO: Epoch: 25/30, Step: 23/32, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074574
2023-06-01 11:47:04,921:INFO: Epoch: 25/30, Step: 24/32, Lr: 0.000203274, Loss: 0.000186, Step Loss: 0.000186, Time: 0.069010
2023-06-01 11:47:05,000:INFO: Epoch: 25/30, Step: 25/32, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078493
2023-06-01 11:47:05,071:INFO: Epoch: 25/30, Step: 26/32, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070699
2023-06-01 11:47:05,147:INFO: Epoch: 25/30, Step: 27/32, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075279
2023-06-01 11:47:05,227:INFO: Epoch: 25/30, Step: 28/32, Lr: 0.000203274, Loss: 0.000003, Step Loss: 0.000003, Time: 0.079950
2023-06-01 11:47:05,309:INFO: Epoch: 25/30, Step: 29/32, Lr: 0.000203274, Loss: 0.000005, Step Loss: 0.000005, Time: 0.081257
2023-06-01 11:47:05,389:INFO: Epoch: 25/30, Step: 30/32, Lr: 0.000203274, Loss: 0.000050, Step Loss: 0.000050, Time: 0.079499
2023-06-01 11:47:05,472:INFO: Epoch: 25/30, Step: 31/32, Lr: 0.000203274, Loss: 0.000014, Step Loss: 0.000014, Time: 0.081632
2023-06-01 11:47:05,548:INFO: Epoch: 25/30, Step: 32/32, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075197
2023-06-01 11:47:05,701:INFO: Epoch 25/30 Finished, Train Loss: 0.000067
2023-06-01 11:47:17,668:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.24
2023-06-01 11:47:20,598:INFO: Classfication Metrics:
2023-06-01 11:47:20,599:INFO: f1 score: 0.8745 - precision score: 0.8783 - recall score: 0.8707 - accuracy score: 0.901695
2023-06-01 11:47:20,599:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:47:21,938:INFO: Epoch: 26/30, Step: 1/32, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 1.311929
2023-06-01 11:47:22,015:INFO: Epoch: 26/30, Step: 2/32, Lr: 0.000143237, Loss: 0.006160, Step Loss: 0.006160, Time: 0.076935
2023-06-01 11:47:22,095:INFO: Epoch: 26/30, Step: 3/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079257
2023-06-01 11:47:22,170:INFO: Epoch: 26/30, Step: 4/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073967
2023-06-01 11:47:22,244:INFO: Epoch: 26/30, Step: 5/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073951
2023-06-01 11:47:22,325:INFO: Epoch: 26/30, Step: 6/32, Lr: 0.000143237, Loss: 0.000095, Step Loss: 0.000095, Time: 0.080613
2023-06-01 11:47:22,406:INFO: Epoch: 26/30, Step: 7/32, Lr: 0.000143237, Loss: 0.000201, Step Loss: 0.000201, Time: 0.080190
2023-06-01 11:47:22,482:INFO: Epoch: 26/30, Step: 8/32, Lr: 0.000143237, Loss: 0.000009, Step Loss: 0.000009, Time: 0.075225
2023-06-01 11:47:22,574:INFO: Epoch: 26/30, Step: 9/32, Lr: 0.000143237, Loss: 0.000027, Step Loss: 0.000027, Time: 0.091234
2023-06-01 11:47:22,647:INFO: Epoch: 26/30, Step: 10/32, Lr: 0.000143237, Loss: 0.000007, Step Loss: 0.000007, Time: 0.072373
2023-06-01 11:47:22,727:INFO: Epoch: 26/30, Step: 11/32, Lr: 0.000143237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.079527
2023-06-01 11:47:22,799:INFO: Epoch: 26/30, Step: 12/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071794
2023-06-01 11:47:22,871:INFO: Epoch: 26/30, Step: 13/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071576
2023-06-01 11:47:22,944:INFO: Epoch: 26/30, Step: 14/32, Lr: 0.000143237, Loss: 0.000024, Step Loss: 0.000024, Time: 0.073316
2023-06-01 11:47:23,018:INFO: Epoch: 26/30, Step: 15/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073296
2023-06-01 11:47:23,091:INFO: Epoch: 26/30, Step: 16/32, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.072405
2023-06-01 11:47:23,171:INFO: Epoch: 26/30, Step: 17/32, Lr: 0.000143237, Loss: 0.000116, Step Loss: 0.000116, Time: 0.080255
2023-06-01 11:47:23,243:INFO: Epoch: 26/30, Step: 18/32, Lr: 0.000143237, Loss: 0.001158, Step Loss: 0.001158, Time: 0.070893
2023-06-01 11:47:23,326:INFO: Epoch: 26/30, Step: 19/32, Lr: 0.000143237, Loss: 0.000009, Step Loss: 0.000009, Time: 0.082443
2023-06-01 11:47:23,403:INFO: Epoch: 26/30, Step: 20/32, Lr: 0.000143237, Loss: 0.000326, Step Loss: 0.000326, Time: 0.076922
2023-06-01 11:47:23,487:INFO: Epoch: 26/30, Step: 21/32, Lr: 0.000143237, Loss: 0.000006, Step Loss: 0.000006, Time: 0.083358
2023-06-01 11:47:23,572:INFO: Epoch: 26/30, Step: 22/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.084614
2023-06-01 11:47:23,655:INFO: Epoch: 26/30, Step: 23/32, Lr: 0.000143237, Loss: 0.000105, Step Loss: 0.000105, Time: 0.081875
2023-06-01 11:47:23,743:INFO: Epoch: 26/30, Step: 24/32, Lr: 0.000143237, Loss: 0.000097, Step Loss: 0.000097, Time: 0.087232
2023-06-01 11:47:23,821:INFO: Epoch: 26/30, Step: 25/32, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.077414
2023-06-01 11:47:23,903:INFO: Epoch: 26/30, Step: 26/32, Lr: 0.000143237, Loss: 0.000016, Step Loss: 0.000016, Time: 0.080763
2023-06-01 11:47:23,981:INFO: Epoch: 26/30, Step: 27/32, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.077846
2023-06-01 11:47:24,056:INFO: Epoch: 26/30, Step: 28/32, Lr: 0.000143237, Loss: 0.000006, Step Loss: 0.000006, Time: 0.074219
2023-06-01 11:47:24,138:INFO: Epoch: 26/30, Step: 29/32, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.081041
2023-06-01 11:47:24,217:INFO: Epoch: 26/30, Step: 30/32, Lr: 0.000143237, Loss: 0.000154, Step Loss: 0.000154, Time: 0.078305
2023-06-01 11:47:24,306:INFO: Epoch: 26/30, Step: 31/32, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.088488
2023-06-01 11:47:24,380:INFO: Epoch: 26/30, Step: 32/32, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073370
2023-06-01 11:47:24,529:INFO: Epoch 26/30 Finished, Train Loss: 0.000266
2023-06-01 11:47:30,779:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.25
2023-06-01 11:47:33,638:INFO: Classfication Metrics:
2023-06-01 11:47:33,638:INFO: f1 score: 0.8734 - precision score: 0.8850 - recall score: 0.8621 - accuracy score: 0.901695
2023-06-01 11:47:33,638:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:47:34,759:INFO: Epoch: 27/30, Step: 1/32, Lr: 0.000092770, Loss: 0.000011, Step Loss: 0.000011, Time: 1.111588
2023-06-01 11:47:35,020:INFO: Epoch: 27/30, Step: 2/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.260906
2023-06-01 11:47:35,095:INFO: Epoch: 27/30, Step: 3/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074566
2023-06-01 11:47:35,170:INFO: Epoch: 27/30, Step: 4/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074235
2023-06-01 11:47:35,244:INFO: Epoch: 27/30, Step: 5/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073430
2023-06-01 11:47:35,322:INFO: Epoch: 27/30, Step: 6/32, Lr: 0.000092770, Loss: 0.000025, Step Loss: 0.000025, Time: 0.077872
2023-06-01 11:47:35,392:INFO: Epoch: 27/30, Step: 7/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069029
2023-06-01 11:47:35,466:INFO: Epoch: 27/30, Step: 8/32, Lr: 0.000092770, Loss: 0.000003, Step Loss: 0.000003, Time: 0.073910
2023-06-01 11:47:35,544:INFO: Epoch: 27/30, Step: 9/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.076725
2023-06-01 11:47:35,623:INFO: Epoch: 27/30, Step: 10/32, Lr: 0.000092770, Loss: 0.000003, Step Loss: 0.000003, Time: 0.078775
2023-06-01 11:47:35,692:INFO: Epoch: 27/30, Step: 11/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068417
2023-06-01 11:47:35,761:INFO: Epoch: 27/30, Step: 12/32, Lr: 0.000092770, Loss: 0.000026, Step Loss: 0.000026, Time: 0.068198
2023-06-01 11:47:35,829:INFO: Epoch: 27/30, Step: 13/32, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068210
2023-06-01 11:47:35,903:INFO: Epoch: 27/30, Step: 14/32, Lr: 0.000092770, Loss: 0.000003, Step Loss: 0.000003, Time: 0.073404
2023-06-01 11:47:35,974:INFO: Epoch: 27/30, Step: 15/32, Lr: 0.000092770, Loss: 0.000008, Step Loss: 0.000008, Time: 0.070285
2023-06-01 11:47:36,046:INFO: Epoch: 27/30, Step: 16/32, Lr: 0.000092770, Loss: 0.000017, Step Loss: 0.000017, Time: 0.071807
2023-06-01 11:47:36,123:INFO: Epoch: 27/30, Step: 17/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075795
2023-06-01 11:47:36,207:INFO: Epoch: 27/30, Step: 18/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.083575
2023-06-01 11:47:36,281:INFO: Epoch: 27/30, Step: 19/32, Lr: 0.000092770, Loss: 0.000098, Step Loss: 0.000098, Time: 0.073427
2023-06-01 11:47:36,359:INFO: Epoch: 27/30, Step: 20/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.078207
2023-06-01 11:47:36,436:INFO: Epoch: 27/30, Step: 21/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076604
2023-06-01 11:47:36,511:INFO: Epoch: 27/30, Step: 22/32, Lr: 0.000092770, Loss: 0.000005, Step Loss: 0.000005, Time: 0.073370
2023-06-01 11:47:36,579:INFO: Epoch: 27/30, Step: 23/32, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068220
2023-06-01 11:47:36,655:INFO: Epoch: 27/30, Step: 24/32, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.075308
2023-06-01 11:47:36,739:INFO: Epoch: 27/30, Step: 25/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.083208
2023-06-01 11:47:36,815:INFO: Epoch: 27/30, Step: 26/32, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075681
2023-06-01 11:47:36,888:INFO: Epoch: 27/30, Step: 27/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072666
2023-06-01 11:47:36,962:INFO: Epoch: 27/30, Step: 28/32, Lr: 0.000092770, Loss: 0.000112, Step Loss: 0.000112, Time: 0.073801
2023-06-01 11:47:37,039:INFO: Epoch: 27/30, Step: 29/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075805
2023-06-01 11:47:37,116:INFO: Epoch: 27/30, Step: 30/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076419
2023-06-01 11:47:37,190:INFO: Epoch: 27/30, Step: 31/32, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074195
2023-06-01 11:47:37,267:INFO: Epoch: 27/30, Step: 32/32, Lr: 0.000092770, Loss: 0.000005, Step Loss: 0.000005, Time: 0.075781
2023-06-01 11:47:37,391:INFO: Epoch 27/30 Finished, Train Loss: 0.000010
2023-06-01 11:47:48,944:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.26
2023-06-01 11:47:51,792:INFO: Classfication Metrics:
2023-06-01 11:47:51,792:INFO: f1 score: 0.8734 - precision score: 0.8850 - recall score: 0.8621 - accuracy score: 0.901695
2023-06-01 11:47:51,792:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:47:52,763:INFO: Epoch: 28/30, Step: 1/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.963032
2023-06-01 11:47:52,844:INFO: Epoch: 28/30, Step: 2/32, Lr: 0.000052668, Loss: 0.000059, Step Loss: 0.000059, Time: 0.080750
2023-06-01 11:47:52,940:INFO: Epoch: 28/30, Step: 3/32, Lr: 0.000052668, Loss: 0.000002, Step Loss: 0.000002, Time: 0.095144
2023-06-01 11:47:53,027:INFO: Epoch: 28/30, Step: 4/32, Lr: 0.000052668, Loss: 0.000014, Step Loss: 0.000014, Time: 0.086038
2023-06-01 11:47:53,102:INFO: Epoch: 28/30, Step: 5/32, Lr: 0.000052668, Loss: 0.000025, Step Loss: 0.000025, Time: 0.074578
2023-06-01 11:47:53,176:INFO: Epoch: 28/30, Step: 6/32, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073275
2023-06-01 11:47:53,256:INFO: Epoch: 28/30, Step: 7/32, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079524
2023-06-01 11:47:53,332:INFO: Epoch: 28/30, Step: 8/32, Lr: 0.000052668, Loss: 0.000004, Step Loss: 0.000004, Time: 0.075213
2023-06-01 11:47:53,415:INFO: Epoch: 28/30, Step: 9/32, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.082853
2023-06-01 11:47:53,494:INFO: Epoch: 28/30, Step: 10/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.078514
2023-06-01 11:47:53,583:INFO: Epoch: 28/30, Step: 11/32, Lr: 0.000052668, Loss: 0.000002, Step Loss: 0.000002, Time: 0.088418
2023-06-01 11:47:53,662:INFO: Epoch: 28/30, Step: 12/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.078293
2023-06-01 11:47:53,741:INFO: Epoch: 28/30, Step: 13/32, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078057
2023-06-01 11:47:53,814:INFO: Epoch: 28/30, Step: 14/32, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.073275
2023-06-01 11:47:53,888:INFO: Epoch: 28/30, Step: 15/32, Lr: 0.000052668, Loss: 0.000020, Step Loss: 0.000020, Time: 0.073221
2023-06-01 11:47:53,964:INFO: Epoch: 28/30, Step: 16/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075715
2023-06-01 11:47:54,039:INFO: Epoch: 28/30, Step: 17/32, Lr: 0.000052668, Loss: 0.000011, Step Loss: 0.000011, Time: 0.074234
2023-06-01 11:47:54,119:INFO: Epoch: 28/30, Step: 18/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.078836
2023-06-01 11:47:54,195:INFO: Epoch: 28/30, Step: 19/32, Lr: 0.000052668, Loss: 0.000002, Step Loss: 0.000002, Time: 0.075901
2023-06-01 11:47:54,279:INFO: Epoch: 28/30, Step: 20/32, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.083353
2023-06-01 11:47:54,359:INFO: Epoch: 28/30, Step: 21/32, Lr: 0.000052668, Loss: 0.000017, Step Loss: 0.000017, Time: 0.078833
2023-06-01 11:47:54,431:INFO: Epoch: 28/30, Step: 22/32, Lr: 0.000052668, Loss: 0.003304, Step Loss: 0.003304, Time: 0.071903
2023-06-01 11:47:54,511:INFO: Epoch: 28/30, Step: 23/32, Lr: 0.000052668, Loss: 0.000009, Step Loss: 0.000009, Time: 0.080096
2023-06-01 11:47:54,583:INFO: Epoch: 28/30, Step: 24/32, Lr: 0.000052668, Loss: 0.000026, Step Loss: 0.000026, Time: 0.071666
2023-06-01 11:47:54,655:INFO: Epoch: 28/30, Step: 25/32, Lr: 0.000052668, Loss: 0.000006, Step Loss: 0.000006, Time: 0.071243
2023-06-01 11:47:54,735:INFO: Epoch: 28/30, Step: 26/32, Lr: 0.000052668, Loss: 0.000397, Step Loss: 0.000397, Time: 0.079875
2023-06-01 11:47:54,813:INFO: Epoch: 28/30, Step: 27/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.077839
2023-06-01 11:47:54,895:INFO: Epoch: 28/30, Step: 28/32, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.081779
2023-06-01 11:47:54,967:INFO: Epoch: 28/30, Step: 29/32, Lr: 0.000052668, Loss: 0.000016, Step Loss: 0.000016, Time: 0.071507
2023-06-01 11:47:55,039:INFO: Epoch: 28/30, Step: 30/32, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071712
2023-06-01 11:47:55,115:INFO: Epoch: 28/30, Step: 31/32, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074991
2023-06-01 11:47:55,188:INFO: Epoch: 28/30, Step: 32/32, Lr: 0.000052668, Loss: 0.000012, Step Loss: 0.000012, Time: 0.072914
2023-06-01 11:47:55,349:INFO: Epoch 28/30 Finished, Train Loss: 0.000123
2023-06-01 11:48:02,318:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.27
2023-06-01 11:48:05,166:INFO: Classfication Metrics:
2023-06-01 11:48:05,166:INFO: f1 score: 0.8734 - precision score: 0.8850 - recall score: 0.8621 - accuracy score: 0.901695
2023-06-01 11:48:05,166:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:48:06,436:INFO: Epoch: 29/30, Step: 1/32, Lr: 0.000023563, Loss: 0.000007, Step Loss: 0.000007, Time: 1.247794
2023-06-01 11:48:06,517:INFO: Epoch: 29/30, Step: 2/32, Lr: 0.000023563, Loss: 0.000005, Step Loss: 0.000005, Time: 0.080506
2023-06-01 11:48:06,592:INFO: Epoch: 29/30, Step: 3/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074236
2023-06-01 11:48:06,667:INFO: Epoch: 29/30, Step: 4/32, Lr: 0.000023563, Loss: 0.000007, Step Loss: 0.000007, Time: 0.075368
2023-06-01 11:48:06,739:INFO: Epoch: 29/30, Step: 5/32, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071295
2023-06-01 11:48:06,819:INFO: Epoch: 29/30, Step: 6/32, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.079375
2023-06-01 11:48:06,896:INFO: Epoch: 29/30, Step: 7/32, Lr: 0.000023563, Loss: 0.000005, Step Loss: 0.000005, Time: 0.076395
2023-06-01 11:48:06,975:INFO: Epoch: 29/30, Step: 8/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078411
2023-06-01 11:48:07,061:INFO: Epoch: 29/30, Step: 9/32, Lr: 0.000023563, Loss: 0.000010, Step Loss: 0.000010, Time: 0.085459
2023-06-01 11:48:07,143:INFO: Epoch: 29/30, Step: 10/32, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.081479
2023-06-01 11:48:07,214:INFO: Epoch: 29/30, Step: 11/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070453
2023-06-01 11:48:07,296:INFO: Epoch: 29/30, Step: 12/32, Lr: 0.000023563, Loss: 0.000070, Step Loss: 0.000070, Time: 0.080610
2023-06-01 11:48:07,378:INFO: Epoch: 29/30, Step: 13/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.082103
2023-06-01 11:48:07,454:INFO: Epoch: 29/30, Step: 14/32, Lr: 0.000023563, Loss: 0.000454, Step Loss: 0.000454, Time: 0.075307
2023-06-01 11:48:07,536:INFO: Epoch: 29/30, Step: 15/32, Lr: 0.000023563, Loss: 0.000198, Step Loss: 0.000198, Time: 0.081549
2023-06-01 11:48:07,615:INFO: Epoch: 29/30, Step: 16/32, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.077561
2023-06-01 11:48:07,707:INFO: Epoch: 29/30, Step: 17/32, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.091748
2023-06-01 11:48:07,788:INFO: Epoch: 29/30, Step: 18/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.080017
2023-06-01 11:48:07,864:INFO: Epoch: 29/30, Step: 19/32, Lr: 0.000023563, Loss: 0.000023, Step Loss: 0.000023, Time: 0.075811
2023-06-01 11:48:07,938:INFO: Epoch: 29/30, Step: 20/32, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.073561
2023-06-01 11:48:08,017:INFO: Epoch: 29/30, Step: 21/32, Lr: 0.000023563, Loss: 0.000005, Step Loss: 0.000005, Time: 0.077903
2023-06-01 11:48:08,097:INFO: Epoch: 29/30, Step: 22/32, Lr: 0.000023563, Loss: 0.000051, Step Loss: 0.000051, Time: 0.079386
2023-06-01 11:48:08,169:INFO: Epoch: 29/30, Step: 23/32, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.071389
2023-06-01 11:48:08,248:INFO: Epoch: 29/30, Step: 24/32, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.078749
2023-06-01 11:48:08,340:INFO: Epoch: 29/30, Step: 25/32, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.091246
2023-06-01 11:48:08,415:INFO: Epoch: 29/30, Step: 26/32, Lr: 0.000023563, Loss: 0.000051, Step Loss: 0.000051, Time: 0.074821
2023-06-01 11:48:08,492:INFO: Epoch: 29/30, Step: 27/32, Lr: 0.000023563, Loss: 0.000009, Step Loss: 0.000009, Time: 0.076536
2023-06-01 11:48:08,568:INFO: Epoch: 29/30, Step: 28/32, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074784
2023-06-01 11:48:08,643:INFO: Epoch: 29/30, Step: 29/32, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075097
2023-06-01 11:48:08,717:INFO: Epoch: 29/30, Step: 30/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072679
2023-06-01 11:48:08,799:INFO: Epoch: 29/30, Step: 31/32, Lr: 0.000023563, Loss: 0.000009, Step Loss: 0.000009, Time: 0.081974
2023-06-01 11:48:08,880:INFO: Epoch: 29/30, Step: 32/32, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.080249
2023-06-01 11:48:09,018:INFO: Epoch 29/30 Finished, Train Loss: 0.000029
2023-06-01 11:48:17,326:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.28
2023-06-01 11:48:20,343:INFO: Classfication Metrics:
2023-06-01 11:48:20,343:INFO: f1 score: 0.8734 - precision score: 0.8850 - recall score: 0.8621 - accuracy score: 0.901695
2023-06-01 11:48:20,344:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:48:21,366:INFO: Epoch: 30/30, Step: 1/32, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 1.012938
2023-06-01 11:48:21,443:INFO: Epoch: 30/30, Step: 2/32, Lr: 0.000005914, Loss: 0.000030, Step Loss: 0.000030, Time: 0.076439
2023-06-01 11:48:21,556:INFO: Epoch: 30/30, Step: 3/32, Lr: 0.000005914, Loss: 0.000003, Step Loss: 0.000003, Time: 0.112657
2023-06-01 11:48:21,635:INFO: Epoch: 30/30, Step: 4/32, Lr: 0.000005914, Loss: 0.000016, Step Loss: 0.000016, Time: 0.077934
2023-06-01 11:48:21,712:INFO: Epoch: 30/30, Step: 5/32, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.076364
2023-06-01 11:48:21,784:INFO: Epoch: 30/30, Step: 6/32, Lr: 0.000005914, Loss: 0.000007, Step Loss: 0.000007, Time: 0.071909
2023-06-01 11:48:21,858:INFO: Epoch: 30/30, Step: 7/32, Lr: 0.000005914, Loss: 0.000024, Step Loss: 0.000024, Time: 0.073267
2023-06-01 11:48:21,932:INFO: Epoch: 30/30, Step: 8/32, Lr: 0.000005914, Loss: 0.000007, Step Loss: 0.000007, Time: 0.073456
2023-06-01 11:48:22,023:INFO: Epoch: 30/30, Step: 9/32, Lr: 0.000005914, Loss: 0.000007, Step Loss: 0.000007, Time: 0.090608
2023-06-01 11:48:22,099:INFO: Epoch: 30/30, Step: 10/32, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075497
2023-06-01 11:48:22,176:INFO: Epoch: 30/30, Step: 11/32, Lr: 0.000005914, Loss: 0.000028, Step Loss: 0.000028, Time: 0.076321
2023-06-01 11:48:22,254:INFO: Epoch: 30/30, Step: 12/32, Lr: 0.000005914, Loss: 0.000078, Step Loss: 0.000078, Time: 0.077242
2023-06-01 11:48:22,328:INFO: Epoch: 30/30, Step: 13/32, Lr: 0.000005914, Loss: 0.143953, Step Loss: 0.143953, Time: 0.073059
2023-06-01 11:48:22,404:INFO: Epoch: 30/30, Step: 14/32, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075421
2023-06-01 11:48:22,478:INFO: Epoch: 30/30, Step: 15/32, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073686
2023-06-01 11:48:22,551:INFO: Epoch: 30/30, Step: 16/32, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073084
2023-06-01 11:48:22,643:INFO: Epoch: 30/30, Step: 17/32, Lr: 0.000005914, Loss: 0.000021, Step Loss: 0.000021, Time: 0.090957
2023-06-01 11:48:22,713:INFO: Epoch: 30/30, Step: 18/32, Lr: 0.000005914, Loss: 0.000012, Step Loss: 0.000012, Time: 0.069585
2023-06-01 11:48:22,791:INFO: Epoch: 30/30, Step: 19/32, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.077208
2023-06-01 11:48:22,868:INFO: Epoch: 30/30, Step: 20/32, Lr: 0.000005914, Loss: 0.000005, Step Loss: 0.000005, Time: 0.076370
2023-06-01 11:48:22,948:INFO: Epoch: 30/30, Step: 21/32, Lr: 0.000005914, Loss: 0.000004, Step Loss: 0.000004, Time: 0.079711
2023-06-01 11:48:23,026:INFO: Epoch: 30/30, Step: 22/32, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.078021
2023-06-01 11:48:23,095:INFO: Epoch: 30/30, Step: 23/32, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068616
2023-06-01 11:48:23,172:INFO: Epoch: 30/30, Step: 24/32, Lr: 0.000005914, Loss: 0.000089, Step Loss: 0.000089, Time: 0.075900
2023-06-01 11:48:23,254:INFO: Epoch: 30/30, Step: 25/32, Lr: 0.000005914, Loss: 0.000005, Step Loss: 0.000005, Time: 0.081422
2023-06-01 11:48:23,328:INFO: Epoch: 30/30, Step: 26/32, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073905
2023-06-01 11:48:23,403:INFO: Epoch: 30/30, Step: 27/32, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074296
2023-06-01 11:48:23,477:INFO: Epoch: 30/30, Step: 28/32, Lr: 0.000005914, Loss: 0.000023, Step Loss: 0.000023, Time: 0.072997
2023-06-01 11:48:23,551:INFO: Epoch: 30/30, Step: 29/32, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074054
2023-06-01 11:48:23,627:INFO: Epoch: 30/30, Step: 30/32, Lr: 0.000005914, Loss: 0.000013, Step Loss: 0.000013, Time: 0.075157
2023-06-01 11:48:23,704:INFO: Epoch: 30/30, Step: 31/32, Lr: 0.000005914, Loss: 0.000062, Step Loss: 0.000062, Time: 0.076634
2023-06-01 11:48:23,779:INFO: Epoch: 30/30, Step: 32/32, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.074229
2023-06-01 11:48:23,910:INFO: Epoch 30/30 Finished, Train Loss: 0.004512
2023-06-01 11:48:31,804:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.29
2023-06-01 11:48:34,738:INFO: Classfication Metrics:
2023-06-01 11:48:34,739:INFO: f1 score: 0.8734 - precision score: 0.8850 - recall score: 0.8621 - accuracy score: 0.901695
2023-06-01 11:48:34,739:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6, the F1 is: 0.9013
2023-06-01 11:48:34,739:INFO: ***** Running testing *****
2023-06-01 11:48:34,739:INFO:   Num examples = 295
2023-06-01 11:48:34,739:INFO:   Batch size = 128
2023-06-01 11:48:38,251:INFO: Classfication Metrics:
2023-06-01 11:48:38,252:INFO: f1 score: 0.9013 - precision score: 0.8974 - recall score: 0.9052 - accuracy score: 0.922034
2023-06-01 11:53:35,030:INFO: Effective parameters:
2023-06-01 11:53:35,030:INFO:   <<< CUDA_VISIBLE_DEVICES: 6
2023-06-01 11:53:35,030:INFO:   <<< attention_model: bilinear
2023-06-01 11:53:35,030:INFO:   <<< batch_size: 16
2023-06-01 11:53:35,030:INFO:   <<< batch_size_val: 128
2023-06-01 11:53:35,030:INFO:   <<< dataset: weibo
2023-06-01 11:53:35,030:INFO:   <<< debug: False
2023-06-01 11:53:35,030:INFO:   <<< do_train: True
2023-06-01 11:53:35,030:INFO:   <<< exchange: False
2023-06-01 11:53:35,030:INFO:   <<< exchange_early: False
2023-06-01 11:53:35,030:INFO:   <<< expand_image: True
2023-06-01 11:53:35,030:INFO:   <<< expand_language: True
2023-06-01 11:53:35,030:INFO:   <<< freeze_image: True
2023-06-01 11:53:35,030:INFO:   <<< freeze_language: True
2023-06-01 11:53:35,030:INFO:   <<< image_model_type: clip
2023-06-01 11:53:35,031:INFO:   <<< image_size: 224
2023-06-01 11:53:35,031:INFO:   <<< init_model: 
2023-06-01 11:53:35,031:INFO:   <<< l1_lamda: 0.0002
2023-06-01 11:53:35,031:INFO:   <<< language_model_type: bert
2023-06-01 11:53:35,031:INFO:   <<< local_rank: 0
2023-06-01 11:53:35,031:INFO:   <<< loss_weight: 1,1
2023-06-01 11:53:35,031:INFO:   <<< lr: 0.00015
2023-06-01 11:53:35,031:INFO:   <<< max_text_len: 50
2023-06-01 11:53:35,031:INFO:   <<< more_layer: True
2023-06-01 11:53:35,031:INFO:   <<< n_epochs: 30
2023-06-01 11:53:35,031:INFO:   <<< num_workers: 8
2023-06-01 11:53:35,031:INFO:   <<< output_dir: experiments/weibo/train_weibo_clip_bert_bilinear_more
2023-06-01 11:53:35,031:INFO:   <<< pin_memory: False
2023-06-01 11:53:35,031:INFO:   <<< pretrained_image: True
2023-06-01 11:53:35,031:INFO:   <<< pretrained_language: True
2023-06-01 11:53:35,031:INFO:   <<< rank: 0
2023-06-01 11:53:35,031:INFO:   <<< seed: 42
2023-06-01 11:53:35,031:INFO:   <<< weight_decay: 2e-05
2023-06-01 11:53:35,031:INFO:   <<< world_size: 1
2023-06-01 11:53:35,031:INFO: device: cuda:0 n_gpu: 1
2023-06-01 11:53:42,635:INFO: ***** Running training *****
2023-06-01 11:53:42,635:INFO:   Num examples = 1026
2023-06-01 11:53:42,635:INFO:   Batch size = 16
2023-06-01 11:53:42,635:INFO: ***** Running validation  *****
2023-06-01 11:53:42,635:INFO:   Num examples = 146
2023-06-01 11:53:42,635:INFO:   Batch size = 128
2023-06-01 11:53:43,497:INFO: Epoch: 1/30, Step: 1/64, Lr: 0.000150000, Loss: 1.140348, Step Loss: 1.140348, Time: 0.856425
2023-06-01 11:53:43,771:INFO: Epoch: 1/30, Step: 2/64, Lr: 0.000150000, Loss: 6.910848, Step Loss: 6.910848, Time: 0.274296
2023-06-01 11:53:43,836:INFO: Epoch: 1/30, Step: 3/64, Lr: 0.000150000, Loss: 2.222811, Step Loss: 2.222811, Time: 0.063972
2023-06-01 11:53:43,902:INFO: Epoch: 1/30, Step: 4/64, Lr: 0.000150000, Loss: 1.902938, Step Loss: 1.902938, Time: 0.065932
2023-06-01 11:53:43,966:INFO: Epoch: 1/30, Step: 5/64, Lr: 0.000150000, Loss: 2.341483, Step Loss: 2.341483, Time: 0.064240
2023-06-01 11:53:44,031:INFO: Epoch: 1/30, Step: 6/64, Lr: 0.000150000, Loss: 2.714443, Step Loss: 2.714443, Time: 0.064716
2023-06-01 11:53:44,100:INFO: Epoch: 1/30, Step: 7/64, Lr: 0.000150000, Loss: 1.311948, Step Loss: 1.311948, Time: 0.068998
2023-06-01 11:53:44,170:INFO: Epoch: 1/30, Step: 8/64, Lr: 0.000150000, Loss: 1.578963, Step Loss: 1.578963, Time: 0.069541
2023-06-01 11:53:44,235:INFO: Epoch: 1/30, Step: 9/64, Lr: 0.000150000, Loss: 1.042953, Step Loss: 1.042953, Time: 0.064604
2023-06-01 11:53:44,312:INFO: Epoch: 1/30, Step: 10/64, Lr: 0.000150000, Loss: 2.270415, Step Loss: 2.270415, Time: 0.076471
2023-06-01 11:53:44,383:INFO: Epoch: 1/30, Step: 11/64, Lr: 0.000150000, Loss: 1.831686, Step Loss: 1.831686, Time: 0.070953
2023-06-01 11:53:44,454:INFO: Epoch: 1/30, Step: 12/64, Lr: 0.000150000, Loss: 2.835854, Step Loss: 2.835854, Time: 0.071175
2023-06-01 11:53:44,524:INFO: Epoch: 1/30, Step: 13/64, Lr: 0.000150000, Loss: 0.759902, Step Loss: 0.759902, Time: 0.068961
2023-06-01 11:53:44,592:INFO: Epoch: 1/30, Step: 14/64, Lr: 0.000150000, Loss: 0.720953, Step Loss: 0.720953, Time: 0.067946
2023-06-01 11:53:44,656:INFO: Epoch: 1/30, Step: 15/64, Lr: 0.000150000, Loss: 1.056851, Step Loss: 1.056851, Time: 0.063581
2023-06-01 11:53:44,725:INFO: Epoch: 1/30, Step: 16/64, Lr: 0.000150000, Loss: 1.518614, Step Loss: 1.518614, Time: 0.069270
2023-06-01 11:53:44,793:INFO: Epoch: 1/30, Step: 17/64, Lr: 0.000150000, Loss: 0.559600, Step Loss: 0.559600, Time: 0.067423
2023-06-01 11:53:44,862:INFO: Epoch: 1/30, Step: 18/64, Lr: 0.000150000, Loss: 1.160026, Step Loss: 1.160026, Time: 0.068481
2023-06-01 11:53:44,931:INFO: Epoch: 1/30, Step: 19/64, Lr: 0.000150000, Loss: 1.212575, Step Loss: 1.212575, Time: 0.069397
2023-06-01 11:53:44,995:INFO: Epoch: 1/30, Step: 20/64, Lr: 0.000150000, Loss: 0.373714, Step Loss: 0.373714, Time: 0.063980
2023-06-01 11:53:45,067:INFO: Epoch: 1/30, Step: 21/64, Lr: 0.000150000, Loss: 1.108983, Step Loss: 1.108983, Time: 0.071415
2023-06-01 11:53:45,135:INFO: Epoch: 1/30, Step: 22/64, Lr: 0.000150000, Loss: 0.758584, Step Loss: 0.758584, Time: 0.067979
2023-06-01 11:53:45,203:INFO: Epoch: 1/30, Step: 23/64, Lr: 0.000150000, Loss: 0.751382, Step Loss: 0.751382, Time: 0.067257
2023-06-01 11:53:45,271:INFO: Epoch: 1/30, Step: 24/64, Lr: 0.000150000, Loss: 0.593939, Step Loss: 0.593939, Time: 0.068104
2023-06-01 11:53:45,336:INFO: Epoch: 1/30, Step: 25/64, Lr: 0.000150000, Loss: 0.882869, Step Loss: 0.882869, Time: 0.064159
2023-06-01 11:53:45,411:INFO: Epoch: 1/30, Step: 26/64, Lr: 0.000150000, Loss: 1.376604, Step Loss: 1.376604, Time: 0.074677
2023-06-01 11:53:45,475:INFO: Epoch: 1/30, Step: 27/64, Lr: 0.000150000, Loss: 0.189408, Step Loss: 0.189408, Time: 0.063926
2023-06-01 11:53:45,541:INFO: Epoch: 1/30, Step: 28/64, Lr: 0.000150000, Loss: 1.356349, Step Loss: 1.356349, Time: 0.066239
2023-06-01 11:53:45,610:INFO: Epoch: 1/30, Step: 29/64, Lr: 0.000150000, Loss: 0.615102, Step Loss: 0.615102, Time: 0.068748
2023-06-01 11:53:45,675:INFO: Epoch: 1/30, Step: 30/64, Lr: 0.000150000, Loss: 0.322814, Step Loss: 0.322814, Time: 0.064308
2023-06-01 11:53:45,742:INFO: Epoch: 1/30, Step: 31/64, Lr: 0.000150000, Loss: 1.053597, Step Loss: 1.053597, Time: 0.066854
2023-06-01 11:53:45,811:INFO: Epoch: 1/30, Step: 32/64, Lr: 0.000150000, Loss: 0.255196, Step Loss: 0.255196, Time: 0.068402
2023-06-01 11:53:45,878:INFO: Epoch: 1/30, Step: 33/64, Lr: 0.000150000, Loss: 0.636720, Step Loss: 0.636720, Time: 0.066847
2023-06-01 11:53:45,947:INFO: Epoch: 1/30, Step: 34/64, Lr: 0.000150000, Loss: 0.890695, Step Loss: 0.890695, Time: 0.068774
2023-06-01 11:53:46,015:INFO: Epoch: 1/30, Step: 35/64, Lr: 0.000150000, Loss: 0.469765, Step Loss: 0.469765, Time: 0.067609
2023-06-01 11:53:46,089:INFO: Epoch: 1/30, Step: 36/64, Lr: 0.000150000, Loss: 0.650874, Step Loss: 0.650874, Time: 0.074499
2023-06-01 11:53:46,163:INFO: Epoch: 1/30, Step: 37/64, Lr: 0.000150000, Loss: 0.332410, Step Loss: 0.332410, Time: 0.073339
2023-06-01 11:53:46,238:INFO: Epoch: 1/30, Step: 38/64, Lr: 0.000150000, Loss: 0.548012, Step Loss: 0.548012, Time: 0.074287
2023-06-01 11:53:46,308:INFO: Epoch: 1/30, Step: 39/64, Lr: 0.000150000, Loss: 0.774260, Step Loss: 0.774260, Time: 0.070208
2023-06-01 11:53:46,381:INFO: Epoch: 1/30, Step: 40/64, Lr: 0.000150000, Loss: 0.828653, Step Loss: 0.828653, Time: 0.073043
2023-06-01 11:53:46,455:INFO: Epoch: 1/30, Step: 41/64, Lr: 0.000150000, Loss: 1.133340, Step Loss: 1.133340, Time: 0.073243
2023-06-01 11:53:46,527:INFO: Epoch: 1/30, Step: 42/64, Lr: 0.000150000, Loss: 0.182399, Step Loss: 0.182399, Time: 0.071425
2023-06-01 11:53:46,594:INFO: Epoch: 1/30, Step: 43/64, Lr: 0.000150000, Loss: 0.256001, Step Loss: 0.256001, Time: 0.067546
2023-06-01 11:53:46,662:INFO: Epoch: 1/30, Step: 44/64, Lr: 0.000150000, Loss: 0.695608, Step Loss: 0.695608, Time: 0.067559
2023-06-01 11:53:46,735:INFO: Epoch: 1/30, Step: 45/64, Lr: 0.000150000, Loss: 0.187899, Step Loss: 0.187899, Time: 0.072614
2023-06-01 11:53:46,805:INFO: Epoch: 1/30, Step: 46/64, Lr: 0.000150000, Loss: 0.381107, Step Loss: 0.381107, Time: 0.069459
2023-06-01 11:53:46,871:INFO: Epoch: 1/30, Step: 47/64, Lr: 0.000150000, Loss: 1.071625, Step Loss: 1.071625, Time: 0.066365
2023-06-01 11:53:46,943:INFO: Epoch: 1/30, Step: 48/64, Lr: 0.000150000, Loss: 0.268562, Step Loss: 0.268562, Time: 0.071854
2023-06-01 11:53:47,011:INFO: Epoch: 1/30, Step: 49/64, Lr: 0.000150000, Loss: 0.562669, Step Loss: 0.562669, Time: 0.067433
2023-06-01 11:53:47,086:INFO: Epoch: 1/30, Step: 50/64, Lr: 0.000150000, Loss: 0.667230, Step Loss: 0.667230, Time: 0.074126
2023-06-01 11:53:47,158:INFO: Epoch: 1/30, Step: 51/64, Lr: 0.000150000, Loss: 0.820566, Step Loss: 0.820566, Time: 0.071841
2023-06-01 11:53:47,228:INFO: Epoch: 1/30, Step: 52/64, Lr: 0.000150000, Loss: 0.573300, Step Loss: 0.573300, Time: 0.069715
2023-06-01 11:53:47,294:INFO: Epoch: 1/30, Step: 53/64, Lr: 0.000150000, Loss: 0.425524, Step Loss: 0.425524, Time: 0.066281
2023-06-01 11:53:47,366:INFO: Epoch: 1/30, Step: 54/64, Lr: 0.000150000, Loss: 0.239175, Step Loss: 0.239175, Time: 0.071128
2023-06-01 11:53:47,435:INFO: Epoch: 1/30, Step: 55/64, Lr: 0.000150000, Loss: 1.202604, Step Loss: 1.202604, Time: 0.069252
2023-06-01 11:53:47,500:INFO: Epoch: 1/30, Step: 56/64, Lr: 0.000150000, Loss: 0.765300, Step Loss: 0.765300, Time: 0.064478
2023-06-01 11:53:47,567:INFO: Epoch: 1/30, Step: 57/64, Lr: 0.000150000, Loss: 0.670700, Step Loss: 0.670700, Time: 0.066748
2023-06-01 11:53:47,636:INFO: Epoch: 1/30, Step: 58/64, Lr: 0.000150000, Loss: 0.846114, Step Loss: 0.846114, Time: 0.068449
2023-06-01 11:53:47,702:INFO: Epoch: 1/30, Step: 59/64, Lr: 0.000150000, Loss: 0.393627, Step Loss: 0.393627, Time: 0.066096
2023-06-01 11:53:47,777:INFO: Epoch: 1/30, Step: 60/64, Lr: 0.000150000, Loss: 0.264846, Step Loss: 0.264846, Time: 0.075238
2023-06-01 11:53:47,848:INFO: Epoch: 1/30, Step: 61/64, Lr: 0.000150000, Loss: 0.317568, Step Loss: 0.317568, Time: 0.070459
2023-06-01 11:53:47,918:INFO: Epoch: 1/30, Step: 62/64, Lr: 0.000150000, Loss: 0.152929, Step Loss: 0.152929, Time: 0.069328
2023-06-01 11:53:47,986:INFO: Epoch: 1/30, Step: 63/64, Lr: 0.000150000, Loss: 0.348275, Step Loss: 0.348275, Time: 0.068161
2023-06-01 11:53:48,054:INFO: Epoch: 1/30, Step: 64/64, Lr: 0.000150000, Loss: 0.856876, Step Loss: 0.856876, Time: 0.067877
2023-06-01 11:53:48,208:INFO: Epoch 1/30 Finished, Train Loss: 0.986672
2023-06-01 11:53:56,598:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0
2023-06-01 11:53:59,693:INFO: Classfication Metrics:
2023-06-01 11:53:59,693:INFO: f1 score: 0.8357 - precision score: 0.9175 - recall score: 0.7672 - accuracy score: 0.881356
2023-06-01 11:53:59,693:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0, the F1 is: 0.8357
2023-06-01 11:54:00,748:INFO: Epoch: 2/30, Step: 1/64, Lr: 0.000420000, Loss: 0.440139, Step Loss: 0.440139, Time: 1.035053
2023-06-01 11:54:00,823:INFO: Epoch: 2/30, Step: 2/64, Lr: 0.000420000, Loss: 1.640751, Step Loss: 1.640751, Time: 0.074214
2023-06-01 11:54:00,983:INFO: Epoch: 2/30, Step: 3/64, Lr: 0.000420000, Loss: 1.153906, Step Loss: 1.153906, Time: 0.159462
2023-06-01 11:54:01,047:INFO: Epoch: 2/30, Step: 4/64, Lr: 0.000420000, Loss: 0.308346, Step Loss: 0.308346, Time: 0.063951
2023-06-01 11:54:01,112:INFO: Epoch: 2/30, Step: 5/64, Lr: 0.000420000, Loss: 0.112051, Step Loss: 0.112051, Time: 0.064491
2023-06-01 11:54:01,178:INFO: Epoch: 2/30, Step: 6/64, Lr: 0.000420000, Loss: 0.301229, Step Loss: 0.301229, Time: 0.066034
2023-06-01 11:54:01,258:INFO: Epoch: 2/30, Step: 7/64, Lr: 0.000420000, Loss: 1.805945, Step Loss: 1.805945, Time: 0.080126
2023-06-01 11:54:01,333:INFO: Epoch: 2/30, Step: 8/64, Lr: 0.000420000, Loss: 0.361687, Step Loss: 0.361687, Time: 0.074861
2023-06-01 11:54:01,402:INFO: Epoch: 2/30, Step: 9/64, Lr: 0.000420000, Loss: 0.535260, Step Loss: 0.535260, Time: 0.068218
2023-06-01 11:54:01,472:INFO: Epoch: 2/30, Step: 10/64, Lr: 0.000420000, Loss: 0.876969, Step Loss: 0.876969, Time: 0.069386
2023-06-01 11:54:01,547:INFO: Epoch: 2/30, Step: 11/64, Lr: 0.000420000, Loss: 1.103888, Step Loss: 1.103888, Time: 0.074347
2023-06-01 11:54:01,611:INFO: Epoch: 2/30, Step: 12/64, Lr: 0.000420000, Loss: 1.004712, Step Loss: 1.004712, Time: 0.064257
2023-06-01 11:54:01,684:INFO: Epoch: 2/30, Step: 13/64, Lr: 0.000420000, Loss: 1.759341, Step Loss: 1.759341, Time: 0.072299
2023-06-01 11:54:01,750:INFO: Epoch: 2/30, Step: 14/64, Lr: 0.000420000, Loss: 0.126657, Step Loss: 0.126657, Time: 0.066198
2023-06-01 11:54:01,818:INFO: Epoch: 2/30, Step: 15/64, Lr: 0.000420000, Loss: 0.252452, Step Loss: 0.252452, Time: 0.066889
2023-06-01 11:54:01,883:INFO: Epoch: 2/30, Step: 16/64, Lr: 0.000420000, Loss: 0.982811, Step Loss: 0.982811, Time: 0.065038
2023-06-01 11:54:01,951:INFO: Epoch: 2/30, Step: 17/64, Lr: 0.000420000, Loss: 0.547975, Step Loss: 0.547975, Time: 0.067637
2023-06-01 11:54:02,019:INFO: Epoch: 2/30, Step: 18/64, Lr: 0.000420000, Loss: 1.926625, Step Loss: 1.926625, Time: 0.067489
2023-06-01 11:54:02,091:INFO: Epoch: 2/30, Step: 19/64, Lr: 0.000420000, Loss: 0.114536, Step Loss: 0.114536, Time: 0.071662
2023-06-01 11:54:02,156:INFO: Epoch: 2/30, Step: 20/64, Lr: 0.000420000, Loss: 0.600752, Step Loss: 0.600752, Time: 0.065276
2023-06-01 11:54:02,225:INFO: Epoch: 2/30, Step: 21/64, Lr: 0.000420000, Loss: 1.123609, Step Loss: 1.123609, Time: 0.068178
2023-06-01 11:54:02,294:INFO: Epoch: 2/30, Step: 22/64, Lr: 0.000420000, Loss: 0.933070, Step Loss: 0.933070, Time: 0.069557
2023-06-01 11:54:02,363:INFO: Epoch: 2/30, Step: 23/64, Lr: 0.000420000, Loss: 0.025381, Step Loss: 0.025381, Time: 0.068026
2023-06-01 11:54:02,431:INFO: Epoch: 2/30, Step: 24/64, Lr: 0.000420000, Loss: 0.870341, Step Loss: 0.870341, Time: 0.068557
2023-06-01 11:54:02,503:INFO: Epoch: 2/30, Step: 25/64, Lr: 0.000420000, Loss: 0.410074, Step Loss: 0.410074, Time: 0.070704
2023-06-01 11:54:02,566:INFO: Epoch: 2/30, Step: 26/64, Lr: 0.000420000, Loss: 0.887525, Step Loss: 0.887525, Time: 0.063440
2023-06-01 11:54:02,641:INFO: Epoch: 2/30, Step: 27/64, Lr: 0.000420000, Loss: 0.266189, Step Loss: 0.266189, Time: 0.074025
2023-06-01 11:54:02,710:INFO: Epoch: 2/30, Step: 28/64, Lr: 0.000420000, Loss: 1.384416, Step Loss: 1.384416, Time: 0.069238
2023-06-01 11:54:02,779:INFO: Epoch: 2/30, Step: 29/64, Lr: 0.000420000, Loss: 0.332581, Step Loss: 0.332581, Time: 0.068602
2023-06-01 11:54:02,852:INFO: Epoch: 2/30, Step: 30/64, Lr: 0.000420000, Loss: 1.884591, Step Loss: 1.884591, Time: 0.072554
2023-06-01 11:54:02,925:INFO: Epoch: 2/30, Step: 31/64, Lr: 0.000420000, Loss: 0.413165, Step Loss: 0.413165, Time: 0.072774
2023-06-01 11:54:02,994:INFO: Epoch: 2/30, Step: 32/64, Lr: 0.000420000, Loss: 0.420731, Step Loss: 0.420731, Time: 0.068289
2023-06-01 11:54:03,067:INFO: Epoch: 2/30, Step: 33/64, Lr: 0.000420000, Loss: 1.438253, Step Loss: 1.438253, Time: 0.072608
2023-06-01 11:54:03,131:INFO: Epoch: 2/30, Step: 34/64, Lr: 0.000420000, Loss: 0.255731, Step Loss: 0.255731, Time: 0.063961
2023-06-01 11:54:03,199:INFO: Epoch: 2/30, Step: 35/64, Lr: 0.000420000, Loss: 0.773637, Step Loss: 0.773637, Time: 0.067598
2023-06-01 11:54:03,272:INFO: Epoch: 2/30, Step: 36/64, Lr: 0.000420000, Loss: 0.168960, Step Loss: 0.168960, Time: 0.072362
2023-06-01 11:54:03,348:INFO: Epoch: 2/30, Step: 37/64, Lr: 0.000420000, Loss: 0.547486, Step Loss: 0.547486, Time: 0.075778
2023-06-01 11:54:03,415:INFO: Epoch: 2/30, Step: 38/64, Lr: 0.000420000, Loss: 0.584652, Step Loss: 0.584652, Time: 0.067096
2023-06-01 11:54:03,486:INFO: Epoch: 2/30, Step: 39/64, Lr: 0.000420000, Loss: 2.202871, Step Loss: 2.202871, Time: 0.070256
2023-06-01 11:54:03,555:INFO: Epoch: 2/30, Step: 40/64, Lr: 0.000420000, Loss: 1.475484, Step Loss: 1.475484, Time: 0.068373
2023-06-01 11:54:03,623:INFO: Epoch: 2/30, Step: 41/64, Lr: 0.000420000, Loss: 0.930107, Step Loss: 0.930107, Time: 0.067888
2023-06-01 11:54:03,693:INFO: Epoch: 2/30, Step: 42/64, Lr: 0.000420000, Loss: 2.918188, Step Loss: 2.918188, Time: 0.070019
2023-06-01 11:54:03,767:INFO: Epoch: 2/30, Step: 43/64, Lr: 0.000420000, Loss: 1.041742, Step Loss: 1.041742, Time: 0.072992
2023-06-01 11:54:03,832:INFO: Epoch: 2/30, Step: 44/64, Lr: 0.000420000, Loss: 0.557810, Step Loss: 0.557810, Time: 0.065410
2023-06-01 11:54:03,907:INFO: Epoch: 2/30, Step: 45/64, Lr: 0.000420000, Loss: 0.949403, Step Loss: 0.949403, Time: 0.074093
2023-06-01 11:54:03,977:INFO: Epoch: 2/30, Step: 46/64, Lr: 0.000420000, Loss: 2.229784, Step Loss: 2.229784, Time: 0.070573
2023-06-01 11:54:04,043:INFO: Epoch: 2/30, Step: 47/64, Lr: 0.000420000, Loss: 0.006781, Step Loss: 0.006781, Time: 0.065549
2023-06-01 11:54:04,112:INFO: Epoch: 2/30, Step: 48/64, Lr: 0.000420000, Loss: 1.015533, Step Loss: 1.015533, Time: 0.068802
2023-06-01 11:54:04,183:INFO: Epoch: 2/30, Step: 49/64, Lr: 0.000420000, Loss: 1.377567, Step Loss: 1.377567, Time: 0.070166
2023-06-01 11:54:04,253:INFO: Epoch: 2/30, Step: 50/64, Lr: 0.000420000, Loss: 2.115050, Step Loss: 2.115050, Time: 0.070231
2023-06-01 11:54:04,327:INFO: Epoch: 2/30, Step: 51/64, Lr: 0.000420000, Loss: 1.726568, Step Loss: 1.726568, Time: 0.073503
2023-06-01 11:54:04,399:INFO: Epoch: 2/30, Step: 52/64, Lr: 0.000420000, Loss: 0.386512, Step Loss: 0.386512, Time: 0.072309
2023-06-01 11:54:04,474:INFO: Epoch: 2/30, Step: 53/64, Lr: 0.000420000, Loss: 2.493003, Step Loss: 2.493003, Time: 0.074519
2023-06-01 11:54:04,543:INFO: Epoch: 2/30, Step: 54/64, Lr: 0.000420000, Loss: 6.301786, Step Loss: 6.301786, Time: 0.068138
2023-06-01 11:54:04,611:INFO: Epoch: 2/30, Step: 55/64, Lr: 0.000420000, Loss: 3.406369, Step Loss: 3.406369, Time: 0.067825
2023-06-01 11:54:04,688:INFO: Epoch: 2/30, Step: 56/64, Lr: 0.000420000, Loss: 0.505190, Step Loss: 0.505190, Time: 0.077459
2023-06-01 11:54:04,755:INFO: Epoch: 2/30, Step: 57/64, Lr: 0.000420000, Loss: 1.804945, Step Loss: 1.804945, Time: 0.065986
2023-06-01 11:54:04,827:INFO: Epoch: 2/30, Step: 58/64, Lr: 0.000420000, Loss: 5.259760, Step Loss: 5.259760, Time: 0.072034
2023-06-01 11:54:04,897:INFO: Epoch: 2/30, Step: 59/64, Lr: 0.000420000, Loss: 8.287406, Step Loss: 8.287406, Time: 0.069965
2023-06-01 11:54:04,972:INFO: Epoch: 2/30, Step: 60/64, Lr: 0.000420000, Loss: 1.108655, Step Loss: 1.108655, Time: 0.074533
2023-06-01 11:54:05,047:INFO: Epoch: 2/30, Step: 61/64, Lr: 0.000420000, Loss: 1.040994, Step Loss: 1.040994, Time: 0.074662
2023-06-01 11:54:05,114:INFO: Epoch: 2/30, Step: 62/64, Lr: 0.000420000, Loss: 0.985915, Step Loss: 0.985915, Time: 0.066981
2023-06-01 11:54:05,183:INFO: Epoch: 2/30, Step: 63/64, Lr: 0.000420000, Loss: 2.854825, Step Loss: 2.854825, Time: 0.068374
2023-06-01 11:54:05,251:INFO: Epoch: 2/30, Step: 64/64, Lr: 0.000420000, Loss: 3.116283, Step Loss: 3.116283, Time: 0.067610
2023-06-01 11:54:05,408:INFO: Epoch 2/30 Finished, Train Loss: 1.324609
2023-06-01 11:54:13,853:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.1
2023-06-01 11:54:17,010:INFO: Classfication Metrics:
2023-06-01 11:54:17,010:INFO: f1 score: 0.7412 - precision score: 0.5888 - recall score: 1.0000 - accuracy score: 0.725424
2023-06-01 11:54:17,011:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.0, the F1 is: 0.8357
2023-06-01 11:54:18,099:INFO: Epoch: 3/30, Step: 1/64, Lr: 0.000690000, Loss: 3.889876, Step Loss: 3.889876, Time: 1.080311
2023-06-01 11:54:18,167:INFO: Epoch: 3/30, Step: 2/64, Lr: 0.000690000, Loss: 0.196510, Step Loss: 0.196510, Time: 0.066871
2023-06-01 11:54:18,231:INFO: Epoch: 3/30, Step: 3/64, Lr: 0.000690000, Loss: 3.194738, Step Loss: 3.194738, Time: 0.064189
2023-06-01 11:54:18,302:INFO: Epoch: 3/30, Step: 4/64, Lr: 0.000690000, Loss: 1.500095, Step Loss: 1.500095, Time: 0.069979
2023-06-01 11:54:18,367:INFO: Epoch: 3/30, Step: 5/64, Lr: 0.000690000, Loss: 1.425878, Step Loss: 1.425878, Time: 0.065448
2023-06-01 11:54:18,436:INFO: Epoch: 3/30, Step: 6/64, Lr: 0.000690000, Loss: 0.904222, Step Loss: 0.904222, Time: 0.068426
2023-06-01 11:54:18,503:INFO: Epoch: 3/30, Step: 7/64, Lr: 0.000690000, Loss: 1.821718, Step Loss: 1.821718, Time: 0.066007
2023-06-01 11:54:18,583:INFO: Epoch: 3/30, Step: 8/64, Lr: 0.000690000, Loss: 0.104535, Step Loss: 0.104535, Time: 0.079796
2023-06-01 11:54:18,647:INFO: Epoch: 3/30, Step: 9/64, Lr: 0.000690000, Loss: 1.404048, Step Loss: 1.404048, Time: 0.064270
2023-06-01 11:54:18,718:INFO: Epoch: 3/30, Step: 10/64, Lr: 0.000690000, Loss: 0.454666, Step Loss: 0.454666, Time: 0.069886
2023-06-01 11:54:18,787:INFO: Epoch: 3/30, Step: 11/64, Lr: 0.000690000, Loss: 3.097847, Step Loss: 3.097847, Time: 0.068820
2023-06-01 11:54:18,855:INFO: Epoch: 3/30, Step: 12/64, Lr: 0.000690000, Loss: 1.141567, Step Loss: 1.141567, Time: 0.067711
2023-06-01 11:54:18,925:INFO: Epoch: 3/30, Step: 13/64, Lr: 0.000690000, Loss: 1.408303, Step Loss: 1.408303, Time: 0.069278
2023-06-01 11:54:18,992:INFO: Epoch: 3/30, Step: 14/64, Lr: 0.000690000, Loss: 1.078812, Step Loss: 1.078812, Time: 0.066693
2023-06-01 11:54:19,061:INFO: Epoch: 3/30, Step: 15/64, Lr: 0.000690000, Loss: 2.673293, Step Loss: 2.673293, Time: 0.068543
2023-06-01 11:54:19,140:INFO: Epoch: 3/30, Step: 16/64, Lr: 0.000690000, Loss: 0.971631, Step Loss: 0.971631, Time: 0.078507
2023-06-01 11:54:19,210:INFO: Epoch: 3/30, Step: 17/64, Lr: 0.000690000, Loss: 0.784051, Step Loss: 0.784051, Time: 0.070162
2023-06-01 11:54:19,288:INFO: Epoch: 3/30, Step: 18/64, Lr: 0.000690000, Loss: 0.743048, Step Loss: 0.743048, Time: 0.077232
2023-06-01 11:54:19,355:INFO: Epoch: 3/30, Step: 19/64, Lr: 0.000690000, Loss: 0.112041, Step Loss: 0.112041, Time: 0.067022
2023-06-01 11:54:19,423:INFO: Epoch: 3/30, Step: 20/64, Lr: 0.000690000, Loss: 0.511913, Step Loss: 0.511913, Time: 0.067580
2023-06-01 11:54:19,495:INFO: Epoch: 3/30, Step: 21/64, Lr: 0.000690000, Loss: 0.152006, Step Loss: 0.152006, Time: 0.071629
2023-06-01 11:54:19,564:INFO: Epoch: 3/30, Step: 22/64, Lr: 0.000690000, Loss: 0.883186, Step Loss: 0.883186, Time: 0.068330
2023-06-01 11:54:19,631:INFO: Epoch: 3/30, Step: 23/64, Lr: 0.000690000, Loss: 0.621493, Step Loss: 0.621493, Time: 0.066543
2023-06-01 11:54:19,695:INFO: Epoch: 3/30, Step: 24/64, Lr: 0.000690000, Loss: 0.418809, Step Loss: 0.418809, Time: 0.064627
2023-06-01 11:54:19,771:INFO: Epoch: 3/30, Step: 25/64, Lr: 0.000690000, Loss: 1.996757, Step Loss: 1.996757, Time: 0.074940
2023-06-01 11:54:19,835:INFO: Epoch: 3/30, Step: 26/64, Lr: 0.000690000, Loss: 0.111534, Step Loss: 0.111534, Time: 0.064180
2023-06-01 11:54:19,901:INFO: Epoch: 3/30, Step: 27/64, Lr: 0.000690000, Loss: 3.100641, Step Loss: 3.100641, Time: 0.065958
2023-06-01 11:54:19,968:INFO: Epoch: 3/30, Step: 28/64, Lr: 0.000690000, Loss: 0.309377, Step Loss: 0.309377, Time: 0.066388
2023-06-01 11:54:20,043:INFO: Epoch: 3/30, Step: 29/64, Lr: 0.000690000, Loss: 1.297450, Step Loss: 1.297450, Time: 0.074292
2023-06-01 11:54:20,121:INFO: Epoch: 3/30, Step: 30/64, Lr: 0.000690000, Loss: 0.157311, Step Loss: 0.157311, Time: 0.078190
2023-06-01 11:54:20,191:INFO: Epoch: 3/30, Step: 31/64, Lr: 0.000690000, Loss: 2.743389, Step Loss: 2.743389, Time: 0.069979
2023-06-01 11:54:20,261:INFO: Epoch: 3/30, Step: 32/64, Lr: 0.000690000, Loss: 1.247034, Step Loss: 1.247034, Time: 0.069831
2023-06-01 11:54:20,332:INFO: Epoch: 3/30, Step: 33/64, Lr: 0.000690000, Loss: 2.536270, Step Loss: 2.536270, Time: 0.070226
2023-06-01 11:54:20,402:INFO: Epoch: 3/30, Step: 34/64, Lr: 0.000690000, Loss: 1.308723, Step Loss: 1.308723, Time: 0.070205
2023-06-01 11:54:20,479:INFO: Epoch: 3/30, Step: 35/64, Lr: 0.000690000, Loss: 1.657890, Step Loss: 1.657890, Time: 0.076655
2023-06-01 11:54:20,546:INFO: Epoch: 3/30, Step: 36/64, Lr: 0.000690000, Loss: 2.603825, Step Loss: 2.603825, Time: 0.066693
2023-06-01 11:54:20,615:INFO: Epoch: 3/30, Step: 37/64, Lr: 0.000690000, Loss: 4.117654, Step Loss: 4.117654, Time: 0.068119
2023-06-01 11:54:20,683:INFO: Epoch: 3/30, Step: 38/64, Lr: 0.000690000, Loss: 0.748207, Step Loss: 0.748207, Time: 0.067843
2023-06-01 11:54:20,758:INFO: Epoch: 3/30, Step: 39/64, Lr: 0.000690000, Loss: 0.099357, Step Loss: 0.099357, Time: 0.075150
2023-06-01 11:54:20,823:INFO: Epoch: 3/30, Step: 40/64, Lr: 0.000690000, Loss: 0.046912, Step Loss: 0.046912, Time: 0.064822
2023-06-01 11:54:20,887:INFO: Epoch: 3/30, Step: 41/64, Lr: 0.000690000, Loss: 4.063559, Step Loss: 4.063559, Time: 0.064080
2023-06-01 11:54:20,950:INFO: Epoch: 3/30, Step: 42/64, Lr: 0.000690000, Loss: 2.160087, Step Loss: 2.160087, Time: 0.062494
2023-06-01 11:54:21,018:INFO: Epoch: 3/30, Step: 43/64, Lr: 0.000690000, Loss: 0.803319, Step Loss: 0.803319, Time: 0.067484
2023-06-01 11:54:21,086:INFO: Epoch: 3/30, Step: 44/64, Lr: 0.000690000, Loss: 0.024209, Step Loss: 0.024209, Time: 0.067891
2023-06-01 11:54:21,159:INFO: Epoch: 3/30, Step: 45/64, Lr: 0.000690000, Loss: 0.023119, Step Loss: 0.023119, Time: 0.072685
2023-06-01 11:54:21,229:INFO: Epoch: 3/30, Step: 46/64, Lr: 0.000690000, Loss: 1.519014, Step Loss: 1.519014, Time: 0.070236
2023-06-01 11:54:21,298:INFO: Epoch: 3/30, Step: 47/64, Lr: 0.000690000, Loss: 4.683397, Step Loss: 4.683397, Time: 0.068792
2023-06-01 11:54:21,367:INFO: Epoch: 3/30, Step: 48/64, Lr: 0.000690000, Loss: 2.094384, Step Loss: 2.094384, Time: 0.067821
2023-06-01 11:54:21,438:INFO: Epoch: 3/30, Step: 49/64, Lr: 0.000690000, Loss: 0.503421, Step Loss: 0.503421, Time: 0.071065
2023-06-01 11:54:21,503:INFO: Epoch: 3/30, Step: 50/64, Lr: 0.000690000, Loss: 0.345787, Step Loss: 0.345787, Time: 0.064665
2023-06-01 11:54:21,569:INFO: Epoch: 3/30, Step: 51/64, Lr: 0.000690000, Loss: 1.239335, Step Loss: 1.239335, Time: 0.066073
2023-06-01 11:54:21,636:INFO: Epoch: 3/30, Step: 52/64, Lr: 0.000690000, Loss: 2.457250, Step Loss: 2.457250, Time: 0.066435
2023-06-01 11:54:21,704:INFO: Epoch: 3/30, Step: 53/64, Lr: 0.000690000, Loss: 1.093225, Step Loss: 1.093225, Time: 0.067283
2023-06-01 11:54:21,768:INFO: Epoch: 3/30, Step: 54/64, Lr: 0.000690000, Loss: 0.078207, Step Loss: 0.078207, Time: 0.063883
2023-06-01 11:54:21,840:INFO: Epoch: 3/30, Step: 55/64, Lr: 0.000690000, Loss: 0.112640, Step Loss: 0.112640, Time: 0.072160
2023-06-01 11:54:21,906:INFO: Epoch: 3/30, Step: 56/64, Lr: 0.000690000, Loss: 1.294976, Step Loss: 1.294976, Time: 0.065489
2023-06-01 11:54:21,973:INFO: Epoch: 3/30, Step: 57/64, Lr: 0.000690000, Loss: 0.359624, Step Loss: 0.359624, Time: 0.066476
2023-06-01 11:54:22,042:INFO: Epoch: 3/30, Step: 58/64, Lr: 0.000690000, Loss: 0.360155, Step Loss: 0.360155, Time: 0.068764
2023-06-01 11:54:22,115:INFO: Epoch: 3/30, Step: 59/64, Lr: 0.000690000, Loss: 0.021508, Step Loss: 0.021508, Time: 0.072301
2023-06-01 11:54:22,183:INFO: Epoch: 3/30, Step: 60/64, Lr: 0.000690000, Loss: 0.063668, Step Loss: 0.063668, Time: 0.067320
2023-06-01 11:54:22,253:INFO: Epoch: 3/30, Step: 61/64, Lr: 0.000690000, Loss: 0.014739, Step Loss: 0.014739, Time: 0.070023
2023-06-01 11:54:22,324:INFO: Epoch: 3/30, Step: 62/64, Lr: 0.000690000, Loss: 1.051121, Step Loss: 1.051121, Time: 0.070340
2023-06-01 11:54:22,388:INFO: Epoch: 3/30, Step: 63/64, Lr: 0.000690000, Loss: 1.874480, Step Loss: 1.874480, Time: 0.064299
2023-06-01 11:54:22,454:INFO: Epoch: 3/30, Step: 64/64, Lr: 0.000690000, Loss: 0.515291, Step Loss: 0.515291, Time: 0.066036
2023-06-01 11:54:22,599:INFO: Epoch 3/30 Finished, Train Loss: 1.255205
2023-06-01 11:54:30,139:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2
2023-06-01 11:54:33,358:INFO: Classfication Metrics:
2023-06-01 11:54:33,358:INFO: f1 score: 0.8472 - precision score: 0.8584 - recall score: 0.8362 - accuracy score: 0.881356
2023-06-01 11:54:33,358:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.2, the F1 is: 0.8472
2023-06-01 11:54:34,364:INFO: Epoch: 4/30, Step: 1/64, Lr: 0.001230000, Loss: 0.007126, Step Loss: 0.007126, Time: 0.998247
2023-06-01 11:54:34,437:INFO: Epoch: 4/30, Step: 2/64, Lr: 0.001230000, Loss: 0.035398, Step Loss: 0.035398, Time: 0.072354
2023-06-01 11:54:34,510:INFO: Epoch: 4/30, Step: 3/64, Lr: 0.001230000, Loss: 0.382491, Step Loss: 0.382491, Time: 0.072373
2023-06-01 11:54:34,682:INFO: Epoch: 4/30, Step: 4/64, Lr: 0.001230000, Loss: 0.799381, Step Loss: 0.799381, Time: 0.172246
2023-06-01 11:54:34,757:INFO: Epoch: 4/30, Step: 5/64, Lr: 0.001230000, Loss: 0.757513, Step Loss: 0.757513, Time: 0.073945
2023-06-01 11:54:34,829:INFO: Epoch: 4/30, Step: 6/64, Lr: 0.001230000, Loss: 0.799526, Step Loss: 0.799526, Time: 0.071614
2023-06-01 11:54:34,895:INFO: Epoch: 4/30, Step: 7/64, Lr: 0.001230000, Loss: 0.925891, Step Loss: 0.925891, Time: 0.065423
2023-06-01 11:54:34,966:INFO: Epoch: 4/30, Step: 8/64, Lr: 0.001230000, Loss: 2.164320, Step Loss: 2.164320, Time: 0.071135
2023-06-01 11:54:35,031:INFO: Epoch: 4/30, Step: 9/64, Lr: 0.001230000, Loss: 0.158719, Step Loss: 0.158719, Time: 0.064633
2023-06-01 11:54:35,107:INFO: Epoch: 4/30, Step: 10/64, Lr: 0.001230000, Loss: 0.365330, Step Loss: 0.365330, Time: 0.075623
2023-06-01 11:54:35,171:INFO: Epoch: 4/30, Step: 11/64, Lr: 0.001230000, Loss: 1.266165, Step Loss: 1.266165, Time: 0.063718
2023-06-01 11:54:35,242:INFO: Epoch: 4/30, Step: 12/64, Lr: 0.001230000, Loss: 1.357046, Step Loss: 1.357046, Time: 0.070843
2023-06-01 11:54:35,312:INFO: Epoch: 4/30, Step: 13/64, Lr: 0.001230000, Loss: 1.359042, Step Loss: 1.359042, Time: 0.068745
2023-06-01 11:54:35,384:INFO: Epoch: 4/30, Step: 14/64, Lr: 0.001230000, Loss: 0.869149, Step Loss: 0.869149, Time: 0.072163
2023-06-01 11:54:35,454:INFO: Epoch: 4/30, Step: 15/64, Lr: 0.001230000, Loss: 2.194896, Step Loss: 2.194896, Time: 0.069989
2023-06-01 11:54:35,524:INFO: Epoch: 4/30, Step: 16/64, Lr: 0.001230000, Loss: 0.668498, Step Loss: 0.668498, Time: 0.068612
2023-06-01 11:54:35,590:INFO: Epoch: 4/30, Step: 17/64, Lr: 0.001230000, Loss: 0.080666, Step Loss: 0.080666, Time: 0.066467
2023-06-01 11:54:35,658:INFO: Epoch: 4/30, Step: 18/64, Lr: 0.001230000, Loss: 0.411993, Step Loss: 0.411993, Time: 0.067100
2023-06-01 11:54:35,723:INFO: Epoch: 4/30, Step: 19/64, Lr: 0.001230000, Loss: 0.654766, Step Loss: 0.654766, Time: 0.064435
2023-06-01 11:54:35,801:INFO: Epoch: 4/30, Step: 20/64, Lr: 0.001230000, Loss: 0.038069, Step Loss: 0.038069, Time: 0.077458
2023-06-01 11:54:35,867:INFO: Epoch: 4/30, Step: 21/64, Lr: 0.001230000, Loss: 0.524685, Step Loss: 0.524685, Time: 0.065732
2023-06-01 11:54:35,936:INFO: Epoch: 4/30, Step: 22/64, Lr: 0.001230000, Loss: 1.285895, Step Loss: 1.285895, Time: 0.068650
2023-06-01 11:54:36,007:INFO: Epoch: 4/30, Step: 23/64, Lr: 0.001230000, Loss: 0.098697, Step Loss: 0.098697, Time: 0.070349
2023-06-01 11:54:36,078:INFO: Epoch: 4/30, Step: 24/64, Lr: 0.001230000, Loss: 1.365082, Step Loss: 1.365082, Time: 0.070611
2023-06-01 11:54:36,143:INFO: Epoch: 4/30, Step: 25/64, Lr: 0.001230000, Loss: 0.138030, Step Loss: 0.138030, Time: 0.064888
2023-06-01 11:54:36,222:INFO: Epoch: 4/30, Step: 26/64, Lr: 0.001230000, Loss: 0.697368, Step Loss: 0.697368, Time: 0.078255
2023-06-01 11:54:36,286:INFO: Epoch: 4/30, Step: 27/64, Lr: 0.001230000, Loss: 0.675301, Step Loss: 0.675301, Time: 0.064193
2023-06-01 11:54:36,354:INFO: Epoch: 4/30, Step: 28/64, Lr: 0.001230000, Loss: 0.300204, Step Loss: 0.300204, Time: 0.067260
2023-06-01 11:54:36,419:INFO: Epoch: 4/30, Step: 29/64, Lr: 0.001230000, Loss: 0.004476, Step Loss: 0.004476, Time: 0.064769
2023-06-01 11:54:36,486:INFO: Epoch: 4/30, Step: 30/64, Lr: 0.001230000, Loss: 1.260505, Step Loss: 1.260505, Time: 0.066324
2023-06-01 11:54:36,551:INFO: Epoch: 4/30, Step: 31/64, Lr: 0.001230000, Loss: 0.243347, Step Loss: 0.243347, Time: 0.064524
2023-06-01 11:54:36,618:INFO: Epoch: 4/30, Step: 32/64, Lr: 0.001230000, Loss: 0.324012, Step Loss: 0.324012, Time: 0.066334
2023-06-01 11:54:36,686:INFO: Epoch: 4/30, Step: 33/64, Lr: 0.001230000, Loss: 0.646494, Step Loss: 0.646494, Time: 0.067649
2023-06-01 11:54:36,754:INFO: Epoch: 4/30, Step: 34/64, Lr: 0.001230000, Loss: 1.100100, Step Loss: 1.100100, Time: 0.067709
2023-06-01 11:54:36,826:INFO: Epoch: 4/30, Step: 35/64, Lr: 0.001230000, Loss: 0.307495, Step Loss: 0.307495, Time: 0.071632
2023-06-01 11:54:36,894:INFO: Epoch: 4/30, Step: 36/64, Lr: 0.001230000, Loss: 0.933463, Step Loss: 0.933463, Time: 0.067490
2023-06-01 11:54:36,963:INFO: Epoch: 4/30, Step: 37/64, Lr: 0.001230000, Loss: 0.261067, Step Loss: 0.261067, Time: 0.068209
2023-06-01 11:54:37,031:INFO: Epoch: 4/30, Step: 38/64, Lr: 0.001230000, Loss: 0.032436, Step Loss: 0.032436, Time: 0.068313
2023-06-01 11:54:37,102:INFO: Epoch: 4/30, Step: 39/64, Lr: 0.001230000, Loss: 0.696355, Step Loss: 0.696355, Time: 0.070754
2023-06-01 11:54:37,170:INFO: Epoch: 4/30, Step: 40/64, Lr: 0.001230000, Loss: 0.348050, Step Loss: 0.348050, Time: 0.067024
2023-06-01 11:54:37,247:INFO: Epoch: 4/30, Step: 41/64, Lr: 0.001230000, Loss: 0.317981, Step Loss: 0.317981, Time: 0.076460
2023-06-01 11:54:37,314:INFO: Epoch: 4/30, Step: 42/64, Lr: 0.001230000, Loss: 0.686342, Step Loss: 0.686342, Time: 0.067047
2023-06-01 11:54:37,382:INFO: Epoch: 4/30, Step: 43/64, Lr: 0.001230000, Loss: 0.998380, Step Loss: 0.998380, Time: 0.067735
2023-06-01 11:54:37,453:INFO: Epoch: 4/30, Step: 44/64, Lr: 0.001230000, Loss: 0.036414, Step Loss: 0.036414, Time: 0.070032
2023-06-01 11:54:37,531:INFO: Epoch: 4/30, Step: 45/64, Lr: 0.001230000, Loss: 1.460701, Step Loss: 1.460701, Time: 0.077205
2023-06-01 11:54:37,598:INFO: Epoch: 4/30, Step: 46/64, Lr: 0.001230000, Loss: 1.112147, Step Loss: 1.112147, Time: 0.066637
2023-06-01 11:54:37,663:INFO: Epoch: 4/30, Step: 47/64, Lr: 0.001230000, Loss: 0.598437, Step Loss: 0.598437, Time: 0.064842
2023-06-01 11:54:37,728:INFO: Epoch: 4/30, Step: 48/64, Lr: 0.001230000, Loss: 0.825191, Step Loss: 0.825191, Time: 0.064152
2023-06-01 11:54:37,794:INFO: Epoch: 4/30, Step: 49/64, Lr: 0.001230000, Loss: 3.183791, Step Loss: 3.183791, Time: 0.065539
2023-06-01 11:54:37,862:INFO: Epoch: 4/30, Step: 50/64, Lr: 0.001230000, Loss: 0.268550, Step Loss: 0.268550, Time: 0.067792
2023-06-01 11:54:37,930:INFO: Epoch: 4/30, Step: 51/64, Lr: 0.001230000, Loss: 0.545077, Step Loss: 0.545077, Time: 0.067630
2023-06-01 11:54:37,998:INFO: Epoch: 4/30, Step: 52/64, Lr: 0.001230000, Loss: 0.459463, Step Loss: 0.459463, Time: 0.067638
2023-06-01 11:54:38,066:INFO: Epoch: 4/30, Step: 53/64, Lr: 0.001230000, Loss: 0.663631, Step Loss: 0.663631, Time: 0.067689
2023-06-01 11:54:38,135:INFO: Epoch: 4/30, Step: 54/64, Lr: 0.001230000, Loss: 1.201439, Step Loss: 1.201439, Time: 0.068502
2023-06-01 11:54:38,199:INFO: Epoch: 4/30, Step: 55/64, Lr: 0.001230000, Loss: 0.045506, Step Loss: 0.045506, Time: 0.063890
2023-06-01 11:54:38,267:INFO: Epoch: 4/30, Step: 56/64, Lr: 0.001230000, Loss: 0.273872, Step Loss: 0.273872, Time: 0.067109
2023-06-01 11:54:38,338:INFO: Epoch: 4/30, Step: 57/64, Lr: 0.001230000, Loss: 0.472535, Step Loss: 0.472535, Time: 0.071230
2023-06-01 11:54:38,411:INFO: Epoch: 4/30, Step: 58/64, Lr: 0.001230000, Loss: 0.749208, Step Loss: 0.749208, Time: 0.071743
2023-06-01 11:54:38,478:INFO: Epoch: 4/30, Step: 59/64, Lr: 0.001230000, Loss: 1.152360, Step Loss: 1.152360, Time: 0.066891
2023-06-01 11:54:38,551:INFO: Epoch: 4/30, Step: 60/64, Lr: 0.001230000, Loss: 0.016684, Step Loss: 0.016684, Time: 0.072247
2023-06-01 11:54:38,618:INFO: Epoch: 4/30, Step: 61/64, Lr: 0.001230000, Loss: 1.030951, Step Loss: 1.030951, Time: 0.067058
2023-06-01 11:54:38,686:INFO: Epoch: 4/30, Step: 62/64, Lr: 0.001230000, Loss: 0.218199, Step Loss: 0.218199, Time: 0.067863
2023-06-01 11:54:38,754:INFO: Epoch: 4/30, Step: 63/64, Lr: 0.001230000, Loss: 0.567198, Step Loss: 0.567198, Time: 0.067631
2023-06-01 11:54:38,822:INFO: Epoch: 4/30, Step: 64/64, Lr: 0.001230000, Loss: 0.059911, Step Loss: 0.059911, Time: 0.067258
2023-06-01 11:54:38,981:INFO: Epoch 4/30 Finished, Train Loss: 0.679422
2023-06-01 11:54:47,090:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.3
2023-06-01 11:54:50,232:INFO: Classfication Metrics:
2023-06-01 11:54:50,232:INFO: f1 score: 0.8494 - precision score: 0.7692 - recall score: 0.9483 - accuracy score: 0.867797
2023-06-01 11:54:50,232:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.3, the F1 is: 0.8494
2023-06-01 11:54:51,382:INFO: Epoch: 5/30, Step: 1/64, Lr: 0.001500000, Loss: 0.204359, Step Loss: 0.204359, Time: 1.141110
2023-06-01 11:54:51,446:INFO: Epoch: 5/30, Step: 2/64, Lr: 0.001500000, Loss: 0.469236, Step Loss: 0.469236, Time: 0.063041
2023-06-01 11:54:51,510:INFO: Epoch: 5/30, Step: 3/64, Lr: 0.001500000, Loss: 0.034375, Step Loss: 0.034375, Time: 0.063724
2023-06-01 11:54:51,574:INFO: Epoch: 5/30, Step: 4/64, Lr: 0.001500000, Loss: 0.002187, Step Loss: 0.002187, Time: 0.063964
2023-06-01 11:54:51,649:INFO: Epoch: 5/30, Step: 5/64, Lr: 0.001500000, Loss: 0.240528, Step Loss: 0.240528, Time: 0.074473
2023-06-01 11:54:51,714:INFO: Epoch: 5/30, Step: 6/64, Lr: 0.001500000, Loss: 0.102182, Step Loss: 0.102182, Time: 0.065158
2023-06-01 11:54:51,781:INFO: Epoch: 5/30, Step: 7/64, Lr: 0.001500000, Loss: 0.293814, Step Loss: 0.293814, Time: 0.066625
2023-06-01 11:54:51,846:INFO: Epoch: 5/30, Step: 8/64, Lr: 0.001500000, Loss: 0.030198, Step Loss: 0.030198, Time: 0.064587
2023-06-01 11:54:51,915:INFO: Epoch: 5/30, Step: 9/64, Lr: 0.001500000, Loss: 0.234156, Step Loss: 0.234156, Time: 0.068866
2023-06-01 11:54:51,984:INFO: Epoch: 5/30, Step: 10/64, Lr: 0.001500000, Loss: 0.023311, Step Loss: 0.023311, Time: 0.068096
2023-06-01 11:54:52,055:INFO: Epoch: 5/30, Step: 11/64, Lr: 0.001500000, Loss: 0.519890, Step Loss: 0.519890, Time: 0.070587
2023-06-01 11:54:52,131:INFO: Epoch: 5/30, Step: 12/64, Lr: 0.001500000, Loss: 0.445622, Step Loss: 0.445622, Time: 0.075587
2023-06-01 11:54:52,201:INFO: Epoch: 5/30, Step: 13/64, Lr: 0.001500000, Loss: 0.004258, Step Loss: 0.004258, Time: 0.069768
2023-06-01 11:54:52,272:INFO: Epoch: 5/30, Step: 14/64, Lr: 0.001500000, Loss: 0.007775, Step Loss: 0.007775, Time: 0.070753
2023-06-01 11:54:52,340:INFO: Epoch: 5/30, Step: 15/64, Lr: 0.001500000, Loss: 1.058796, Step Loss: 1.058796, Time: 0.067637
2023-06-01 11:54:52,408:INFO: Epoch: 5/30, Step: 16/64, Lr: 0.001500000, Loss: 1.173630, Step Loss: 1.173630, Time: 0.067980
2023-06-01 11:54:52,483:INFO: Epoch: 5/30, Step: 17/64, Lr: 0.001500000, Loss: 0.477052, Step Loss: 0.477052, Time: 0.074029
2023-06-01 11:54:52,550:INFO: Epoch: 5/30, Step: 18/64, Lr: 0.001500000, Loss: 0.292882, Step Loss: 0.292882, Time: 0.066382
2023-06-01 11:54:52,625:INFO: Epoch: 5/30, Step: 19/64, Lr: 0.001500000, Loss: 0.290357, Step Loss: 0.290357, Time: 0.074863
2023-06-01 11:54:52,698:INFO: Epoch: 5/30, Step: 20/64, Lr: 0.001500000, Loss: 0.950929, Step Loss: 0.950929, Time: 0.072486
2023-06-01 11:54:52,766:INFO: Epoch: 5/30, Step: 21/64, Lr: 0.001500000, Loss: 0.014833, Step Loss: 0.014833, Time: 0.067740
2023-06-01 11:54:52,832:INFO: Epoch: 5/30, Step: 22/64, Lr: 0.001500000, Loss: 0.196926, Step Loss: 0.196926, Time: 0.066165
2023-06-01 11:54:52,902:INFO: Epoch: 5/30, Step: 23/64, Lr: 0.001500000, Loss: 0.546694, Step Loss: 0.546694, Time: 0.069916
2023-06-01 11:54:52,967:INFO: Epoch: 5/30, Step: 24/64, Lr: 0.001500000, Loss: 0.000213, Step Loss: 0.000213, Time: 0.064091
2023-06-01 11:54:53,034:INFO: Epoch: 5/30, Step: 25/64, Lr: 0.001500000, Loss: 0.492945, Step Loss: 0.492945, Time: 0.066973
2023-06-01 11:54:53,102:INFO: Epoch: 5/30, Step: 26/64, Lr: 0.001500000, Loss: 0.473043, Step Loss: 0.473043, Time: 0.067779
2023-06-01 11:54:53,171:INFO: Epoch: 5/30, Step: 27/64, Lr: 0.001500000, Loss: 0.097688, Step Loss: 0.097688, Time: 0.068324
2023-06-01 11:54:53,245:INFO: Epoch: 5/30, Step: 28/64, Lr: 0.001500000, Loss: 0.532761, Step Loss: 0.532761, Time: 0.073597
2023-06-01 11:54:53,311:INFO: Epoch: 5/30, Step: 29/64, Lr: 0.001500000, Loss: 0.001073, Step Loss: 0.001073, Time: 0.065250
2023-06-01 11:54:53,381:INFO: Epoch: 5/30, Step: 30/64, Lr: 0.001500000, Loss: 0.491332, Step Loss: 0.491332, Time: 0.070196
2023-06-01 11:54:53,450:INFO: Epoch: 5/30, Step: 31/64, Lr: 0.001500000, Loss: 0.306645, Step Loss: 0.306645, Time: 0.068050
2023-06-01 11:54:53,521:INFO: Epoch: 5/30, Step: 32/64, Lr: 0.001500000, Loss: 0.000600, Step Loss: 0.000600, Time: 0.071001
2023-06-01 11:54:53,586:INFO: Epoch: 5/30, Step: 33/64, Lr: 0.001500000, Loss: 0.644651, Step Loss: 0.644651, Time: 0.064673
2023-06-01 11:54:53,653:INFO: Epoch: 5/30, Step: 34/64, Lr: 0.001500000, Loss: 0.012193, Step Loss: 0.012193, Time: 0.066836
2023-06-01 11:54:53,729:INFO: Epoch: 5/30, Step: 35/64, Lr: 0.001500000, Loss: 0.214903, Step Loss: 0.214903, Time: 0.075010
2023-06-01 11:54:53,803:INFO: Epoch: 5/30, Step: 36/64, Lr: 0.001500000, Loss: 0.582300, Step Loss: 0.582300, Time: 0.073717
2023-06-01 11:54:53,870:INFO: Epoch: 5/30, Step: 37/64, Lr: 0.001500000, Loss: 0.077312, Step Loss: 0.077312, Time: 0.066147
2023-06-01 11:54:53,940:INFO: Epoch: 5/30, Step: 38/64, Lr: 0.001500000, Loss: 1.133046, Step Loss: 1.133046, Time: 0.070359
2023-06-01 11:54:54,010:INFO: Epoch: 5/30, Step: 39/64, Lr: 0.001500000, Loss: 0.111707, Step Loss: 0.111707, Time: 0.069358
2023-06-01 11:54:54,076:INFO: Epoch: 5/30, Step: 40/64, Lr: 0.001500000, Loss: 0.102481, Step Loss: 0.102481, Time: 0.065263
2023-06-01 11:54:54,151:INFO: Epoch: 5/30, Step: 41/64, Lr: 0.001500000, Loss: 0.184652, Step Loss: 0.184652, Time: 0.075164
2023-06-01 11:54:54,223:INFO: Epoch: 5/30, Step: 42/64, Lr: 0.001500000, Loss: 0.477509, Step Loss: 0.477509, Time: 0.070921
2023-06-01 11:54:54,288:INFO: Epoch: 5/30, Step: 43/64, Lr: 0.001500000, Loss: 0.053258, Step Loss: 0.053258, Time: 0.065122
2023-06-01 11:54:54,358:INFO: Epoch: 5/30, Step: 44/64, Lr: 0.001500000, Loss: 0.073909, Step Loss: 0.073909, Time: 0.069571
2023-06-01 11:54:54,427:INFO: Epoch: 5/30, Step: 45/64, Lr: 0.001500000, Loss: 1.250046, Step Loss: 1.250046, Time: 0.068744
2023-06-01 11:54:54,499:INFO: Epoch: 5/30, Step: 46/64, Lr: 0.001500000, Loss: 0.086010, Step Loss: 0.086010, Time: 0.071291
2023-06-01 11:54:54,567:INFO: Epoch: 5/30, Step: 47/64, Lr: 0.001500000, Loss: 1.239679, Step Loss: 1.239679, Time: 0.066866
2023-06-01 11:54:54,637:INFO: Epoch: 5/30, Step: 48/64, Lr: 0.001500000, Loss: 0.461842, Step Loss: 0.461842, Time: 0.069921
2023-06-01 11:54:54,718:INFO: Epoch: 5/30, Step: 49/64, Lr: 0.001500000, Loss: 1.034944, Step Loss: 1.034944, Time: 0.080391
2023-06-01 11:54:54,783:INFO: Epoch: 5/30, Step: 50/64, Lr: 0.001500000, Loss: 0.703767, Step Loss: 0.703767, Time: 0.065089
2023-06-01 11:54:54,847:INFO: Epoch: 5/30, Step: 51/64, Lr: 0.001500000, Loss: 0.912649, Step Loss: 0.912649, Time: 0.063629
2023-06-01 11:54:54,916:INFO: Epoch: 5/30, Step: 52/64, Lr: 0.001500000, Loss: 0.701897, Step Loss: 0.701897, Time: 0.068319
2023-06-01 11:54:54,982:INFO: Epoch: 5/30, Step: 53/64, Lr: 0.001500000, Loss: 1.177100, Step Loss: 1.177100, Time: 0.065235
2023-06-01 11:54:55,050:INFO: Epoch: 5/30, Step: 54/64, Lr: 0.001500000, Loss: 0.775862, Step Loss: 0.775862, Time: 0.068300
2023-06-01 11:54:55,124:INFO: Epoch: 5/30, Step: 55/64, Lr: 0.001500000, Loss: 0.521381, Step Loss: 0.521381, Time: 0.073489
2023-06-01 11:54:55,207:INFO: Epoch: 5/30, Step: 56/64, Lr: 0.001500000, Loss: 1.164439, Step Loss: 1.164439, Time: 0.082627
2023-06-01 11:54:55,275:INFO: Epoch: 5/30, Step: 57/64, Lr: 0.001500000, Loss: 0.054719, Step Loss: 0.054719, Time: 0.067480
2023-06-01 11:54:55,344:INFO: Epoch: 5/30, Step: 58/64, Lr: 0.001500000, Loss: 0.203397, Step Loss: 0.203397, Time: 0.068763
2023-06-01 11:54:55,415:INFO: Epoch: 5/30, Step: 59/64, Lr: 0.001500000, Loss: 0.196042, Step Loss: 0.196042, Time: 0.069854
2023-06-01 11:54:55,478:INFO: Epoch: 5/30, Step: 60/64, Lr: 0.001500000, Loss: 0.361105, Step Loss: 0.361105, Time: 0.063026
2023-06-01 11:54:55,550:INFO: Epoch: 5/30, Step: 61/64, Lr: 0.001500000, Loss: 0.424085, Step Loss: 0.424085, Time: 0.071841
2023-06-01 11:54:55,622:INFO: Epoch: 5/30, Step: 62/64, Lr: 0.001500000, Loss: 0.041849, Step Loss: 0.041849, Time: 0.070701
2023-06-01 11:54:55,687:INFO: Epoch: 5/30, Step: 63/64, Lr: 0.001500000, Loss: 0.893911, Step Loss: 0.893911, Time: 0.064776
2023-06-01 11:54:55,755:INFO: Epoch: 5/30, Step: 64/64, Lr: 0.001500000, Loss: 0.332869, Step Loss: 0.332869, Time: 0.067406
2023-06-01 11:54:55,906:INFO: Epoch 5/30 Finished, Train Loss: 0.409622
2023-06-01 11:55:02,809:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4
2023-06-01 11:55:05,945:INFO: Classfication Metrics:
2023-06-01 11:55:05,945:INFO: f1 score: 0.8627 - precision score: 0.7914 - recall score: 0.9483 - accuracy score: 0.881356
2023-06-01 11:55:05,945:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.4, the F1 is: 0.8627
2023-06-01 11:55:06,986:INFO: Epoch: 6/30, Step: 1/64, Lr: 0.001500000, Loss: 0.382995, Step Loss: 0.382995, Time: 1.032672
2023-06-01 11:55:07,059:INFO: Epoch: 6/30, Step: 2/64, Lr: 0.001500000, Loss: 0.624749, Step Loss: 0.624749, Time: 0.072942
2023-06-01 11:55:07,127:INFO: Epoch: 6/30, Step: 3/64, Lr: 0.001500000, Loss: 0.296439, Step Loss: 0.296439, Time: 0.067176
2023-06-01 11:55:07,210:INFO: Epoch: 6/30, Step: 4/64, Lr: 0.001500000, Loss: 0.639476, Step Loss: 0.639476, Time: 0.082478
2023-06-01 11:55:07,275:INFO: Epoch: 6/30, Step: 5/64, Lr: 0.001500000, Loss: 0.107566, Step Loss: 0.107566, Time: 0.065244
2023-06-01 11:55:07,346:INFO: Epoch: 6/30, Step: 6/64, Lr: 0.001500000, Loss: 0.026784, Step Loss: 0.026784, Time: 0.070765
2023-06-01 11:55:07,412:INFO: Epoch: 6/30, Step: 7/64, Lr: 0.001500000, Loss: 0.467738, Step Loss: 0.467738, Time: 0.065095
2023-06-01 11:55:07,480:INFO: Epoch: 6/30, Step: 8/64, Lr: 0.001500000, Loss: 2.639446, Step Loss: 2.639446, Time: 0.067656
2023-06-01 11:55:07,548:INFO: Epoch: 6/30, Step: 9/64, Lr: 0.001500000, Loss: 0.900588, Step Loss: 0.900588, Time: 0.067613
2023-06-01 11:55:07,614:INFO: Epoch: 6/30, Step: 10/64, Lr: 0.001500000, Loss: 0.005846, Step Loss: 0.005846, Time: 0.065927
2023-06-01 11:55:07,678:INFO: Epoch: 6/30, Step: 11/64, Lr: 0.001500000, Loss: 0.004406, Step Loss: 0.004406, Time: 0.064195
2023-06-01 11:55:07,755:INFO: Epoch: 6/30, Step: 12/64, Lr: 0.001500000, Loss: 0.794749, Step Loss: 0.794749, Time: 0.076304
2023-06-01 11:55:07,823:INFO: Epoch: 6/30, Step: 13/64, Lr: 0.001500000, Loss: 0.027436, Step Loss: 0.027436, Time: 0.067964
2023-06-01 11:55:07,890:INFO: Epoch: 6/30, Step: 14/64, Lr: 0.001500000, Loss: 0.296369, Step Loss: 0.296369, Time: 0.065938
2023-06-01 11:55:07,954:INFO: Epoch: 6/30, Step: 15/64, Lr: 0.001500000, Loss: 1.077093, Step Loss: 1.077093, Time: 0.064436
2023-06-01 11:55:08,019:INFO: Epoch: 6/30, Step: 16/64, Lr: 0.001500000, Loss: 0.995870, Step Loss: 0.995870, Time: 0.064306
2023-06-01 11:55:08,089:INFO: Epoch: 6/30, Step: 17/64, Lr: 0.001500000, Loss: 0.000534, Step Loss: 0.000534, Time: 0.070052
2023-06-01 11:55:08,154:INFO: Epoch: 6/30, Step: 18/64, Lr: 0.001500000, Loss: 0.268628, Step Loss: 0.268628, Time: 0.064572
2023-06-01 11:55:08,220:INFO: Epoch: 6/30, Step: 19/64, Lr: 0.001500000, Loss: 0.200868, Step Loss: 0.200868, Time: 0.065012
2023-06-01 11:55:08,289:INFO: Epoch: 6/30, Step: 20/64, Lr: 0.001500000, Loss: 0.739821, Step Loss: 0.739821, Time: 0.068913
2023-06-01 11:55:08,354:INFO: Epoch: 6/30, Step: 21/64, Lr: 0.001500000, Loss: 0.150163, Step Loss: 0.150163, Time: 0.064583
2023-06-01 11:55:08,425:INFO: Epoch: 6/30, Step: 22/64, Lr: 0.001500000, Loss: 0.494803, Step Loss: 0.494803, Time: 0.070979
2023-06-01 11:55:08,491:INFO: Epoch: 6/30, Step: 23/64, Lr: 0.001500000, Loss: 1.464552, Step Loss: 1.464552, Time: 0.065230
2023-06-01 11:55:08,557:INFO: Epoch: 6/30, Step: 24/64, Lr: 0.001500000, Loss: 1.199166, Step Loss: 1.199166, Time: 0.066337
2023-06-01 11:55:08,630:INFO: Epoch: 6/30, Step: 25/64, Lr: 0.001500000, Loss: 1.183852, Step Loss: 1.183852, Time: 0.072541
2023-06-01 11:55:08,697:INFO: Epoch: 6/30, Step: 26/64, Lr: 0.001500000, Loss: 2.934657, Step Loss: 2.934657, Time: 0.066619
2023-06-01 11:55:08,767:INFO: Epoch: 6/30, Step: 27/64, Lr: 0.001500000, Loss: 1.804899, Step Loss: 1.804899, Time: 0.069045
2023-06-01 11:55:08,835:INFO: Epoch: 6/30, Step: 28/64, Lr: 0.001500000, Loss: 0.843396, Step Loss: 0.843396, Time: 0.067763
2023-06-01 11:55:08,899:INFO: Epoch: 6/30, Step: 29/64, Lr: 0.001500000, Loss: 0.001294, Step Loss: 0.001294, Time: 0.064073
2023-06-01 11:55:08,967:INFO: Epoch: 6/30, Step: 30/64, Lr: 0.001500000, Loss: 1.892235, Step Loss: 1.892235, Time: 0.067062
2023-06-01 11:55:09,034:INFO: Epoch: 6/30, Step: 31/64, Lr: 0.001500000, Loss: 0.161698, Step Loss: 0.161698, Time: 0.067423
2023-06-01 11:55:09,103:INFO: Epoch: 6/30, Step: 32/64, Lr: 0.001500000, Loss: 0.327389, Step Loss: 0.327389, Time: 0.068672
2023-06-01 11:55:09,171:INFO: Epoch: 6/30, Step: 33/64, Lr: 0.001500000, Loss: 1.365822, Step Loss: 1.365822, Time: 0.067503
2023-06-01 11:55:09,246:INFO: Epoch: 6/30, Step: 34/64, Lr: 0.001500000, Loss: 1.171593, Step Loss: 1.171593, Time: 0.074802
2023-06-01 11:55:09,311:INFO: Epoch: 6/30, Step: 35/64, Lr: 0.001500000, Loss: 0.003129, Step Loss: 0.003129, Time: 0.064215
2023-06-01 11:55:09,378:INFO: Epoch: 6/30, Step: 36/64, Lr: 0.001500000, Loss: 0.020306, Step Loss: 0.020306, Time: 0.066855
2023-06-01 11:55:09,447:INFO: Epoch: 6/30, Step: 37/64, Lr: 0.001500000, Loss: 0.790491, Step Loss: 0.790491, Time: 0.068500
2023-06-01 11:55:09,514:INFO: Epoch: 6/30, Step: 38/64, Lr: 0.001500000, Loss: 1.158307, Step Loss: 1.158307, Time: 0.066917
2023-06-01 11:55:09,583:INFO: Epoch: 6/30, Step: 39/64, Lr: 0.001500000, Loss: 0.412965, Step Loss: 0.412965, Time: 0.068306
2023-06-01 11:55:09,654:INFO: Epoch: 6/30, Step: 40/64, Lr: 0.001500000, Loss: 0.702054, Step Loss: 0.702054, Time: 0.070583
2023-06-01 11:55:09,719:INFO: Epoch: 6/30, Step: 41/64, Lr: 0.001500000, Loss: 0.113611, Step Loss: 0.113611, Time: 0.064928
2023-06-01 11:55:09,783:INFO: Epoch: 6/30, Step: 42/64, Lr: 0.001500000, Loss: 0.049006, Step Loss: 0.049006, Time: 0.063812
2023-06-01 11:55:09,851:INFO: Epoch: 6/30, Step: 43/64, Lr: 0.001500000, Loss: 0.382147, Step Loss: 0.382147, Time: 0.067240
2023-06-01 11:55:09,916:INFO: Epoch: 6/30, Step: 44/64, Lr: 0.001500000, Loss: 1.111250, Step Loss: 1.111250, Time: 0.065247
2023-06-01 11:55:09,990:INFO: Epoch: 6/30, Step: 45/64, Lr: 0.001500000, Loss: 0.237406, Step Loss: 0.237406, Time: 0.073120
2023-06-01 11:55:10,055:INFO: Epoch: 6/30, Step: 46/64, Lr: 0.001500000, Loss: 0.663271, Step Loss: 0.663271, Time: 0.064649
2023-06-01 11:55:10,123:INFO: Epoch: 6/30, Step: 47/64, Lr: 0.001500000, Loss: 0.014836, Step Loss: 0.014836, Time: 0.068072
2023-06-01 11:55:10,196:INFO: Epoch: 6/30, Step: 48/64, Lr: 0.001500000, Loss: 0.282002, Step Loss: 0.282002, Time: 0.072031
2023-06-01 11:55:10,262:INFO: Epoch: 6/30, Step: 49/64, Lr: 0.001500000, Loss: 0.488393, Step Loss: 0.488393, Time: 0.065635
2023-06-01 11:55:10,335:INFO: Epoch: 6/30, Step: 50/64, Lr: 0.001500000, Loss: 0.060980, Step Loss: 0.060980, Time: 0.072613
2023-06-01 11:55:10,409:INFO: Epoch: 6/30, Step: 51/64, Lr: 0.001500000, Loss: 1.326726, Step Loss: 1.326726, Time: 0.074070
2023-06-01 11:55:10,484:INFO: Epoch: 6/30, Step: 52/64, Lr: 0.001500000, Loss: 0.416953, Step Loss: 0.416953, Time: 0.074313
2023-06-01 11:55:10,553:INFO: Epoch: 6/30, Step: 53/64, Lr: 0.001500000, Loss: 0.453822, Step Loss: 0.453822, Time: 0.068942
2023-06-01 11:55:10,622:INFO: Epoch: 6/30, Step: 54/64, Lr: 0.001500000, Loss: 0.639629, Step Loss: 0.639629, Time: 0.068169
2023-06-01 11:55:10,690:INFO: Epoch: 6/30, Step: 55/64, Lr: 0.001500000, Loss: 0.448233, Step Loss: 0.448233, Time: 0.067925
2023-06-01 11:55:10,762:INFO: Epoch: 6/30, Step: 56/64, Lr: 0.001500000, Loss: 0.000514, Step Loss: 0.000514, Time: 0.071818
2023-06-01 11:55:10,829:INFO: Epoch: 6/30, Step: 57/64, Lr: 0.001500000, Loss: 0.287462, Step Loss: 0.287462, Time: 0.066832
2023-06-01 11:55:10,895:INFO: Epoch: 6/30, Step: 58/64, Lr: 0.001500000, Loss: 0.016523, Step Loss: 0.016523, Time: 0.064813
2023-06-01 11:55:10,962:INFO: Epoch: 6/30, Step: 59/64, Lr: 0.001500000, Loss: 0.046045, Step Loss: 0.046045, Time: 0.067126
2023-06-01 11:55:11,035:INFO: Epoch: 6/30, Step: 60/64, Lr: 0.001500000, Loss: 0.135124, Step Loss: 0.135124, Time: 0.072073
2023-06-01 11:55:11,098:INFO: Epoch: 6/30, Step: 61/64, Lr: 0.001500000, Loss: 0.871664, Step Loss: 0.871664, Time: 0.062882
2023-06-01 11:55:11,167:INFO: Epoch: 6/30, Step: 62/64, Lr: 0.001500000, Loss: 0.596838, Step Loss: 0.596838, Time: 0.069109
2023-06-01 11:55:11,239:INFO: Epoch: 6/30, Step: 63/64, Lr: 0.001500000, Loss: 0.256412, Step Loss: 0.256412, Time: 0.070929
2023-06-01 11:55:11,306:INFO: Epoch: 6/30, Step: 64/64, Lr: 0.001500000, Loss: 0.066562, Step Loss: 0.066562, Time: 0.066907
2023-06-01 11:55:11,460:INFO: Epoch 6/30 Finished, Train Loss: 0.586650
2023-06-01 11:55:18,146:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5
2023-06-01 11:55:21,277:INFO: Classfication Metrics:
2023-06-01 11:55:21,277:INFO: f1 score: 0.8871 - precision score: 0.8333 - recall score: 0.9483 - accuracy score: 0.905085
2023-06-01 11:55:21,277:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:55:22,566:INFO: Epoch: 7/30, Step: 1/64, Lr: 0.001494086, Loss: 0.083132, Step Loss: 0.083132, Time: 1.280312
2023-06-01 11:55:22,630:INFO: Epoch: 7/30, Step: 2/64, Lr: 0.001494086, Loss: 0.085388, Step Loss: 0.085388, Time: 0.063250
2023-06-01 11:55:22,695:INFO: Epoch: 7/30, Step: 3/64, Lr: 0.001494086, Loss: 0.830898, Step Loss: 0.830898, Time: 0.064559
2023-06-01 11:55:22,761:INFO: Epoch: 7/30, Step: 4/64, Lr: 0.001494086, Loss: 0.678713, Step Loss: 0.678713, Time: 0.066473
2023-06-01 11:55:22,827:INFO: Epoch: 7/30, Step: 5/64, Lr: 0.001494086, Loss: 0.056732, Step Loss: 0.056732, Time: 0.064872
2023-06-01 11:55:22,891:INFO: Epoch: 7/30, Step: 6/64, Lr: 0.001494086, Loss: 0.065890, Step Loss: 0.065890, Time: 0.063987
2023-06-01 11:55:22,957:INFO: Epoch: 7/30, Step: 7/64, Lr: 0.001494086, Loss: 0.056247, Step Loss: 0.056247, Time: 0.066079
2023-06-01 11:55:23,023:INFO: Epoch: 7/30, Step: 8/64, Lr: 0.001494086, Loss: 0.965249, Step Loss: 0.965249, Time: 0.065146
2023-06-01 11:55:23,097:INFO: Epoch: 7/30, Step: 9/64, Lr: 0.001494086, Loss: 0.453645, Step Loss: 0.453645, Time: 0.074157
2023-06-01 11:55:23,162:INFO: Epoch: 7/30, Step: 10/64, Lr: 0.001494086, Loss: 1.216783, Step Loss: 1.216783, Time: 0.064785
2023-06-01 11:55:23,229:INFO: Epoch: 7/30, Step: 11/64, Lr: 0.001494086, Loss: 1.375842, Step Loss: 1.375842, Time: 0.066388
2023-06-01 11:55:23,294:INFO: Epoch: 7/30, Step: 12/64, Lr: 0.001494086, Loss: 1.060469, Step Loss: 1.060469, Time: 0.065013
2023-06-01 11:55:23,359:INFO: Epoch: 7/30, Step: 13/64, Lr: 0.001494086, Loss: 0.000746, Step Loss: 0.000746, Time: 0.064210
2023-06-01 11:55:23,423:INFO: Epoch: 7/30, Step: 14/64, Lr: 0.001494086, Loss: 0.014533, Step Loss: 0.014533, Time: 0.064281
2023-06-01 11:55:23,488:INFO: Epoch: 7/30, Step: 15/64, Lr: 0.001494086, Loss: 0.775361, Step Loss: 0.775361, Time: 0.064026
2023-06-01 11:55:23,555:INFO: Epoch: 7/30, Step: 16/64, Lr: 0.001494086, Loss: 0.266836, Step Loss: 0.266836, Time: 0.067023
2023-06-01 11:55:23,627:INFO: Epoch: 7/30, Step: 17/64, Lr: 0.001494086, Loss: 0.143730, Step Loss: 0.143730, Time: 0.071400
2023-06-01 11:55:23,694:INFO: Epoch: 7/30, Step: 18/64, Lr: 0.001494086, Loss: 0.008597, Step Loss: 0.008597, Time: 0.067152
2023-06-01 11:55:23,760:INFO: Epoch: 7/30, Step: 19/64, Lr: 0.001494086, Loss: 1.043713, Step Loss: 1.043713, Time: 0.065664
2023-06-01 11:55:23,838:INFO: Epoch: 7/30, Step: 20/64, Lr: 0.001494086, Loss: 0.002438, Step Loss: 0.002438, Time: 0.077676
2023-06-01 11:55:23,903:INFO: Epoch: 7/30, Step: 21/64, Lr: 0.001494086, Loss: 0.084295, Step Loss: 0.084295, Time: 0.064652
2023-06-01 11:55:23,972:INFO: Epoch: 7/30, Step: 22/64, Lr: 0.001494086, Loss: 0.112286, Step Loss: 0.112286, Time: 0.067918
2023-06-01 11:55:24,040:INFO: Epoch: 7/30, Step: 23/64, Lr: 0.001494086, Loss: 0.008264, Step Loss: 0.008264, Time: 0.067744
2023-06-01 11:55:24,113:INFO: Epoch: 7/30, Step: 24/64, Lr: 0.001494086, Loss: 0.500780, Step Loss: 0.500780, Time: 0.073118
2023-06-01 11:55:24,180:INFO: Epoch: 7/30, Step: 25/64, Lr: 0.001494086, Loss: 0.356005, Step Loss: 0.356005, Time: 0.065926
2023-06-01 11:55:24,247:INFO: Epoch: 7/30, Step: 26/64, Lr: 0.001494086, Loss: 0.031511, Step Loss: 0.031511, Time: 0.067229
2023-06-01 11:55:24,315:INFO: Epoch: 7/30, Step: 27/64, Lr: 0.001494086, Loss: 0.191422, Step Loss: 0.191422, Time: 0.067901
2023-06-01 11:55:24,382:INFO: Epoch: 7/30, Step: 28/64, Lr: 0.001494086, Loss: 0.003026, Step Loss: 0.003026, Time: 0.066162
2023-06-01 11:55:24,450:INFO: Epoch: 7/30, Step: 29/64, Lr: 0.001494086, Loss: 0.000060, Step Loss: 0.000060, Time: 0.067522
2023-06-01 11:55:24,518:INFO: Epoch: 7/30, Step: 30/64, Lr: 0.001494086, Loss: 0.002033, Step Loss: 0.002033, Time: 0.067667
2023-06-01 11:55:24,586:INFO: Epoch: 7/30, Step: 31/64, Lr: 0.001494086, Loss: 0.203607, Step Loss: 0.203607, Time: 0.067872
2023-06-01 11:55:24,654:INFO: Epoch: 7/30, Step: 32/64, Lr: 0.001494086, Loss: 0.767179, Step Loss: 0.767179, Time: 0.067704
2023-06-01 11:55:24,723:INFO: Epoch: 7/30, Step: 33/64, Lr: 0.001494086, Loss: 0.388287, Step Loss: 0.388287, Time: 0.068810
2023-06-01 11:55:24,791:INFO: Epoch: 7/30, Step: 34/64, Lr: 0.001494086, Loss: 1.815005, Step Loss: 1.815005, Time: 0.067278
2023-06-01 11:55:24,855:INFO: Epoch: 7/30, Step: 35/64, Lr: 0.001494086, Loss: 4.033184, Step Loss: 4.033184, Time: 0.063890
2023-06-01 11:55:24,922:INFO: Epoch: 7/30, Step: 36/64, Lr: 0.001494086, Loss: 0.169931, Step Loss: 0.169931, Time: 0.066810
2023-06-01 11:55:24,991:INFO: Epoch: 7/30, Step: 37/64, Lr: 0.001494086, Loss: 0.467942, Step Loss: 0.467942, Time: 0.067991
2023-06-01 11:55:25,055:INFO: Epoch: 7/30, Step: 38/64, Lr: 0.001494086, Loss: 0.578149, Step Loss: 0.578149, Time: 0.063945
2023-06-01 11:55:25,130:INFO: Epoch: 7/30, Step: 39/64, Lr: 0.001494086, Loss: 0.581175, Step Loss: 0.581175, Time: 0.074767
2023-06-01 11:55:25,199:INFO: Epoch: 7/30, Step: 40/64, Lr: 0.001494086, Loss: 0.000352, Step Loss: 0.000352, Time: 0.068263
2023-06-01 11:55:25,264:INFO: Epoch: 7/30, Step: 41/64, Lr: 0.001494086, Loss: 0.040501, Step Loss: 0.040501, Time: 0.064167
2023-06-01 11:55:25,336:INFO: Epoch: 7/30, Step: 42/64, Lr: 0.001494086, Loss: 1.754257, Step Loss: 1.754257, Time: 0.071903
2023-06-01 11:55:25,405:INFO: Epoch: 7/30, Step: 43/64, Lr: 0.001494086, Loss: 0.258414, Step Loss: 0.258414, Time: 0.069060
2023-06-01 11:55:25,474:INFO: Epoch: 7/30, Step: 44/64, Lr: 0.001494086, Loss: 0.770670, Step Loss: 0.770670, Time: 0.068256
2023-06-01 11:55:25,543:INFO: Epoch: 7/30, Step: 45/64, Lr: 0.001494086, Loss: 0.045656, Step Loss: 0.045656, Time: 0.069087
2023-06-01 11:55:25,610:INFO: Epoch: 7/30, Step: 46/64, Lr: 0.001494086, Loss: 0.002025, Step Loss: 0.002025, Time: 0.066689
2023-06-01 11:55:25,679:INFO: Epoch: 7/30, Step: 47/64, Lr: 0.001494086, Loss: 0.000013, Step Loss: 0.000013, Time: 0.068642
2023-06-01 11:55:25,747:INFO: Epoch: 7/30, Step: 48/64, Lr: 0.001494086, Loss: 1.129085, Step Loss: 1.129085, Time: 0.068174
2023-06-01 11:55:25,814:INFO: Epoch: 7/30, Step: 49/64, Lr: 0.001494086, Loss: 0.071523, Step Loss: 0.071523, Time: 0.067025
2023-06-01 11:55:25,888:INFO: Epoch: 7/30, Step: 50/64, Lr: 0.001494086, Loss: 0.000024, Step Loss: 0.000024, Time: 0.072936
2023-06-01 11:55:25,956:INFO: Epoch: 7/30, Step: 51/64, Lr: 0.001494086, Loss: 0.917473, Step Loss: 0.917473, Time: 0.067671
2023-06-01 11:55:26,023:INFO: Epoch: 7/30, Step: 52/64, Lr: 0.001494086, Loss: 0.011618, Step Loss: 0.011618, Time: 0.066705
2023-06-01 11:55:26,090:INFO: Epoch: 7/30, Step: 53/64, Lr: 0.001494086, Loss: 0.374064, Step Loss: 0.374064, Time: 0.066941
2023-06-01 11:55:26,166:INFO: Epoch: 7/30, Step: 54/64, Lr: 0.001494086, Loss: 0.427918, Step Loss: 0.427918, Time: 0.075439
2023-06-01 11:55:26,231:INFO: Epoch: 7/30, Step: 55/64, Lr: 0.001494086, Loss: 0.189627, Step Loss: 0.189627, Time: 0.064816
2023-06-01 11:55:26,298:INFO: Epoch: 7/30, Step: 56/64, Lr: 0.001494086, Loss: 0.000174, Step Loss: 0.000174, Time: 0.066315
2023-06-01 11:55:26,371:INFO: Epoch: 7/30, Step: 57/64, Lr: 0.001494086, Loss: 0.858059, Step Loss: 0.858059, Time: 0.072685
2023-06-01 11:55:26,446:INFO: Epoch: 7/30, Step: 58/64, Lr: 0.001494086, Loss: 0.761493, Step Loss: 0.761493, Time: 0.075206
2023-06-01 11:55:26,513:INFO: Epoch: 7/30, Step: 59/64, Lr: 0.001494086, Loss: 0.002088, Step Loss: 0.002088, Time: 0.065921
2023-06-01 11:55:26,586:INFO: Epoch: 7/30, Step: 60/64, Lr: 0.001494086, Loss: 0.003094, Step Loss: 0.003094, Time: 0.073306
2023-06-01 11:55:26,651:INFO: Epoch: 7/30, Step: 61/64, Lr: 0.001494086, Loss: 0.432877, Step Loss: 0.432877, Time: 0.064157
2023-06-01 11:55:26,725:INFO: Epoch: 7/30, Step: 62/64, Lr: 0.001494086, Loss: 0.279468, Step Loss: 0.279468, Time: 0.073636
2023-06-01 11:55:26,792:INFO: Epoch: 7/30, Step: 63/64, Lr: 0.001494086, Loss: 0.461195, Step Loss: 0.461195, Time: 0.067433
2023-06-01 11:55:26,863:INFO: Epoch: 7/30, Step: 64/64, Lr: 0.001494086, Loss: 0.403751, Step Loss: 0.403751, Time: 0.070869
2023-06-01 11:55:27,020:INFO: Epoch 7/30 Finished, Train Loss: 0.448039
2023-06-01 11:55:33,732:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.6
2023-06-01 11:55:36,918:INFO: Classfication Metrics:
2023-06-01 11:55:36,918:INFO: f1 score: 0.8165 - precision score: 0.8725 - recall score: 0.7672 - accuracy score: 0.864407
2023-06-01 11:55:36,918:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:55:38,011:INFO: Epoch: 8/30, Step: 1/64, Lr: 0.001476437, Loss: 0.032952, Step Loss: 0.032952, Time: 1.083315
2023-06-01 11:55:38,079:INFO: Epoch: 8/30, Step: 2/64, Lr: 0.001476437, Loss: 0.504271, Step Loss: 0.504271, Time: 0.067949
2023-06-01 11:55:38,149:INFO: Epoch: 8/30, Step: 3/64, Lr: 0.001476437, Loss: 0.002074, Step Loss: 0.002074, Time: 0.069499
2023-06-01 11:55:38,223:INFO: Epoch: 8/30, Step: 4/64, Lr: 0.001476437, Loss: 0.047707, Step Loss: 0.047707, Time: 0.073772
2023-06-01 11:55:38,286:INFO: Epoch: 8/30, Step: 5/64, Lr: 0.001476437, Loss: 0.721499, Step Loss: 0.721499, Time: 0.062781
2023-06-01 11:55:38,355:INFO: Epoch: 8/30, Step: 6/64, Lr: 0.001476437, Loss: 0.765478, Step Loss: 0.765478, Time: 0.068569
2023-06-01 11:55:38,423:INFO: Epoch: 8/30, Step: 7/64, Lr: 0.001476437, Loss: 0.026882, Step Loss: 0.026882, Time: 0.067860
2023-06-01 11:55:38,488:INFO: Epoch: 8/30, Step: 8/64, Lr: 0.001476437, Loss: 0.002229, Step Loss: 0.002229, Time: 0.065290
2023-06-01 11:55:38,562:INFO: Epoch: 8/30, Step: 9/64, Lr: 0.001476437, Loss: 0.721702, Step Loss: 0.721702, Time: 0.073284
2023-06-01 11:55:38,631:INFO: Epoch: 8/30, Step: 10/64, Lr: 0.001476437, Loss: 1.484223, Step Loss: 1.484223, Time: 0.068787
2023-06-01 11:55:38,699:INFO: Epoch: 8/30, Step: 11/64, Lr: 0.001476437, Loss: 0.286442, Step Loss: 0.286442, Time: 0.067814
2023-06-01 11:55:38,763:INFO: Epoch: 8/30, Step: 12/64, Lr: 0.001476437, Loss: 0.000151, Step Loss: 0.000151, Time: 0.063543
2023-06-01 11:55:38,830:INFO: Epoch: 8/30, Step: 13/64, Lr: 0.001476437, Loss: 0.783347, Step Loss: 0.783347, Time: 0.066948
2023-06-01 11:55:38,897:INFO: Epoch: 8/30, Step: 14/64, Lr: 0.001476437, Loss: 0.484294, Step Loss: 0.484294, Time: 0.066750
2023-06-01 11:55:38,962:INFO: Epoch: 8/30, Step: 15/64, Lr: 0.001476437, Loss: 0.386576, Step Loss: 0.386576, Time: 0.065068
2023-06-01 11:55:39,027:INFO: Epoch: 8/30, Step: 16/64, Lr: 0.001476437, Loss: 0.002386, Step Loss: 0.002386, Time: 0.064667
2023-06-01 11:55:39,103:INFO: Epoch: 8/30, Step: 17/64, Lr: 0.001476437, Loss: 0.000004, Step Loss: 0.000004, Time: 0.075237
2023-06-01 11:55:39,172:INFO: Epoch: 8/30, Step: 18/64, Lr: 0.001476437, Loss: 0.000104, Step Loss: 0.000104, Time: 0.068741
2023-06-01 11:55:39,243:INFO: Epoch: 8/30, Step: 19/64, Lr: 0.001476437, Loss: 0.972735, Step Loss: 0.972735, Time: 0.070296
2023-06-01 11:55:39,306:INFO: Epoch: 8/30, Step: 20/64, Lr: 0.001476437, Loss: 0.266011, Step Loss: 0.266011, Time: 0.062969
2023-06-01 11:55:39,371:INFO: Epoch: 8/30, Step: 21/64, Lr: 0.001476437, Loss: 0.001064, Step Loss: 0.001064, Time: 0.064518
2023-06-01 11:55:39,443:INFO: Epoch: 8/30, Step: 22/64, Lr: 0.001476437, Loss: 0.226427, Step Loss: 0.226427, Time: 0.071815
2023-06-01 11:55:39,511:INFO: Epoch: 8/30, Step: 23/64, Lr: 0.001476437, Loss: 1.538149, Step Loss: 1.538149, Time: 0.067648
2023-06-01 11:55:39,585:INFO: Epoch: 8/30, Step: 24/64, Lr: 0.001476437, Loss: 0.264037, Step Loss: 0.264037, Time: 0.073758
2023-06-01 11:55:39,655:INFO: Epoch: 8/30, Step: 25/64, Lr: 0.001476437, Loss: 0.922957, Step Loss: 0.922957, Time: 0.069150
2023-06-01 11:55:39,729:INFO: Epoch: 8/30, Step: 26/64, Lr: 0.001476437, Loss: 0.000042, Step Loss: 0.000042, Time: 0.074226
2023-06-01 11:55:39,799:INFO: Epoch: 8/30, Step: 27/64, Lr: 0.001476437, Loss: 0.006316, Step Loss: 0.006316, Time: 0.069255
2023-06-01 11:55:39,864:INFO: Epoch: 8/30, Step: 28/64, Lr: 0.001476437, Loss: 0.172966, Step Loss: 0.172966, Time: 0.064624
2023-06-01 11:55:39,935:INFO: Epoch: 8/30, Step: 29/64, Lr: 0.001476437, Loss: 0.010557, Step Loss: 0.010557, Time: 0.070611
2023-06-01 11:55:40,007:INFO: Epoch: 8/30, Step: 30/64, Lr: 0.001476437, Loss: 1.041245, Step Loss: 1.041245, Time: 0.072176
2023-06-01 11:55:40,074:INFO: Epoch: 8/30, Step: 31/64, Lr: 0.001476437, Loss: 0.840100, Step Loss: 0.840100, Time: 0.066658
2023-06-01 11:55:40,143:INFO: Epoch: 8/30, Step: 32/64, Lr: 0.001476437, Loss: 0.238361, Step Loss: 0.238361, Time: 0.068509
2023-06-01 11:55:40,219:INFO: Epoch: 8/30, Step: 33/64, Lr: 0.001476437, Loss: 0.160326, Step Loss: 0.160326, Time: 0.075806
2023-06-01 11:55:40,297:INFO: Epoch: 8/30, Step: 34/64, Lr: 0.001476437, Loss: 0.353738, Step Loss: 0.353738, Time: 0.077739
2023-06-01 11:55:40,366:INFO: Epoch: 8/30, Step: 35/64, Lr: 0.001476437, Loss: 0.271246, Step Loss: 0.271246, Time: 0.068063
2023-06-01 11:55:40,443:INFO: Epoch: 8/30, Step: 36/64, Lr: 0.001476437, Loss: 0.349617, Step Loss: 0.349617, Time: 0.076798
2023-06-01 11:55:40,512:INFO: Epoch: 8/30, Step: 37/64, Lr: 0.001476437, Loss: 0.447648, Step Loss: 0.447648, Time: 0.068503
2023-06-01 11:55:40,578:INFO: Epoch: 8/30, Step: 38/64, Lr: 0.001476437, Loss: 0.007390, Step Loss: 0.007390, Time: 0.065981
2023-06-01 11:55:40,643:INFO: Epoch: 8/30, Step: 39/64, Lr: 0.001476437, Loss: 0.963775, Step Loss: 0.963775, Time: 0.064847
2023-06-01 11:55:40,710:INFO: Epoch: 8/30, Step: 40/64, Lr: 0.001476437, Loss: 0.050922, Step Loss: 0.050922, Time: 0.066639
2023-06-01 11:55:40,783:INFO: Epoch: 8/30, Step: 41/64, Lr: 0.001476437, Loss: 1.439946, Step Loss: 1.439946, Time: 0.072309
2023-06-01 11:55:40,853:INFO: Epoch: 8/30, Step: 42/64, Lr: 0.001476437, Loss: 0.007350, Step Loss: 0.007350, Time: 0.070236
2023-06-01 11:55:40,932:INFO: Epoch: 8/30, Step: 43/64, Lr: 0.001476437, Loss: 1.796771, Step Loss: 1.796771, Time: 0.077795
2023-06-01 11:55:40,995:INFO: Epoch: 8/30, Step: 44/64, Lr: 0.001476437, Loss: 0.378259, Step Loss: 0.378259, Time: 0.063650
2023-06-01 11:55:41,064:INFO: Epoch: 8/30, Step: 45/64, Lr: 0.001476437, Loss: 0.006718, Step Loss: 0.006718, Time: 0.068513
2023-06-01 11:55:41,143:INFO: Epoch: 8/30, Step: 46/64, Lr: 0.001476437, Loss: 0.028029, Step Loss: 0.028029, Time: 0.078502
2023-06-01 11:55:41,210:INFO: Epoch: 8/30, Step: 47/64, Lr: 0.001476437, Loss: 0.001259, Step Loss: 0.001259, Time: 0.066523
2023-06-01 11:55:41,283:INFO: Epoch: 8/30, Step: 48/64, Lr: 0.001476437, Loss: 0.073952, Step Loss: 0.073952, Time: 0.072842
2023-06-01 11:55:41,351:INFO: Epoch: 8/30, Step: 49/64, Lr: 0.001476437, Loss: 0.244212, Step Loss: 0.244212, Time: 0.067018
2023-06-01 11:55:41,419:INFO: Epoch: 8/30, Step: 50/64, Lr: 0.001476437, Loss: 0.004102, Step Loss: 0.004102, Time: 0.068184
2023-06-01 11:55:41,487:INFO: Epoch: 8/30, Step: 51/64, Lr: 0.001476437, Loss: 0.157784, Step Loss: 0.157784, Time: 0.067155
2023-06-01 11:55:41,555:INFO: Epoch: 8/30, Step: 52/64, Lr: 0.001476437, Loss: 0.075206, Step Loss: 0.075206, Time: 0.068018
2023-06-01 11:55:41,623:INFO: Epoch: 8/30, Step: 53/64, Lr: 0.001476437, Loss: 0.429775, Step Loss: 0.429775, Time: 0.067798
2023-06-01 11:55:41,695:INFO: Epoch: 8/30, Step: 54/64, Lr: 0.001476437, Loss: 0.158782, Step Loss: 0.158782, Time: 0.071167
2023-06-01 11:55:41,767:INFO: Epoch: 8/30, Step: 55/64, Lr: 0.001476437, Loss: 0.353625, Step Loss: 0.353625, Time: 0.070531
2023-06-01 11:55:41,835:INFO: Epoch: 8/30, Step: 56/64, Lr: 0.001476437, Loss: 0.508291, Step Loss: 0.508291, Time: 0.067778
2023-06-01 11:55:41,906:INFO: Epoch: 8/30, Step: 57/64, Lr: 0.001476437, Loss: 0.000248, Step Loss: 0.000248, Time: 0.070560
2023-06-01 11:55:41,974:INFO: Epoch: 8/30, Step: 58/64, Lr: 0.001476437, Loss: 0.017319, Step Loss: 0.017319, Time: 0.068074
2023-06-01 11:55:42,049:INFO: Epoch: 8/30, Step: 59/64, Lr: 0.001476437, Loss: 0.041606, Step Loss: 0.041606, Time: 0.074545
2023-06-01 11:55:42,115:INFO: Epoch: 8/30, Step: 60/64, Lr: 0.001476437, Loss: 0.002184, Step Loss: 0.002184, Time: 0.065093
2023-06-01 11:55:42,187:INFO: Epoch: 8/30, Step: 61/64, Lr: 0.001476437, Loss: 0.198189, Step Loss: 0.198189, Time: 0.071645
2023-06-01 11:55:42,252:INFO: Epoch: 8/30, Step: 62/64, Lr: 0.001476437, Loss: 0.011030, Step Loss: 0.011030, Time: 0.064283
2023-06-01 11:55:42,322:INFO: Epoch: 8/30, Step: 63/64, Lr: 0.001476437, Loss: 0.001222, Step Loss: 0.001222, Time: 0.070161
2023-06-01 11:55:42,393:INFO: Epoch: 8/30, Step: 64/64, Lr: 0.001476437, Loss: 0.007515, Step Loss: 0.007515, Time: 0.070719
2023-06-01 11:55:42,548:INFO: Epoch 8/30 Finished, Train Loss: 0.332833
2023-06-01 11:55:48,956:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.7
2023-06-01 11:55:52,079:INFO: Classfication Metrics:
2023-06-01 11:55:52,079:INFO: f1 score: 0.8765 - precision score: 0.8148 - recall score: 0.9483 - accuracy score: 0.894915
2023-06-01 11:55:52,079:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:55:53,202:INFO: Epoch: 9/30, Step: 1/64, Lr: 0.001447332, Loss: 0.000230, Step Loss: 0.000230, Time: 1.114652
2023-06-01 11:55:53,270:INFO: Epoch: 9/30, Step: 2/64, Lr: 0.001447332, Loss: 0.001244, Step Loss: 0.001244, Time: 0.066904
2023-06-01 11:55:53,335:INFO: Epoch: 9/30, Step: 3/64, Lr: 0.001447332, Loss: 0.000699, Step Loss: 0.000699, Time: 0.064841
2023-06-01 11:55:53,404:INFO: Epoch: 9/30, Step: 4/64, Lr: 0.001447332, Loss: 0.000112, Step Loss: 0.000112, Time: 0.069037
2023-06-01 11:55:53,474:INFO: Epoch: 9/30, Step: 5/64, Lr: 0.001447332, Loss: 0.005836, Step Loss: 0.005836, Time: 0.069201
2023-06-01 11:55:53,543:INFO: Epoch: 9/30, Step: 6/64, Lr: 0.001447332, Loss: 0.000066, Step Loss: 0.000066, Time: 0.068817
2023-06-01 11:55:53,609:INFO: Epoch: 9/30, Step: 7/64, Lr: 0.001447332, Loss: 0.108805, Step Loss: 0.108805, Time: 0.065694
2023-06-01 11:55:53,682:INFO: Epoch: 9/30, Step: 8/64, Lr: 0.001447332, Loss: 0.001177, Step Loss: 0.001177, Time: 0.072360
2023-06-01 11:55:53,750:INFO: Epoch: 9/30, Step: 9/64, Lr: 0.001447332, Loss: 0.000026, Step Loss: 0.000026, Time: 0.067454
2023-06-01 11:55:53,814:INFO: Epoch: 9/30, Step: 10/64, Lr: 0.001447332, Loss: 0.000033, Step Loss: 0.000033, Time: 0.064219
2023-06-01 11:55:53,883:INFO: Epoch: 9/30, Step: 11/64, Lr: 0.001447332, Loss: 0.000413, Step Loss: 0.000413, Time: 0.068072
2023-06-01 11:55:53,952:INFO: Epoch: 9/30, Step: 12/64, Lr: 0.001447332, Loss: 0.222556, Step Loss: 0.222556, Time: 0.068258
2023-06-01 11:55:54,016:INFO: Epoch: 9/30, Step: 13/64, Lr: 0.001447332, Loss: 0.020009, Step Loss: 0.020009, Time: 0.063579
2023-06-01 11:55:54,080:INFO: Epoch: 9/30, Step: 14/64, Lr: 0.001447332, Loss: 0.128693, Step Loss: 0.128693, Time: 0.063619
2023-06-01 11:55:54,150:INFO: Epoch: 9/30, Step: 15/64, Lr: 0.001447332, Loss: 0.006818, Step Loss: 0.006818, Time: 0.069976
2023-06-01 11:55:54,221:INFO: Epoch: 9/30, Step: 16/64, Lr: 0.001447332, Loss: 0.198219, Step Loss: 0.198219, Time: 0.070856
2023-06-01 11:55:54,289:INFO: Epoch: 9/30, Step: 17/64, Lr: 0.001447332, Loss: 0.008918, Step Loss: 0.008918, Time: 0.068024
2023-06-01 11:55:54,356:INFO: Epoch: 9/30, Step: 18/64, Lr: 0.001447332, Loss: 0.020877, Step Loss: 0.020877, Time: 0.065620
2023-06-01 11:55:54,426:INFO: Epoch: 9/30, Step: 19/64, Lr: 0.001447332, Loss: 0.262948, Step Loss: 0.262948, Time: 0.070080
2023-06-01 11:55:54,495:INFO: Epoch: 9/30, Step: 20/64, Lr: 0.001447332, Loss: 0.000043, Step Loss: 0.000043, Time: 0.068466
2023-06-01 11:55:54,562:INFO: Epoch: 9/30, Step: 21/64, Lr: 0.001447332, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067045
2023-06-01 11:55:54,627:INFO: Epoch: 9/30, Step: 22/64, Lr: 0.001447332, Loss: 0.000370, Step Loss: 0.000370, Time: 0.064334
2023-06-01 11:55:54,695:INFO: Epoch: 9/30, Step: 23/64, Lr: 0.001447332, Loss: 0.000181, Step Loss: 0.000181, Time: 0.067974
2023-06-01 11:55:54,763:INFO: Epoch: 9/30, Step: 24/64, Lr: 0.001447332, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066996
2023-06-01 11:55:54,831:INFO: Epoch: 9/30, Step: 25/64, Lr: 0.001447332, Loss: 0.200202, Step Loss: 0.200202, Time: 0.067487
2023-06-01 11:55:54,907:INFO: Epoch: 9/30, Step: 26/64, Lr: 0.001447332, Loss: 0.000527, Step Loss: 0.000527, Time: 0.076066
2023-06-01 11:55:54,971:INFO: Epoch: 9/30, Step: 27/64, Lr: 0.001447332, Loss: 0.858470, Step Loss: 0.858470, Time: 0.063894
2023-06-01 11:55:55,036:INFO: Epoch: 9/30, Step: 28/64, Lr: 0.001447332, Loss: 0.040016, Step Loss: 0.040016, Time: 0.063837
2023-06-01 11:55:55,105:INFO: Epoch: 9/30, Step: 29/64, Lr: 0.001447332, Loss: 0.156431, Step Loss: 0.156431, Time: 0.068588
2023-06-01 11:55:55,171:INFO: Epoch: 9/30, Step: 30/64, Lr: 0.001447332, Loss: 0.001090, Step Loss: 0.001090, Time: 0.065699
2023-06-01 11:55:55,239:INFO: Epoch: 9/30, Step: 31/64, Lr: 0.001447332, Loss: 0.000061, Step Loss: 0.000061, Time: 0.067427
2023-06-01 11:55:55,311:INFO: Epoch: 9/30, Step: 32/64, Lr: 0.001447332, Loss: 0.000058, Step Loss: 0.000058, Time: 0.071407
2023-06-01 11:55:55,378:INFO: Epoch: 9/30, Step: 33/64, Lr: 0.001447332, Loss: 0.007884, Step Loss: 0.007884, Time: 0.066599
2023-06-01 11:55:55,443:INFO: Epoch: 9/30, Step: 34/64, Lr: 0.001447332, Loss: 0.000185, Step Loss: 0.000185, Time: 0.064504
2023-06-01 11:55:55,509:INFO: Epoch: 9/30, Step: 35/64, Lr: 0.001447332, Loss: 0.003078, Step Loss: 0.003078, Time: 0.066440
2023-06-01 11:55:55,585:INFO: Epoch: 9/30, Step: 36/64, Lr: 0.001447332, Loss: 0.001826, Step Loss: 0.001826, Time: 0.075648
2023-06-01 11:55:55,651:INFO: Epoch: 9/30, Step: 37/64, Lr: 0.001447332, Loss: 0.227604, Step Loss: 0.227604, Time: 0.065082
2023-06-01 11:55:55,725:INFO: Epoch: 9/30, Step: 38/64, Lr: 0.001447332, Loss: 0.130682, Step Loss: 0.130682, Time: 0.073300
2023-06-01 11:55:55,798:INFO: Epoch: 9/30, Step: 39/64, Lr: 0.001447332, Loss: 0.006276, Step Loss: 0.006276, Time: 0.072729
2023-06-01 11:55:55,868:INFO: Epoch: 9/30, Step: 40/64, Lr: 0.001447332, Loss: 0.000153, Step Loss: 0.000153, Time: 0.069680
2023-06-01 11:55:55,935:INFO: Epoch: 9/30, Step: 41/64, Lr: 0.001447332, Loss: 0.007570, Step Loss: 0.007570, Time: 0.066308
2023-06-01 11:55:56,006:INFO: Epoch: 9/30, Step: 42/64, Lr: 0.001447332, Loss: 0.061927, Step Loss: 0.061927, Time: 0.071078
2023-06-01 11:55:56,078:INFO: Epoch: 9/30, Step: 43/64, Lr: 0.001447332, Loss: 0.014142, Step Loss: 0.014142, Time: 0.071246
2023-06-01 11:55:56,151:INFO: Epoch: 9/30, Step: 44/64, Lr: 0.001447332, Loss: 0.001627, Step Loss: 0.001627, Time: 0.072686
2023-06-01 11:55:56,215:INFO: Epoch: 9/30, Step: 45/64, Lr: 0.001447332, Loss: 0.015218, Step Loss: 0.015218, Time: 0.063961
2023-06-01 11:55:56,290:INFO: Epoch: 9/30, Step: 46/64, Lr: 0.001447332, Loss: 0.254625, Step Loss: 0.254625, Time: 0.073875
2023-06-01 11:55:56,358:INFO: Epoch: 9/30, Step: 47/64, Lr: 0.001447332, Loss: 0.730419, Step Loss: 0.730419, Time: 0.068319
2023-06-01 11:55:56,426:INFO: Epoch: 9/30, Step: 48/64, Lr: 0.001447332, Loss: 0.000087, Step Loss: 0.000087, Time: 0.067711
2023-06-01 11:55:56,494:INFO: Epoch: 9/30, Step: 49/64, Lr: 0.001447332, Loss: 0.003357, Step Loss: 0.003357, Time: 0.067374
2023-06-01 11:55:56,566:INFO: Epoch: 9/30, Step: 50/64, Lr: 0.001447332, Loss: 0.388482, Step Loss: 0.388482, Time: 0.071418
2023-06-01 11:55:56,631:INFO: Epoch: 9/30, Step: 51/64, Lr: 0.001447332, Loss: 0.000005, Step Loss: 0.000005, Time: 0.064141
2023-06-01 11:55:56,700:INFO: Epoch: 9/30, Step: 52/64, Lr: 0.001447332, Loss: 0.000573, Step Loss: 0.000573, Time: 0.068963
2023-06-01 11:55:56,764:INFO: Epoch: 9/30, Step: 53/64, Lr: 0.001447332, Loss: 0.000002, Step Loss: 0.000002, Time: 0.063861
2023-06-01 11:55:56,835:INFO: Epoch: 9/30, Step: 54/64, Lr: 0.001447332, Loss: 0.000036, Step Loss: 0.000036, Time: 0.070003
2023-06-01 11:55:56,903:INFO: Epoch: 9/30, Step: 55/64, Lr: 0.001447332, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067708
2023-06-01 11:55:56,968:INFO: Epoch: 9/30, Step: 56/64, Lr: 0.001447332, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064930
2023-06-01 11:55:57,038:INFO: Epoch: 9/30, Step: 57/64, Lr: 0.001447332, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068893
2023-06-01 11:55:57,108:INFO: Epoch: 9/30, Step: 58/64, Lr: 0.001447332, Loss: 0.008048, Step Loss: 0.008048, Time: 0.070421
2023-06-01 11:55:57,182:INFO: Epoch: 9/30, Step: 59/64, Lr: 0.001447332, Loss: 0.028648, Step Loss: 0.028648, Time: 0.073157
2023-06-01 11:55:57,254:INFO: Epoch: 9/30, Step: 60/64, Lr: 0.001447332, Loss: 0.001366, Step Loss: 0.001366, Time: 0.071063
2023-06-01 11:55:57,323:INFO: Epoch: 9/30, Step: 61/64, Lr: 0.001447332, Loss: 0.000321, Step Loss: 0.000321, Time: 0.068789
2023-06-01 11:55:57,388:INFO: Epoch: 9/30, Step: 62/64, Lr: 0.001447332, Loss: 0.000130, Step Loss: 0.000130, Time: 0.064338
2023-06-01 11:55:57,454:INFO: Epoch: 9/30, Step: 63/64, Lr: 0.001447332, Loss: 0.010761, Step Loss: 0.010761, Time: 0.066379
2023-06-01 11:55:57,523:INFO: Epoch: 9/30, Step: 64/64, Lr: 0.001447332, Loss: 0.008776, Step Loss: 0.008776, Time: 0.067940
2023-06-01 11:55:57,675:INFO: Epoch 9/30 Finished, Train Loss: 0.064983
2023-06-01 11:56:04,681:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.8
2023-06-01 11:56:07,830:INFO: Classfication Metrics:
2023-06-01 11:56:07,830:INFO: f1 score: 0.8831 - precision score: 0.8870 - recall score: 0.8793 - accuracy score: 0.908475
2023-06-01 11:56:07,830:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:56:08,867:INFO: Epoch: 10/30, Step: 1/64, Lr: 0.001407230, Loss: 0.015057, Step Loss: 0.015057, Time: 1.016464
2023-06-01 11:56:08,952:INFO: Epoch: 10/30, Step: 2/64, Lr: 0.001407230, Loss: 0.001393, Step Loss: 0.001393, Time: 0.085242
2023-06-01 11:56:09,021:INFO: Epoch: 10/30, Step: 3/64, Lr: 0.001407230, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068284
2023-06-01 11:56:09,087:INFO: Epoch: 10/30, Step: 4/64, Lr: 0.001407230, Loss: 0.079350, Step Loss: 0.079350, Time: 0.065499
2023-06-01 11:56:09,155:INFO: Epoch: 10/30, Step: 5/64, Lr: 0.001407230, Loss: 0.328902, Step Loss: 0.328902, Time: 0.068131
2023-06-01 11:56:09,219:INFO: Epoch: 10/30, Step: 6/64, Lr: 0.001407230, Loss: 0.000031, Step Loss: 0.000031, Time: 0.064005
2023-06-01 11:56:09,286:INFO: Epoch: 10/30, Step: 7/64, Lr: 0.001407230, Loss: 0.000045, Step Loss: 0.000045, Time: 0.066044
2023-06-01 11:56:09,352:INFO: Epoch: 10/30, Step: 8/64, Lr: 0.001407230, Loss: 0.002258, Step Loss: 0.002258, Time: 0.065905
2023-06-01 11:56:09,425:INFO: Epoch: 10/30, Step: 9/64, Lr: 0.001407230, Loss: 0.080084, Step Loss: 0.080084, Time: 0.072313
2023-06-01 11:56:09,506:INFO: Epoch: 10/30, Step: 10/64, Lr: 0.001407230, Loss: 0.001395, Step Loss: 0.001395, Time: 0.080734
2023-06-01 11:56:09,584:INFO: Epoch: 10/30, Step: 11/64, Lr: 0.001407230, Loss: 0.703060, Step Loss: 0.703060, Time: 0.078359
2023-06-01 11:56:09,650:INFO: Epoch: 10/30, Step: 12/64, Lr: 0.001407230, Loss: 0.000423, Step Loss: 0.000423, Time: 0.065629
2023-06-01 11:56:09,712:INFO: Epoch: 10/30, Step: 13/64, Lr: 0.001407230, Loss: 0.309656, Step Loss: 0.309656, Time: 0.061269
2023-06-01 11:56:09,778:INFO: Epoch: 10/30, Step: 14/64, Lr: 0.001407230, Loss: 0.362848, Step Loss: 0.362848, Time: 0.066470
2023-06-01 11:56:09,843:INFO: Epoch: 10/30, Step: 15/64, Lr: 0.001407230, Loss: 0.111784, Step Loss: 0.111784, Time: 0.064308
2023-06-01 11:56:09,907:INFO: Epoch: 10/30, Step: 16/64, Lr: 0.001407230, Loss: 0.697972, Step Loss: 0.697972, Time: 0.064134
2023-06-01 11:56:09,994:INFO: Epoch: 10/30, Step: 17/64, Lr: 0.001407230, Loss: 0.115093, Step Loss: 0.115093, Time: 0.086547
2023-06-01 11:56:10,072:INFO: Epoch: 10/30, Step: 18/64, Lr: 0.001407230, Loss: 0.000190, Step Loss: 0.000190, Time: 0.077087
2023-06-01 11:56:10,145:INFO: Epoch: 10/30, Step: 19/64, Lr: 0.001407230, Loss: 1.247893, Step Loss: 1.247893, Time: 0.072813
2023-06-01 11:56:10,215:INFO: Epoch: 10/30, Step: 20/64, Lr: 0.001407230, Loss: 0.032556, Step Loss: 0.032556, Time: 0.069654
2023-06-01 11:56:10,279:INFO: Epoch: 10/30, Step: 21/64, Lr: 0.001407230, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063255
2023-06-01 11:56:10,346:INFO: Epoch: 10/30, Step: 22/64, Lr: 0.001407230, Loss: 0.035166, Step Loss: 0.035166, Time: 0.067665
2023-06-01 11:56:10,421:INFO: Epoch: 10/30, Step: 23/64, Lr: 0.001407230, Loss: 0.061155, Step Loss: 0.061155, Time: 0.073893
2023-06-01 11:56:10,487:INFO: Epoch: 10/30, Step: 24/64, Lr: 0.001407230, Loss: 0.026030, Step Loss: 0.026030, Time: 0.065921
2023-06-01 11:56:10,559:INFO: Epoch: 10/30, Step: 25/64, Lr: 0.001407230, Loss: 0.022514, Step Loss: 0.022514, Time: 0.071449
2023-06-01 11:56:10,627:INFO: Epoch: 10/30, Step: 26/64, Lr: 0.001407230, Loss: 0.000053, Step Loss: 0.000053, Time: 0.067971
2023-06-01 11:56:10,694:INFO: Epoch: 10/30, Step: 27/64, Lr: 0.001407230, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066408
2023-06-01 11:56:10,771:INFO: Epoch: 10/30, Step: 28/64, Lr: 0.001407230, Loss: 0.269224, Step Loss: 0.269224, Time: 0.076832
2023-06-01 11:56:10,838:INFO: Epoch: 10/30, Step: 29/64, Lr: 0.001407230, Loss: 0.161753, Step Loss: 0.161753, Time: 0.066918
2023-06-01 11:56:10,903:INFO: Epoch: 10/30, Step: 30/64, Lr: 0.001407230, Loss: 0.085421, Step Loss: 0.085421, Time: 0.064844
2023-06-01 11:56:10,974:INFO: Epoch: 10/30, Step: 31/64, Lr: 0.001407230, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070884
2023-06-01 11:56:11,039:INFO: Epoch: 10/30, Step: 32/64, Lr: 0.001407230, Loss: 0.037735, Step Loss: 0.037735, Time: 0.064403
2023-06-01 11:56:11,107:INFO: Epoch: 10/30, Step: 33/64, Lr: 0.001407230, Loss: 0.000046, Step Loss: 0.000046, Time: 0.067725
2023-06-01 11:56:11,175:INFO: Epoch: 10/30, Step: 34/64, Lr: 0.001407230, Loss: 0.849123, Step Loss: 0.849123, Time: 0.067264
2023-06-01 11:56:11,248:INFO: Epoch: 10/30, Step: 35/64, Lr: 0.001407230, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072246
2023-06-01 11:56:11,314:INFO: Epoch: 10/30, Step: 36/64, Lr: 0.001407230, Loss: 0.000345, Step Loss: 0.000345, Time: 0.066160
2023-06-01 11:56:11,383:INFO: Epoch: 10/30, Step: 37/64, Lr: 0.001407230, Loss: 0.000295, Step Loss: 0.000295, Time: 0.068936
2023-06-01 11:56:11,455:INFO: Epoch: 10/30, Step: 38/64, Lr: 0.001407230, Loss: 0.000015, Step Loss: 0.000015, Time: 0.070787
2023-06-01 11:56:11,522:INFO: Epoch: 10/30, Step: 39/64, Lr: 0.001407230, Loss: 0.280523, Step Loss: 0.280523, Time: 0.067452
2023-06-01 11:56:11,593:INFO: Epoch: 10/30, Step: 40/64, Lr: 0.001407230, Loss: 0.000037, Step Loss: 0.000037, Time: 0.070816
2023-06-01 11:56:11,659:INFO: Epoch: 10/30, Step: 41/64, Lr: 0.001407230, Loss: 0.008322, Step Loss: 0.008322, Time: 0.065567
2023-06-01 11:56:11,727:INFO: Epoch: 10/30, Step: 42/64, Lr: 0.001407230, Loss: 0.255354, Step Loss: 0.255354, Time: 0.067465
2023-06-01 11:56:11,798:INFO: Epoch: 10/30, Step: 43/64, Lr: 0.001407230, Loss: 0.000280, Step Loss: 0.000280, Time: 0.071114
2023-06-01 11:56:11,865:INFO: Epoch: 10/30, Step: 44/64, Lr: 0.001407230, Loss: 0.005144, Step Loss: 0.005144, Time: 0.066698
2023-06-01 11:56:11,934:INFO: Epoch: 10/30, Step: 45/64, Lr: 0.001407230, Loss: 0.027751, Step Loss: 0.027751, Time: 0.068371
2023-06-01 11:56:11,999:INFO: Epoch: 10/30, Step: 46/64, Lr: 0.001407230, Loss: 0.001839, Step Loss: 0.001839, Time: 0.064716
2023-06-01 11:56:12,072:INFO: Epoch: 10/30, Step: 47/64, Lr: 0.001407230, Loss: 0.000026, Step Loss: 0.000026, Time: 0.072182
2023-06-01 11:56:12,139:INFO: Epoch: 10/30, Step: 48/64, Lr: 0.001407230, Loss: 0.000051, Step Loss: 0.000051, Time: 0.067240
2023-06-01 11:56:12,208:INFO: Epoch: 10/30, Step: 49/64, Lr: 0.001407230, Loss: 0.485046, Step Loss: 0.485046, Time: 0.067885
2023-06-01 11:56:12,278:INFO: Epoch: 10/30, Step: 50/64, Lr: 0.001407230, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069958
2023-06-01 11:56:12,347:INFO: Epoch: 10/30, Step: 51/64, Lr: 0.001407230, Loss: 0.024992, Step Loss: 0.024992, Time: 0.068297
2023-06-01 11:56:12,416:INFO: Epoch: 10/30, Step: 52/64, Lr: 0.001407230, Loss: 0.308171, Step Loss: 0.308171, Time: 0.068414
2023-06-01 11:56:12,480:INFO: Epoch: 10/30, Step: 53/64, Lr: 0.001407230, Loss: 0.584801, Step Loss: 0.584801, Time: 0.064097
2023-06-01 11:56:12,548:INFO: Epoch: 10/30, Step: 54/64, Lr: 0.001407230, Loss: 0.105103, Step Loss: 0.105103, Time: 0.067058
2023-06-01 11:56:12,626:INFO: Epoch: 10/30, Step: 55/64, Lr: 0.001407230, Loss: 0.000141, Step Loss: 0.000141, Time: 0.078321
2023-06-01 11:56:12,700:INFO: Epoch: 10/30, Step: 56/64, Lr: 0.001407230, Loss: 0.000023, Step Loss: 0.000023, Time: 0.072605
2023-06-01 11:56:12,766:INFO: Epoch: 10/30, Step: 57/64, Lr: 0.001407230, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065950
2023-06-01 11:56:12,837:INFO: Epoch: 10/30, Step: 58/64, Lr: 0.001407230, Loss: 0.000049, Step Loss: 0.000049, Time: 0.070716
2023-06-01 11:56:12,910:INFO: Epoch: 10/30, Step: 59/64, Lr: 0.001407230, Loss: 0.006186, Step Loss: 0.006186, Time: 0.072366
2023-06-01 11:56:12,976:INFO: Epoch: 10/30, Step: 60/64, Lr: 0.001407230, Loss: 0.000314, Step Loss: 0.000314, Time: 0.065408
2023-06-01 11:56:13,043:INFO: Epoch: 10/30, Step: 61/64, Lr: 0.001407230, Loss: 0.000088, Step Loss: 0.000088, Time: 0.067147
2023-06-01 11:56:13,115:INFO: Epoch: 10/30, Step: 62/64, Lr: 0.001407230, Loss: 0.455741, Step Loss: 0.455741, Time: 0.071185
2023-06-01 11:56:13,182:INFO: Epoch: 10/30, Step: 63/64, Lr: 0.001407230, Loss: 0.587680, Step Loss: 0.587680, Time: 0.067450
2023-06-01 11:56:13,250:INFO: Epoch: 10/30, Step: 64/64, Lr: 0.001407230, Loss: 0.000223, Step Loss: 0.000223, Time: 0.067463
2023-06-01 11:56:13,391:INFO: Epoch 10/30 Finished, Train Loss: 0.137137
2023-06-01 11:56:21,234:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.9
2023-06-01 11:56:24,316:INFO: Classfication Metrics:
2023-06-01 11:56:24,317:INFO: f1 score: 0.8482 - precision score: 0.7730 - recall score: 0.9397 - accuracy score: 0.867797
2023-06-01 11:56:24,317:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:56:25,325:INFO: Epoch: 11/30, Step: 1/64, Lr: 0.001356763, Loss: 0.000033, Step Loss: 0.000033, Time: 0.987735
2023-06-01 11:56:25,418:INFO: Epoch: 11/30, Step: 2/64, Lr: 0.001356763, Loss: 0.112601, Step Loss: 0.112601, Time: 0.092396
2023-06-01 11:56:25,490:INFO: Epoch: 11/30, Step: 3/64, Lr: 0.001356763, Loss: 0.001593, Step Loss: 0.001593, Time: 0.071080
2023-06-01 11:56:25,561:INFO: Epoch: 11/30, Step: 4/64, Lr: 0.001356763, Loss: 0.282862, Step Loss: 0.282862, Time: 0.071167
2023-06-01 11:56:25,631:INFO: Epoch: 11/30, Step: 5/64, Lr: 0.001356763, Loss: 0.065156, Step Loss: 0.065156, Time: 0.069719
2023-06-01 11:56:25,698:INFO: Epoch: 11/30, Step: 6/64, Lr: 0.001356763, Loss: 0.088575, Step Loss: 0.088575, Time: 0.066830
2023-06-01 11:56:25,769:INFO: Epoch: 11/30, Step: 7/64, Lr: 0.001356763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070478
2023-06-01 11:56:25,839:INFO: Epoch: 11/30, Step: 8/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070128
2023-06-01 11:56:25,914:INFO: Epoch: 11/30, Step: 9/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073963
2023-06-01 11:56:25,988:INFO: Epoch: 11/30, Step: 10/64, Lr: 0.001356763, Loss: 0.006998, Step Loss: 0.006998, Time: 0.073855
2023-06-01 11:56:26,054:INFO: Epoch: 11/30, Step: 11/64, Lr: 0.001356763, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066118
2023-06-01 11:56:26,119:INFO: Epoch: 11/30, Step: 12/64, Lr: 0.001356763, Loss: 0.092932, Step Loss: 0.092932, Time: 0.064025
2023-06-01 11:56:26,199:INFO: Epoch: 11/30, Step: 13/64, Lr: 0.001356763, Loss: 0.005215, Step Loss: 0.005215, Time: 0.079754
2023-06-01 11:56:26,264:INFO: Epoch: 11/30, Step: 14/64, Lr: 0.001356763, Loss: 0.041265, Step Loss: 0.041265, Time: 0.064394
2023-06-01 11:56:26,330:INFO: Epoch: 11/30, Step: 15/64, Lr: 0.001356763, Loss: 0.335208, Step Loss: 0.335208, Time: 0.066168
2023-06-01 11:56:26,399:INFO: Epoch: 11/30, Step: 16/64, Lr: 0.001356763, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068457
2023-06-01 11:56:26,471:INFO: Epoch: 11/30, Step: 17/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071831
2023-06-01 11:56:26,538:INFO: Epoch: 11/30, Step: 18/64, Lr: 0.001356763, Loss: 0.003942, Step Loss: 0.003942, Time: 0.066147
2023-06-01 11:56:26,612:INFO: Epoch: 11/30, Step: 19/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073578
2023-06-01 11:56:26,682:INFO: Epoch: 11/30, Step: 20/64, Lr: 0.001356763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069779
2023-06-01 11:56:26,755:INFO: Epoch: 11/30, Step: 21/64, Lr: 0.001356763, Loss: 0.486683, Step Loss: 0.486683, Time: 0.072387
2023-06-01 11:56:26,819:INFO: Epoch: 11/30, Step: 22/64, Lr: 0.001356763, Loss: 1.200237, Step Loss: 1.200237, Time: 0.064232
2023-06-01 11:56:26,893:INFO: Epoch: 11/30, Step: 23/64, Lr: 0.001356763, Loss: 0.000092, Step Loss: 0.000092, Time: 0.073332
2023-06-01 11:56:26,967:INFO: Epoch: 11/30, Step: 24/64, Lr: 0.001356763, Loss: 0.000359, Step Loss: 0.000359, Time: 0.073530
2023-06-01 11:56:27,037:INFO: Epoch: 11/30, Step: 25/64, Lr: 0.001356763, Loss: 0.003580, Step Loss: 0.003580, Time: 0.070046
2023-06-01 11:56:27,106:INFO: Epoch: 11/30, Step: 26/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067957
2023-06-01 11:56:27,174:INFO: Epoch: 11/30, Step: 27/64, Lr: 0.001356763, Loss: 0.000653, Step Loss: 0.000653, Time: 0.068456
2023-06-01 11:56:27,243:INFO: Epoch: 11/30, Step: 28/64, Lr: 0.001356763, Loss: 0.000733, Step Loss: 0.000733, Time: 0.068095
2023-06-01 11:56:27,311:INFO: Epoch: 11/30, Step: 29/64, Lr: 0.001356763, Loss: 0.047667, Step Loss: 0.047667, Time: 0.067947
2023-06-01 11:56:27,382:INFO: Epoch: 11/30, Step: 30/64, Lr: 0.001356763, Loss: 0.007911, Step Loss: 0.007911, Time: 0.070458
2023-06-01 11:56:27,447:INFO: Epoch: 11/30, Step: 31/64, Lr: 0.001356763, Loss: 0.000119, Step Loss: 0.000119, Time: 0.064524
2023-06-01 11:56:27,515:INFO: Epoch: 11/30, Step: 32/64, Lr: 0.001356763, Loss: 0.000008, Step Loss: 0.000008, Time: 0.067538
2023-06-01 11:56:27,590:INFO: Epoch: 11/30, Step: 33/64, Lr: 0.001356763, Loss: 0.120576, Step Loss: 0.120576, Time: 0.074957
2023-06-01 11:56:27,656:INFO: Epoch: 11/30, Step: 34/64, Lr: 0.001356763, Loss: 0.000644, Step Loss: 0.000644, Time: 0.065554
2023-06-01 11:56:27,726:INFO: Epoch: 11/30, Step: 35/64, Lr: 0.001356763, Loss: 0.029590, Step Loss: 0.029590, Time: 0.069798
2023-06-01 11:56:27,803:INFO: Epoch: 11/30, Step: 36/64, Lr: 0.001356763, Loss: 0.652598, Step Loss: 0.652598, Time: 0.077307
2023-06-01 11:56:27,871:INFO: Epoch: 11/30, Step: 37/64, Lr: 0.001356763, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066956
2023-06-01 11:56:27,940:INFO: Epoch: 11/30, Step: 38/64, Lr: 0.001356763, Loss: 0.000106, Step Loss: 0.000106, Time: 0.069413
2023-06-01 11:56:28,006:INFO: Epoch: 11/30, Step: 39/64, Lr: 0.001356763, Loss: 0.003983, Step Loss: 0.003983, Time: 0.066032
2023-06-01 11:56:28,075:INFO: Epoch: 11/30, Step: 40/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067930
2023-06-01 11:56:28,148:INFO: Epoch: 11/30, Step: 41/64, Lr: 0.001356763, Loss: 0.902045, Step Loss: 0.902045, Time: 0.072816
2023-06-01 11:56:28,224:INFO: Epoch: 11/30, Step: 42/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075800
2023-06-01 11:56:28,291:INFO: Epoch: 11/30, Step: 43/64, Lr: 0.001356763, Loss: 0.415599, Step Loss: 0.415599, Time: 0.066502
2023-06-01 11:56:28,355:INFO: Epoch: 11/30, Step: 44/64, Lr: 0.001356763, Loss: 0.000028, Step Loss: 0.000028, Time: 0.064588
2023-06-01 11:56:28,424:INFO: Epoch: 11/30, Step: 45/64, Lr: 0.001356763, Loss: 0.131576, Step Loss: 0.131576, Time: 0.068260
2023-06-01 11:56:28,495:INFO: Epoch: 11/30, Step: 46/64, Lr: 0.001356763, Loss: 0.002016, Step Loss: 0.002016, Time: 0.070581
2023-06-01 11:56:28,563:INFO: Epoch: 11/30, Step: 47/64, Lr: 0.001356763, Loss: 0.757062, Step Loss: 0.757062, Time: 0.067906
2023-06-01 11:56:28,635:INFO: Epoch: 11/30, Step: 48/64, Lr: 0.001356763, Loss: 0.000215, Step Loss: 0.000215, Time: 0.071667
2023-06-01 11:56:28,707:INFO: Epoch: 11/30, Step: 49/64, Lr: 0.001356763, Loss: 0.000056, Step Loss: 0.000056, Time: 0.071357
2023-06-01 11:56:28,772:INFO: Epoch: 11/30, Step: 50/64, Lr: 0.001356763, Loss: 0.000004, Step Loss: 0.000004, Time: 0.065057
2023-06-01 11:56:28,838:INFO: Epoch: 11/30, Step: 51/64, Lr: 0.001356763, Loss: 0.302136, Step Loss: 0.302136, Time: 0.065222
2023-06-01 11:56:28,911:INFO: Epoch: 11/30, Step: 52/64, Lr: 0.001356763, Loss: 0.000004, Step Loss: 0.000004, Time: 0.072402
2023-06-01 11:56:28,979:INFO: Epoch: 11/30, Step: 53/64, Lr: 0.001356763, Loss: 0.000136, Step Loss: 0.000136, Time: 0.068376
2023-06-01 11:56:29,048:INFO: Epoch: 11/30, Step: 54/64, Lr: 0.001356763, Loss: 0.010007, Step Loss: 0.010007, Time: 0.068367
2023-06-01 11:56:29,120:INFO: Epoch: 11/30, Step: 55/64, Lr: 0.001356763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.072153
2023-06-01 11:56:29,188:INFO: Epoch: 11/30, Step: 56/64, Lr: 0.001356763, Loss: 0.342648, Step Loss: 0.342648, Time: 0.067372
2023-06-01 11:56:29,248:INFO: Epoch: 11/30, Step: 57/64, Lr: 0.001356763, Loss: 0.050940, Step Loss: 0.050940, Time: 0.060109
2023-06-01 11:56:29,323:INFO: Epoch: 11/30, Step: 58/64, Lr: 0.001356763, Loss: 0.000496, Step Loss: 0.000496, Time: 0.074131
2023-06-01 11:56:29,399:INFO: Epoch: 11/30, Step: 59/64, Lr: 0.001356763, Loss: 0.133362, Step Loss: 0.133362, Time: 0.076009
2023-06-01 11:56:29,469:INFO: Epoch: 11/30, Step: 60/64, Lr: 0.001356763, Loss: 0.017942, Step Loss: 0.017942, Time: 0.069811
2023-06-01 11:56:29,534:INFO: Epoch: 11/30, Step: 61/64, Lr: 0.001356763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064688
2023-06-01 11:56:29,602:INFO: Epoch: 11/30, Step: 62/64, Lr: 0.001356763, Loss: 0.303989, Step Loss: 0.303989, Time: 0.066944
2023-06-01 11:56:29,670:INFO: Epoch: 11/30, Step: 63/64, Lr: 0.001356763, Loss: 0.000446, Step Loss: 0.000446, Time: 0.068082
2023-06-01 11:56:29,742:INFO: Epoch: 11/30, Step: 64/64, Lr: 0.001356763, Loss: 0.002332, Step Loss: 0.002332, Time: 0.071696
2023-06-01 11:56:29,895:INFO: Epoch 11/30 Finished, Train Loss: 0.108828
2023-06-01 11:56:36,865:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.10
2023-06-01 11:56:39,962:INFO: Classfication Metrics:
2023-06-01 11:56:39,962:INFO: f1 score: 0.8309 - precision score: 0.9451 - recall score: 0.7414 - accuracy score: 0.881356
2023-06-01 11:56:39,962:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:56:41,084:INFO: Epoch: 12/30, Step: 1/64, Lr: 0.001296726, Loss: 0.000025, Step Loss: 0.000025, Time: 1.113756
2023-06-01 11:56:41,155:INFO: Epoch: 12/30, Step: 2/64, Lr: 0.001296726, Loss: 0.250496, Step Loss: 0.250496, Time: 0.070444
2023-06-01 11:56:41,229:INFO: Epoch: 12/30, Step: 3/64, Lr: 0.001296726, Loss: 0.069440, Step Loss: 0.069440, Time: 0.074085
2023-06-01 11:56:41,295:INFO: Epoch: 12/30, Step: 4/64, Lr: 0.001296726, Loss: 0.000137, Step Loss: 0.000137, Time: 0.064822
2023-06-01 11:56:41,363:INFO: Epoch: 12/30, Step: 5/64, Lr: 0.001296726, Loss: 0.000024, Step Loss: 0.000024, Time: 0.068396
2023-06-01 11:56:41,437:INFO: Epoch: 12/30, Step: 6/64, Lr: 0.001296726, Loss: 0.004640, Step Loss: 0.004640, Time: 0.073084
2023-06-01 11:56:41,503:INFO: Epoch: 12/30, Step: 7/64, Lr: 0.001296726, Loss: 0.013289, Step Loss: 0.013289, Time: 0.065534
2023-06-01 11:56:41,570:INFO: Epoch: 12/30, Step: 8/64, Lr: 0.001296726, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066303
2023-06-01 11:56:41,647:INFO: Epoch: 12/30, Step: 9/64, Lr: 0.001296726, Loss: 0.000012, Step Loss: 0.000012, Time: 0.076706
2023-06-01 11:56:41,714:INFO: Epoch: 12/30, Step: 10/64, Lr: 0.001296726, Loss: 0.000027, Step Loss: 0.000027, Time: 0.066463
2023-06-01 11:56:41,787:INFO: Epoch: 12/30, Step: 11/64, Lr: 0.001296726, Loss: 0.548386, Step Loss: 0.548386, Time: 0.073310
2023-06-01 11:56:41,855:INFO: Epoch: 12/30, Step: 12/64, Lr: 0.001296726, Loss: 0.072470, Step Loss: 0.072470, Time: 0.066611
2023-06-01 11:56:41,928:INFO: Epoch: 12/30, Step: 13/64, Lr: 0.001296726, Loss: 0.000047, Step Loss: 0.000047, Time: 0.072848
2023-06-01 11:56:41,994:INFO: Epoch: 12/30, Step: 14/64, Lr: 0.001296726, Loss: 0.000005, Step Loss: 0.000005, Time: 0.065634
2023-06-01 11:56:42,059:INFO: Epoch: 12/30, Step: 15/64, Lr: 0.001296726, Loss: 0.024225, Step Loss: 0.024225, Time: 0.064719
2023-06-01 11:56:42,124:INFO: Epoch: 12/30, Step: 16/64, Lr: 0.001296726, Loss: 0.332860, Step Loss: 0.332860, Time: 0.064108
2023-06-01 11:56:42,194:INFO: Epoch: 12/30, Step: 17/64, Lr: 0.001296726, Loss: 0.853764, Step Loss: 0.853764, Time: 0.069685
2023-06-01 11:56:42,258:INFO: Epoch: 12/30, Step: 18/64, Lr: 0.001296726, Loss: 0.000112, Step Loss: 0.000112, Time: 0.064278
2023-06-01 11:56:42,327:INFO: Epoch: 12/30, Step: 19/64, Lr: 0.001296726, Loss: 0.000007, Step Loss: 0.000007, Time: 0.068655
2023-06-01 11:56:42,394:INFO: Epoch: 12/30, Step: 20/64, Lr: 0.001296726, Loss: 0.009826, Step Loss: 0.009826, Time: 0.066142
2023-06-01 11:56:42,463:INFO: Epoch: 12/30, Step: 21/64, Lr: 0.001296726, Loss: 0.000043, Step Loss: 0.000043, Time: 0.068481
2023-06-01 11:56:42,528:INFO: Epoch: 12/30, Step: 22/64, Lr: 0.001296726, Loss: 0.006893, Step Loss: 0.006893, Time: 0.064207
2023-06-01 11:56:42,598:INFO: Epoch: 12/30, Step: 23/64, Lr: 0.001296726, Loss: 0.025319, Step Loss: 0.025319, Time: 0.069829
2023-06-01 11:56:42,663:INFO: Epoch: 12/30, Step: 24/64, Lr: 0.001296726, Loss: 1.310688, Step Loss: 1.310688, Time: 0.064536
2023-06-01 11:56:42,733:INFO: Epoch: 12/30, Step: 25/64, Lr: 0.001296726, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070273
2023-06-01 11:56:42,799:INFO: Epoch: 12/30, Step: 26/64, Lr: 0.001296726, Loss: 0.004217, Step Loss: 0.004217, Time: 0.065348
2023-06-01 11:56:42,870:INFO: Epoch: 12/30, Step: 27/64, Lr: 0.001296726, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070049
2023-06-01 11:56:42,938:INFO: Epoch: 12/30, Step: 28/64, Lr: 0.001296726, Loss: 0.016844, Step Loss: 0.016844, Time: 0.067335
2023-06-01 11:56:43,006:INFO: Epoch: 12/30, Step: 29/64, Lr: 0.001296726, Loss: 0.014979, Step Loss: 0.014979, Time: 0.068056
2023-06-01 11:56:43,077:INFO: Epoch: 12/30, Step: 30/64, Lr: 0.001296726, Loss: 0.327305, Step Loss: 0.327305, Time: 0.070055
2023-06-01 11:56:43,147:INFO: Epoch: 12/30, Step: 31/64, Lr: 0.001296726, Loss: 0.223823, Step Loss: 0.223823, Time: 0.070101
2023-06-01 11:56:43,211:INFO: Epoch: 12/30, Step: 32/64, Lr: 0.001296726, Loss: 0.000948, Step Loss: 0.000948, Time: 0.063882
2023-06-01 11:56:43,283:INFO: Epoch: 12/30, Step: 33/64, Lr: 0.001296726, Loss: 0.029362, Step Loss: 0.029362, Time: 0.071480
2023-06-01 11:56:43,352:INFO: Epoch: 12/30, Step: 34/64, Lr: 0.001296726, Loss: 0.000327, Step Loss: 0.000327, Time: 0.068249
2023-06-01 11:56:43,419:INFO: Epoch: 12/30, Step: 35/64, Lr: 0.001296726, Loss: 0.000581, Step Loss: 0.000581, Time: 0.066807
2023-06-01 11:56:43,489:INFO: Epoch: 12/30, Step: 36/64, Lr: 0.001296726, Loss: 0.000343, Step Loss: 0.000343, Time: 0.069877
2023-06-01 11:56:43,559:INFO: Epoch: 12/30, Step: 37/64, Lr: 0.001296726, Loss: 0.000022, Step Loss: 0.000022, Time: 0.069049
2023-06-01 11:56:43,626:INFO: Epoch: 12/30, Step: 38/64, Lr: 0.001296726, Loss: 0.773301, Step Loss: 0.773301, Time: 0.066930
2023-06-01 11:56:43,701:INFO: Epoch: 12/30, Step: 39/64, Lr: 0.001296726, Loss: 0.483358, Step Loss: 0.483358, Time: 0.074098
2023-06-01 11:56:43,768:INFO: Epoch: 12/30, Step: 40/64, Lr: 0.001296726, Loss: 0.000174, Step Loss: 0.000174, Time: 0.066281
2023-06-01 11:56:43,839:INFO: Epoch: 12/30, Step: 41/64, Lr: 0.001296726, Loss: 0.004701, Step Loss: 0.004701, Time: 0.070516
2023-06-01 11:56:43,903:INFO: Epoch: 12/30, Step: 42/64, Lr: 0.001296726, Loss: 0.000942, Step Loss: 0.000942, Time: 0.064329
2023-06-01 11:56:43,969:INFO: Epoch: 12/30, Step: 43/64, Lr: 0.001296726, Loss: 0.000006, Step Loss: 0.000006, Time: 0.064887
2023-06-01 11:56:44,038:INFO: Epoch: 12/30, Step: 44/64, Lr: 0.001296726, Loss: 0.000018, Step Loss: 0.000018, Time: 0.068766
2023-06-01 11:56:44,106:INFO: Epoch: 12/30, Step: 45/64, Lr: 0.001296726, Loss: 0.000650, Step Loss: 0.000650, Time: 0.068071
2023-06-01 11:56:44,183:INFO: Epoch: 12/30, Step: 46/64, Lr: 0.001296726, Loss: 0.000436, Step Loss: 0.000436, Time: 0.076348
2023-06-01 11:56:44,250:INFO: Epoch: 12/30, Step: 47/64, Lr: 0.001296726, Loss: 0.684113, Step Loss: 0.684113, Time: 0.066164
2023-06-01 11:56:44,319:INFO: Epoch: 12/30, Step: 48/64, Lr: 0.001296726, Loss: 0.172513, Step Loss: 0.172513, Time: 0.068829
2023-06-01 11:56:44,387:INFO: Epoch: 12/30, Step: 49/64, Lr: 0.001296726, Loss: 0.088783, Step Loss: 0.088783, Time: 0.067819
2023-06-01 11:56:44,461:INFO: Epoch: 12/30, Step: 50/64, Lr: 0.001296726, Loss: 0.000045, Step Loss: 0.000045, Time: 0.073328
2023-06-01 11:56:44,535:INFO: Epoch: 12/30, Step: 51/64, Lr: 0.001296726, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073246
2023-06-01 11:56:44,599:INFO: Epoch: 12/30, Step: 52/64, Lr: 0.001296726, Loss: 0.000050, Step Loss: 0.000050, Time: 0.064323
2023-06-01 11:56:44,677:INFO: Epoch: 12/30, Step: 53/64, Lr: 0.001296726, Loss: 0.011636, Step Loss: 0.011636, Time: 0.076097
2023-06-01 11:56:44,746:INFO: Epoch: 12/30, Step: 54/64, Lr: 0.001296726, Loss: 0.000111, Step Loss: 0.000111, Time: 0.069477
2023-06-01 11:56:44,814:INFO: Epoch: 12/30, Step: 55/64, Lr: 0.001296726, Loss: 0.001714, Step Loss: 0.001714, Time: 0.067497
2023-06-01 11:56:44,885:INFO: Epoch: 12/30, Step: 56/64, Lr: 0.001296726, Loss: 0.236931, Step Loss: 0.236931, Time: 0.070539
2023-06-01 11:56:44,950:INFO: Epoch: 12/30, Step: 57/64, Lr: 0.001296726, Loss: 0.514139, Step Loss: 0.514139, Time: 0.064372
2023-06-01 11:56:45,019:INFO: Epoch: 12/30, Step: 58/64, Lr: 0.001296726, Loss: 0.000349, Step Loss: 0.000349, Time: 0.068241
2023-06-01 11:56:45,087:INFO: Epoch: 12/30, Step: 59/64, Lr: 0.001296726, Loss: 0.011821, Step Loss: 0.011821, Time: 0.067473
2023-06-01 11:56:45,155:INFO: Epoch: 12/30, Step: 60/64, Lr: 0.001296726, Loss: 0.011206, Step Loss: 0.011206, Time: 0.068236
2023-06-01 11:56:45,224:INFO: Epoch: 12/30, Step: 61/64, Lr: 0.001296726, Loss: 0.000357, Step Loss: 0.000357, Time: 0.068455
2023-06-01 11:56:45,295:INFO: Epoch: 12/30, Step: 62/64, Lr: 0.001296726, Loss: 0.000355, Step Loss: 0.000355, Time: 0.070015
2023-06-01 11:56:45,361:INFO: Epoch: 12/30, Step: 63/64, Lr: 0.001296726, Loss: 0.083655, Step Loss: 0.083655, Time: 0.065909
2023-06-01 11:56:45,430:INFO: Epoch: 12/30, Step: 64/64, Lr: 0.001296726, Loss: 0.000215, Step Loss: 0.000215, Time: 0.068534
2023-06-01 11:56:45,581:INFO: Epoch 12/30 Finished, Train Loss: 0.112860
2023-06-01 11:56:52,532:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.11
2023-06-01 11:56:55,681:INFO: Classfication Metrics:
2023-06-01 11:56:55,681:INFO: f1 score: 0.8302 - precision score: 0.9167 - recall score: 0.7586 - accuracy score: 0.877966
2023-06-01 11:56:55,681:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:56:56,806:INFO: Epoch: 13/30, Step: 1/64, Lr: 0.001228068, Loss: 0.002207, Step Loss: 0.002207, Time: 1.116397
2023-06-01 11:56:56,871:INFO: Epoch: 13/30, Step: 2/64, Lr: 0.001228068, Loss: 0.058624, Step Loss: 0.058624, Time: 0.065000
2023-06-01 11:56:56,940:INFO: Epoch: 13/30, Step: 3/64, Lr: 0.001228068, Loss: 0.000006, Step Loss: 0.000006, Time: 0.068076
2023-06-01 11:56:57,006:INFO: Epoch: 13/30, Step: 4/64, Lr: 0.001228068, Loss: 0.000035, Step Loss: 0.000035, Time: 0.065942
2023-06-01 11:56:57,089:INFO: Epoch: 13/30, Step: 5/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.082385
2023-06-01 11:56:57,155:INFO: Epoch: 13/30, Step: 6/64, Lr: 0.001228068, Loss: 0.000004, Step Loss: 0.000004, Time: 0.065262
2023-06-01 11:56:57,220:INFO: Epoch: 13/30, Step: 7/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064619
2023-06-01 11:56:57,286:INFO: Epoch: 13/30, Step: 8/64, Lr: 0.001228068, Loss: 0.000144, Step Loss: 0.000144, Time: 0.066107
2023-06-01 11:56:57,352:INFO: Epoch: 13/30, Step: 9/64, Lr: 0.001228068, Loss: 0.019136, Step Loss: 0.019136, Time: 0.064970
2023-06-01 11:56:57,419:INFO: Epoch: 13/30, Step: 10/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066376
2023-06-01 11:56:57,484:INFO: Epoch: 13/30, Step: 11/64, Lr: 0.001228068, Loss: 0.168383, Step Loss: 0.168383, Time: 0.064685
2023-06-01 11:56:57,553:INFO: Epoch: 13/30, Step: 12/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068679
2023-06-01 11:56:57,634:INFO: Epoch: 13/30, Step: 13/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.081124
2023-06-01 11:56:57,703:INFO: Epoch: 13/30, Step: 14/64, Lr: 0.001228068, Loss: 0.000496, Step Loss: 0.000496, Time: 0.067865
2023-06-01 11:56:57,773:INFO: Epoch: 13/30, Step: 15/64, Lr: 0.001228068, Loss: 0.000010, Step Loss: 0.000010, Time: 0.070274
2023-06-01 11:56:57,839:INFO: Epoch: 13/30, Step: 16/64, Lr: 0.001228068, Loss: 0.000199, Step Loss: 0.000199, Time: 0.065002
2023-06-01 11:56:57,911:INFO: Epoch: 13/30, Step: 17/64, Lr: 0.001228068, Loss: 0.000019, Step Loss: 0.000019, Time: 0.072062
2023-06-01 11:56:57,979:INFO: Epoch: 13/30, Step: 18/64, Lr: 0.001228068, Loss: 0.000700, Step Loss: 0.000700, Time: 0.067329
2023-06-01 11:56:58,047:INFO: Epoch: 13/30, Step: 19/64, Lr: 0.001228068, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067658
2023-06-01 11:56:58,115:INFO: Epoch: 13/30, Step: 20/64, Lr: 0.001228068, Loss: 0.000002, Step Loss: 0.000002, Time: 0.067092
2023-06-01 11:56:58,189:INFO: Epoch: 13/30, Step: 21/64, Lr: 0.001228068, Loss: 0.085436, Step Loss: 0.085436, Time: 0.074398
2023-06-01 11:56:58,255:INFO: Epoch: 13/30, Step: 22/64, Lr: 0.001228068, Loss: 0.000240, Step Loss: 0.000240, Time: 0.065596
2023-06-01 11:56:58,324:INFO: Epoch: 13/30, Step: 23/64, Lr: 0.001228068, Loss: 0.000017, Step Loss: 0.000017, Time: 0.067912
2023-06-01 11:56:58,391:INFO: Epoch: 13/30, Step: 24/64, Lr: 0.001228068, Loss: 0.000733, Step Loss: 0.000733, Time: 0.066987
2023-06-01 11:56:58,462:INFO: Epoch: 13/30, Step: 25/64, Lr: 0.001228068, Loss: 0.000561, Step Loss: 0.000561, Time: 0.070729
2023-06-01 11:56:58,531:INFO: Epoch: 13/30, Step: 26/64, Lr: 0.001228068, Loss: 0.032990, Step Loss: 0.032990, Time: 0.067939
2023-06-01 11:56:58,598:INFO: Epoch: 13/30, Step: 27/64, Lr: 0.001228068, Loss: 0.057107, Step Loss: 0.057107, Time: 0.067184
2023-06-01 11:56:58,663:INFO: Epoch: 13/30, Step: 28/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063992
2023-06-01 11:56:58,729:INFO: Epoch: 13/30, Step: 29/64, Lr: 0.001228068, Loss: 0.007099, Step Loss: 0.007099, Time: 0.065779
2023-06-01 11:56:58,794:INFO: Epoch: 13/30, Step: 30/64, Lr: 0.001228068, Loss: 0.000008, Step Loss: 0.000008, Time: 0.064432
2023-06-01 11:56:58,855:INFO: Epoch: 13/30, Step: 31/64, Lr: 0.001228068, Loss: 0.156916, Step Loss: 0.156916, Time: 0.060093
2023-06-01 11:56:58,918:INFO: Epoch: 13/30, Step: 32/64, Lr: 0.001228068, Loss: 0.000571, Step Loss: 0.000571, Time: 0.062635
2023-06-01 11:56:58,987:INFO: Epoch: 13/30, Step: 33/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069237
2023-06-01 11:56:59,051:INFO: Epoch: 13/30, Step: 34/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063627
2023-06-01 11:56:59,115:INFO: Epoch: 13/30, Step: 35/64, Lr: 0.001228068, Loss: 0.000022, Step Loss: 0.000022, Time: 0.063117
2023-06-01 11:56:59,186:INFO: Epoch: 13/30, Step: 36/64, Lr: 0.001228068, Loss: 0.000009, Step Loss: 0.000009, Time: 0.070399
2023-06-01 11:56:59,246:INFO: Epoch: 13/30, Step: 37/64, Lr: 0.001228068, Loss: 0.000004, Step Loss: 0.000004, Time: 0.060182
2023-06-01 11:56:59,318:INFO: Epoch: 13/30, Step: 38/64, Lr: 0.001228068, Loss: 0.000005, Step Loss: 0.000005, Time: 0.071611
2023-06-01 11:56:59,382:INFO: Epoch: 13/30, Step: 39/64, Lr: 0.001228068, Loss: 0.000132, Step Loss: 0.000132, Time: 0.062732
2023-06-01 11:56:59,444:INFO: Epoch: 13/30, Step: 40/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.062208
2023-06-01 11:56:59,508:INFO: Epoch: 13/30, Step: 41/64, Lr: 0.001228068, Loss: 0.012241, Step Loss: 0.012241, Time: 0.063011
2023-06-01 11:56:59,576:INFO: Epoch: 13/30, Step: 42/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067512
2023-06-01 11:56:59,640:INFO: Epoch: 13/30, Step: 43/64, Lr: 0.001228068, Loss: 0.000047, Step Loss: 0.000047, Time: 0.063569
2023-06-01 11:56:59,710:INFO: Epoch: 13/30, Step: 44/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070079
2023-06-01 11:56:59,780:INFO: Epoch: 13/30, Step: 45/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069068
2023-06-01 11:56:59,846:INFO: Epoch: 13/30, Step: 46/64, Lr: 0.001228068, Loss: 0.004298, Step Loss: 0.004298, Time: 0.066174
2023-06-01 11:56:59,915:INFO: Epoch: 13/30, Step: 47/64, Lr: 0.001228068, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067763
2023-06-01 11:56:59,984:INFO: Epoch: 13/30, Step: 48/64, Lr: 0.001228068, Loss: 0.000271, Step Loss: 0.000271, Time: 0.068501
2023-06-01 11:57:00,052:INFO: Epoch: 13/30, Step: 49/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068390
2023-06-01 11:57:00,119:INFO: Epoch: 13/30, Step: 50/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065885
2023-06-01 11:57:00,199:INFO: Epoch: 13/30, Step: 51/64, Lr: 0.001228068, Loss: 0.000001, Step Loss: 0.000001, Time: 0.079651
2023-06-01 11:57:00,275:INFO: Epoch: 13/30, Step: 52/64, Lr: 0.001228068, Loss: 0.518197, Step Loss: 0.518197, Time: 0.075464
2023-06-01 11:57:00,345:INFO: Epoch: 13/30, Step: 53/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070046
2023-06-01 11:57:00,414:INFO: Epoch: 13/30, Step: 54/64, Lr: 0.001228068, Loss: 0.213473, Step Loss: 0.213473, Time: 0.068953
2023-06-01 11:57:00,483:INFO: Epoch: 13/30, Step: 55/64, Lr: 0.001228068, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068524
2023-06-01 11:57:00,551:INFO: Epoch: 13/30, Step: 56/64, Lr: 0.001228068, Loss: 0.000281, Step Loss: 0.000281, Time: 0.066764
2023-06-01 11:57:00,617:INFO: Epoch: 13/30, Step: 57/64, Lr: 0.001228068, Loss: 0.000022, Step Loss: 0.000022, Time: 0.066068
2023-06-01 11:57:00,688:INFO: Epoch: 13/30, Step: 58/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070167
2023-06-01 11:57:00,756:INFO: Epoch: 13/30, Step: 59/64, Lr: 0.001228068, Loss: 0.007756, Step Loss: 0.007756, Time: 0.067390
2023-06-01 11:57:00,826:INFO: Epoch: 13/30, Step: 60/64, Lr: 0.001228068, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069494
2023-06-01 11:57:00,895:INFO: Epoch: 13/30, Step: 61/64, Lr: 0.001228068, Loss: 0.000349, Step Loss: 0.000349, Time: 0.069203
2023-06-01 11:57:00,962:INFO: Epoch: 13/30, Step: 62/64, Lr: 0.001228068, Loss: 0.020805, Step Loss: 0.020805, Time: 0.066245
2023-06-01 11:57:01,035:INFO: Epoch: 13/30, Step: 63/64, Lr: 0.001228068, Loss: 0.000479, Step Loss: 0.000479, Time: 0.072980
2023-06-01 11:57:01,103:INFO: Epoch: 13/30, Step: 64/64, Lr: 0.001228068, Loss: 0.053804, Step Loss: 0.053804, Time: 0.067454
2023-06-01 11:57:01,258:INFO: Epoch 13/30 Finished, Train Loss: 0.022248
2023-06-01 11:57:09,560:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.12
2023-06-01 11:57:12,695:INFO: Classfication Metrics:
2023-06-01 11:57:12,695:INFO: f1 score: 0.8291 - precision score: 0.7170 - recall score: 0.9828 - accuracy score: 0.840678
2023-06-01 11:57:12,695:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:57:13,697:INFO: Epoch: 14/30, Step: 1/64, Lr: 0.001151870, Loss: 0.000001, Step Loss: 0.000001, Time: 0.980724
2023-06-01 11:57:13,783:INFO: Epoch: 14/30, Step: 2/64, Lr: 0.001151870, Loss: 0.000109, Step Loss: 0.000109, Time: 0.085289
2023-06-01 11:57:13,847:INFO: Epoch: 14/30, Step: 3/64, Lr: 0.001151870, Loss: 0.000010, Step Loss: 0.000010, Time: 0.064238
2023-06-01 11:57:13,915:INFO: Epoch: 14/30, Step: 4/64, Lr: 0.001151870, Loss: 0.000094, Step Loss: 0.000094, Time: 0.067623
2023-06-01 11:57:13,985:INFO: Epoch: 14/30, Step: 5/64, Lr: 0.001151870, Loss: 0.000048, Step Loss: 0.000048, Time: 0.069063
2023-06-01 11:57:14,054:INFO: Epoch: 14/30, Step: 6/64, Lr: 0.001151870, Loss: 0.024235, Step Loss: 0.024235, Time: 0.068831
2023-06-01 11:57:14,119:INFO: Epoch: 14/30, Step: 7/64, Lr: 0.001151870, Loss: 0.000044, Step Loss: 0.000044, Time: 0.064831
2023-06-01 11:57:14,199:INFO: Epoch: 14/30, Step: 8/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079005
2023-06-01 11:57:14,267:INFO: Epoch: 14/30, Step: 9/64, Lr: 0.001151870, Loss: 0.342294, Step Loss: 0.342294, Time: 0.067519
2023-06-01 11:57:14,338:INFO: Epoch: 14/30, Step: 10/64, Lr: 0.001151870, Loss: 0.004002, Step Loss: 0.004002, Time: 0.070727
2023-06-01 11:57:14,405:INFO: Epoch: 14/30, Step: 11/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067201
2023-06-01 11:57:14,471:INFO: Epoch: 14/30, Step: 12/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065314
2023-06-01 11:57:14,538:INFO: Epoch: 14/30, Step: 13/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066778
2023-06-01 11:57:14,606:INFO: Epoch: 14/30, Step: 14/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066971
2023-06-01 11:57:14,670:INFO: Epoch: 14/30, Step: 15/64, Lr: 0.001151870, Loss: 0.000005, Step Loss: 0.000005, Time: 0.063306
2023-06-01 11:57:14,747:INFO: Epoch: 14/30, Step: 16/64, Lr: 0.001151870, Loss: 0.000393, Step Loss: 0.000393, Time: 0.077237
2023-06-01 11:57:14,811:INFO: Epoch: 14/30, Step: 17/64, Lr: 0.001151870, Loss: 0.129153, Step Loss: 0.129153, Time: 0.063457
2023-06-01 11:57:14,878:INFO: Epoch: 14/30, Step: 18/64, Lr: 0.001151870, Loss: 0.000539, Step Loss: 0.000539, Time: 0.066758
2023-06-01 11:57:14,946:INFO: Epoch: 14/30, Step: 19/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067949
2023-06-01 11:57:15,022:INFO: Epoch: 14/30, Step: 20/64, Lr: 0.001151870, Loss: 0.002463, Step Loss: 0.002463, Time: 0.075323
2023-06-01 11:57:15,088:INFO: Epoch: 14/30, Step: 21/64, Lr: 0.001151870, Loss: 0.011158, Step Loss: 0.011158, Time: 0.064994
2023-06-01 11:57:15,159:INFO: Epoch: 14/30, Step: 22/64, Lr: 0.001151870, Loss: 0.000006, Step Loss: 0.000006, Time: 0.070509
2023-06-01 11:57:15,229:INFO: Epoch: 14/30, Step: 23/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069889
2023-06-01 11:57:15,300:INFO: Epoch: 14/30, Step: 24/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070004
2023-06-01 11:57:15,371:INFO: Epoch: 14/30, Step: 25/64, Lr: 0.001151870, Loss: 0.000008, Step Loss: 0.000008, Time: 0.070972
2023-06-01 11:57:15,441:INFO: Epoch: 14/30, Step: 26/64, Lr: 0.001151870, Loss: 0.000141, Step Loss: 0.000141, Time: 0.070007
2023-06-01 11:57:15,510:INFO: Epoch: 14/30, Step: 27/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068335
2023-06-01 11:57:15,583:INFO: Epoch: 14/30, Step: 28/64, Lr: 0.001151870, Loss: 0.000014, Step Loss: 0.000014, Time: 0.072263
2023-06-01 11:57:15,651:INFO: Epoch: 14/30, Step: 29/64, Lr: 0.001151870, Loss: 0.000056, Step Loss: 0.000056, Time: 0.067813
2023-06-01 11:57:15,722:INFO: Epoch: 14/30, Step: 30/64, Lr: 0.001151870, Loss: 0.000014, Step Loss: 0.000014, Time: 0.070848
2023-06-01 11:57:15,792:INFO: Epoch: 14/30, Step: 31/64, Lr: 0.001151870, Loss: 0.000151, Step Loss: 0.000151, Time: 0.069559
2023-06-01 11:57:15,860:INFO: Epoch: 14/30, Step: 32/64, Lr: 0.001151870, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066750
2023-06-01 11:57:15,933:INFO: Epoch: 14/30, Step: 33/64, Lr: 0.001151870, Loss: 0.000709, Step Loss: 0.000709, Time: 0.072981
2023-06-01 11:57:16,012:INFO: Epoch: 14/30, Step: 34/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.077934
2023-06-01 11:57:16,083:INFO: Epoch: 14/30, Step: 35/64, Lr: 0.001151870, Loss: 0.028798, Step Loss: 0.028798, Time: 0.070796
2023-06-01 11:57:16,154:INFO: Epoch: 14/30, Step: 36/64, Lr: 0.001151870, Loss: 0.000007, Step Loss: 0.000007, Time: 0.070983
2023-06-01 11:57:16,225:INFO: Epoch: 14/30, Step: 37/64, Lr: 0.001151870, Loss: 0.000173, Step Loss: 0.000173, Time: 0.070771
2023-06-01 11:57:16,305:INFO: Epoch: 14/30, Step: 38/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079336
2023-06-01 11:57:16,372:INFO: Epoch: 14/30, Step: 39/64, Lr: 0.001151870, Loss: 0.000202, Step Loss: 0.000202, Time: 0.065791
2023-06-01 11:57:16,439:INFO: Epoch: 14/30, Step: 40/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067167
2023-06-01 11:57:16,515:INFO: Epoch: 14/30, Step: 41/64, Lr: 0.001151870, Loss: 0.000040, Step Loss: 0.000040, Time: 0.075164
2023-06-01 11:57:16,582:INFO: Epoch: 14/30, Step: 42/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066988
2023-06-01 11:57:16,647:INFO: Epoch: 14/30, Step: 43/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064668
2023-06-01 11:57:16,719:INFO: Epoch: 14/30, Step: 44/64, Lr: 0.001151870, Loss: 0.000006, Step Loss: 0.000006, Time: 0.070949
2023-06-01 11:57:16,787:INFO: Epoch: 14/30, Step: 45/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067421
2023-06-01 11:57:16,859:INFO: Epoch: 14/30, Step: 46/64, Lr: 0.001151870, Loss: 0.000636, Step Loss: 0.000636, Time: 0.072093
2023-06-01 11:57:16,931:INFO: Epoch: 14/30, Step: 47/64, Lr: 0.001151870, Loss: 0.000043, Step Loss: 0.000043, Time: 0.071587
2023-06-01 11:57:17,003:INFO: Epoch: 14/30, Step: 48/64, Lr: 0.001151870, Loss: 0.000003, Step Loss: 0.000003, Time: 0.071612
2023-06-01 11:57:17,072:INFO: Epoch: 14/30, Step: 49/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068496
2023-06-01 11:57:17,139:INFO: Epoch: 14/30, Step: 50/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067263
2023-06-01 11:57:17,210:INFO: Epoch: 14/30, Step: 51/64, Lr: 0.001151870, Loss: 0.070486, Step Loss: 0.070486, Time: 0.069973
2023-06-01 11:57:17,282:INFO: Epoch: 14/30, Step: 52/64, Lr: 0.001151870, Loss: 0.004550, Step Loss: 0.004550, Time: 0.071826
2023-06-01 11:57:17,364:INFO: Epoch: 14/30, Step: 53/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.081529
2023-06-01 11:57:17,441:INFO: Epoch: 14/30, Step: 54/64, Lr: 0.001151870, Loss: 0.000003, Step Loss: 0.000003, Time: 0.076926
2023-06-01 11:57:17,508:INFO: Epoch: 14/30, Step: 55/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065750
2023-06-01 11:57:17,579:INFO: Epoch: 14/30, Step: 56/64, Lr: 0.001151870, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071154
2023-06-01 11:57:17,654:INFO: Epoch: 14/30, Step: 57/64, Lr: 0.001151870, Loss: 0.000012, Step Loss: 0.000012, Time: 0.074263
2023-06-01 11:57:17,725:INFO: Epoch: 14/30, Step: 58/64, Lr: 0.001151870, Loss: 0.000019, Step Loss: 0.000019, Time: 0.070518
2023-06-01 11:57:17,799:INFO: Epoch: 14/30, Step: 59/64, Lr: 0.001151870, Loss: 0.091917, Step Loss: 0.091917, Time: 0.074171
2023-06-01 11:57:17,860:INFO: Epoch: 14/30, Step: 60/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.060222
2023-06-01 11:57:17,933:INFO: Epoch: 14/30, Step: 61/64, Lr: 0.001151870, Loss: 0.001095, Step Loss: 0.001095, Time: 0.073281
2023-06-01 11:57:18,004:INFO: Epoch: 14/30, Step: 62/64, Lr: 0.001151870, Loss: 0.000862, Step Loss: 0.000862, Time: 0.070841
2023-06-01 11:57:18,074:INFO: Epoch: 14/30, Step: 63/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069106
2023-06-01 11:57:18,144:INFO: Epoch: 14/30, Step: 64/64, Lr: 0.001151870, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070304
2023-06-01 11:57:18,306:INFO: Epoch 14/30 Finished, Train Loss: 0.011164
2023-06-01 11:57:26,216:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.13
2023-06-01 11:57:29,364:INFO: Classfication Metrics:
2023-06-01 11:57:29,365:INFO: f1 score: 0.8482 - precision score: 0.8796 - recall score: 0.8190 - accuracy score: 0.884746
2023-06-01 11:57:29,365:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:57:30,436:INFO: Epoch: 15/30, Step: 1/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 1.049778
2023-06-01 11:57:30,502:INFO: Epoch: 15/30, Step: 2/64, Lr: 0.001069334, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066043
2023-06-01 11:57:30,578:INFO: Epoch: 15/30, Step: 3/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075645
2023-06-01 11:57:30,648:INFO: Epoch: 15/30, Step: 4/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069402
2023-06-01 11:57:30,714:INFO: Epoch: 15/30, Step: 5/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066254
2023-06-01 11:57:30,783:INFO: Epoch: 15/30, Step: 6/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069034
2023-06-01 11:57:30,846:INFO: Epoch: 15/30, Step: 7/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.062765
2023-06-01 11:57:30,910:INFO: Epoch: 15/30, Step: 8/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063190
2023-06-01 11:57:30,986:INFO: Epoch: 15/30, Step: 9/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075721
2023-06-01 11:57:31,050:INFO: Epoch: 15/30, Step: 10/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063581
2023-06-01 11:57:31,115:INFO: Epoch: 15/30, Step: 11/64, Lr: 0.001069334, Loss: 0.013221, Step Loss: 0.013221, Time: 0.064421
2023-06-01 11:57:31,192:INFO: Epoch: 15/30, Step: 12/64, Lr: 0.001069334, Loss: 0.000002, Step Loss: 0.000002, Time: 0.076844
2023-06-01 11:57:31,255:INFO: Epoch: 15/30, Step: 13/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063023
2023-06-01 11:57:31,318:INFO: Epoch: 15/30, Step: 14/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063108
2023-06-01 11:57:31,382:INFO: Epoch: 15/30, Step: 15/64, Lr: 0.001069334, Loss: 0.000002, Step Loss: 0.000002, Time: 0.063319
2023-06-01 11:57:31,453:INFO: Epoch: 15/30, Step: 16/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070525
2023-06-01 11:57:31,546:INFO: Epoch: 15/30, Step: 17/64, Lr: 0.001069334, Loss: 0.000403, Step Loss: 0.000403, Time: 0.092625
2023-06-01 11:57:31,610:INFO: Epoch: 15/30, Step: 18/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064237
2023-06-01 11:57:31,674:INFO: Epoch: 15/30, Step: 19/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063810
2023-06-01 11:57:31,753:INFO: Epoch: 15/30, Step: 20/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.077893
2023-06-01 11:57:31,838:INFO: Epoch: 15/30, Step: 21/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.085394
2023-06-01 11:57:31,906:INFO: Epoch: 15/30, Step: 22/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067327
2023-06-01 11:57:31,975:INFO: Epoch: 15/30, Step: 23/64, Lr: 0.001069334, Loss: 0.000913, Step Loss: 0.000913, Time: 0.068275
2023-06-01 11:57:32,042:INFO: Epoch: 15/30, Step: 24/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066546
2023-06-01 11:57:32,114:INFO: Epoch: 15/30, Step: 25/64, Lr: 0.001069334, Loss: 0.000296, Step Loss: 0.000296, Time: 0.071949
2023-06-01 11:57:32,180:INFO: Epoch: 15/30, Step: 26/64, Lr: 0.001069334, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065396
2023-06-01 11:57:32,246:INFO: Epoch: 15/30, Step: 27/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065580
2023-06-01 11:57:32,313:INFO: Epoch: 15/30, Step: 28/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066448
2023-06-01 11:57:32,382:INFO: Epoch: 15/30, Step: 29/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068423
2023-06-01 11:57:32,450:INFO: Epoch: 15/30, Step: 30/64, Lr: 0.001069334, Loss: 0.246662, Step Loss: 0.246662, Time: 0.067531
2023-06-01 11:57:32,520:INFO: Epoch: 15/30, Step: 31/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070040
2023-06-01 11:57:32,587:INFO: Epoch: 15/30, Step: 32/64, Lr: 0.001069334, Loss: 0.000004, Step Loss: 0.000004, Time: 0.065804
2023-06-01 11:57:32,658:INFO: Epoch: 15/30, Step: 33/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071008
2023-06-01 11:57:32,727:INFO: Epoch: 15/30, Step: 34/64, Lr: 0.001069334, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068533
2023-06-01 11:57:32,795:INFO: Epoch: 15/30, Step: 35/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067488
2023-06-01 11:57:32,866:INFO: Epoch: 15/30, Step: 36/64, Lr: 0.001069334, Loss: 0.000367, Step Loss: 0.000367, Time: 0.070688
2023-06-01 11:57:32,931:INFO: Epoch: 15/30, Step: 37/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064053
2023-06-01 11:57:32,998:INFO: Epoch: 15/30, Step: 38/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067322
2023-06-01 11:57:33,067:INFO: Epoch: 15/30, Step: 39/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068244
2023-06-01 11:57:33,142:INFO: Epoch: 15/30, Step: 40/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074991
2023-06-01 11:57:33,211:INFO: Epoch: 15/30, Step: 41/64, Lr: 0.001069334, Loss: 0.000195, Step Loss: 0.000195, Time: 0.068544
2023-06-01 11:57:33,276:INFO: Epoch: 15/30, Step: 42/64, Lr: 0.001069334, Loss: 0.012796, Step Loss: 0.012796, Time: 0.064892
2023-06-01 11:57:33,344:INFO: Epoch: 15/30, Step: 43/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066863
2023-06-01 11:57:33,408:INFO: Epoch: 15/30, Step: 44/64, Lr: 0.001069334, Loss: 0.001365, Step Loss: 0.001365, Time: 0.063622
2023-06-01 11:57:33,479:INFO: Epoch: 15/30, Step: 45/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070726
2023-06-01 11:57:33,550:INFO: Epoch: 15/30, Step: 46/64, Lr: 0.001069334, Loss: 0.000005, Step Loss: 0.000005, Time: 0.071159
2023-06-01 11:57:33,629:INFO: Epoch: 15/30, Step: 47/64, Lr: 0.001069334, Loss: 0.000016, Step Loss: 0.000016, Time: 0.078211
2023-06-01 11:57:33,694:INFO: Epoch: 15/30, Step: 48/64, Lr: 0.001069334, Loss: 0.001821, Step Loss: 0.001821, Time: 0.065161
2023-06-01 11:57:33,759:INFO: Epoch: 15/30, Step: 49/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064208
2023-06-01 11:57:33,822:INFO: Epoch: 15/30, Step: 50/64, Lr: 0.001069334, Loss: 0.000146, Step Loss: 0.000146, Time: 0.063302
2023-06-01 11:57:33,886:INFO: Epoch: 15/30, Step: 51/64, Lr: 0.001069334, Loss: 0.006346, Step Loss: 0.006346, Time: 0.063543
2023-06-01 11:57:33,953:INFO: Epoch: 15/30, Step: 52/64, Lr: 0.001069334, Loss: 0.057186, Step Loss: 0.057186, Time: 0.066328
2023-06-01 11:57:34,026:INFO: Epoch: 15/30, Step: 53/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072806
2023-06-01 11:57:34,099:INFO: Epoch: 15/30, Step: 54/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072741
2023-06-01 11:57:34,162:INFO: Epoch: 15/30, Step: 55/64, Lr: 0.001069334, Loss: 0.394347, Step Loss: 0.394347, Time: 0.062623
2023-06-01 11:57:34,226:INFO: Epoch: 15/30, Step: 56/64, Lr: 0.001069334, Loss: 0.000005, Step Loss: 0.000005, Time: 0.064204
2023-06-01 11:57:34,291:INFO: Epoch: 15/30, Step: 57/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064047
2023-06-01 11:57:34,356:INFO: Epoch: 15/30, Step: 58/64, Lr: 0.001069334, Loss: 0.543354, Step Loss: 0.543354, Time: 0.065170
2023-06-01 11:57:34,429:INFO: Epoch: 15/30, Step: 59/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072991
2023-06-01 11:57:34,498:INFO: Epoch: 15/30, Step: 60/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068055
2023-06-01 11:57:34,565:INFO: Epoch: 15/30, Step: 61/64, Lr: 0.001069334, Loss: 0.000039, Step Loss: 0.000039, Time: 0.067368
2023-06-01 11:57:34,632:INFO: Epoch: 15/30, Step: 62/64, Lr: 0.001069334, Loss: 0.000254, Step Loss: 0.000254, Time: 0.066439
2023-06-01 11:57:34,701:INFO: Epoch: 15/30, Step: 63/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068827
2023-06-01 11:57:34,774:INFO: Epoch: 15/30, Step: 64/64, Lr: 0.001069334, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072584
2023-06-01 11:57:34,978:INFO: Epoch 15/30 Finished, Train Loss: 0.019996
2023-06-01 11:57:50,267:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.14
2023-06-01 11:57:53,441:INFO: Classfication Metrics:
2023-06-01 11:57:53,441:INFO: f1 score: 0.8619 - precision score: 0.8374 - recall score: 0.8879 - accuracy score: 0.888136
2023-06-01 11:57:53,441:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.5, the F1 is: 0.8871
2023-06-01 11:57:54,421:INFO: Epoch: 16/30, Step: 1/64, Lr: 0.000981763, Loss: 0.000009, Step Loss: 0.000009, Time: 0.971507
2023-06-01 11:57:54,559:INFO: Epoch: 16/30, Step: 2/64, Lr: 0.000981763, Loss: 0.352675, Step Loss: 0.352675, Time: 0.137365
2023-06-01 11:57:54,627:INFO: Epoch: 16/30, Step: 3/64, Lr: 0.000981763, Loss: 0.007988, Step Loss: 0.007988, Time: 0.067164
2023-06-01 11:57:54,691:INFO: Epoch: 16/30, Step: 4/64, Lr: 0.000981763, Loss: 0.065016, Step Loss: 0.065016, Time: 0.063750
2023-06-01 11:57:54,757:INFO: Epoch: 16/30, Step: 5/64, Lr: 0.000981763, Loss: 0.002117, Step Loss: 0.002117, Time: 0.065771
2023-06-01 11:57:54,825:INFO: Epoch: 16/30, Step: 6/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067482
2023-06-01 11:57:54,890:INFO: Epoch: 16/30, Step: 7/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065136
2023-06-01 11:57:54,958:INFO: Epoch: 16/30, Step: 8/64, Lr: 0.000981763, Loss: 0.000002, Step Loss: 0.000002, Time: 0.067975
2023-06-01 11:57:55,026:INFO: Epoch: 16/30, Step: 9/64, Lr: 0.000981763, Loss: 0.001163, Step Loss: 0.001163, Time: 0.066930
2023-06-01 11:57:55,102:INFO: Epoch: 16/30, Step: 10/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.076157
2023-06-01 11:57:55,173:INFO: Epoch: 16/30, Step: 11/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070795
2023-06-01 11:57:55,238:INFO: Epoch: 16/30, Step: 12/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064919
2023-06-01 11:57:55,312:INFO: Epoch: 16/30, Step: 13/64, Lr: 0.000981763, Loss: 0.000004, Step Loss: 0.000004, Time: 0.073793
2023-06-01 11:57:55,378:INFO: Epoch: 16/30, Step: 14/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065191
2023-06-01 11:57:55,447:INFO: Epoch: 16/30, Step: 15/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068481
2023-06-01 11:57:55,517:INFO: Epoch: 16/30, Step: 16/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069861
2023-06-01 11:57:55,582:INFO: Epoch: 16/30, Step: 17/64, Lr: 0.000981763, Loss: 0.000149, Step Loss: 0.000149, Time: 0.064484
2023-06-01 11:57:55,658:INFO: Epoch: 16/30, Step: 18/64, Lr: 0.000981763, Loss: 0.000008, Step Loss: 0.000008, Time: 0.076074
2023-06-01 11:57:55,722:INFO: Epoch: 16/30, Step: 19/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063805
2023-06-01 11:57:55,786:INFO: Epoch: 16/30, Step: 20/64, Lr: 0.000981763, Loss: 0.000006, Step Loss: 0.000006, Time: 0.063808
2023-06-01 11:57:55,850:INFO: Epoch: 16/30, Step: 21/64, Lr: 0.000981763, Loss: 0.000003, Step Loss: 0.000003, Time: 0.063694
2023-06-01 11:57:55,924:INFO: Epoch: 16/30, Step: 22/64, Lr: 0.000981763, Loss: 0.000833, Step Loss: 0.000833, Time: 0.073697
2023-06-01 11:57:55,997:INFO: Epoch: 16/30, Step: 23/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072378
2023-06-01 11:57:56,065:INFO: Epoch: 16/30, Step: 24/64, Lr: 0.000981763, Loss: 0.000098, Step Loss: 0.000098, Time: 0.067825
2023-06-01 11:57:56,131:INFO: Epoch: 16/30, Step: 25/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065383
2023-06-01 11:57:56,202:INFO: Epoch: 16/30, Step: 26/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071048
2023-06-01 11:57:56,272:INFO: Epoch: 16/30, Step: 27/64, Lr: 0.000981763, Loss: 0.000132, Step Loss: 0.000132, Time: 0.069338
2023-06-01 11:57:56,341:INFO: Epoch: 16/30, Step: 28/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068859
2023-06-01 11:57:56,410:INFO: Epoch: 16/30, Step: 29/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068991
2023-06-01 11:57:56,477:INFO: Epoch: 16/30, Step: 30/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066435
2023-06-01 11:57:56,550:INFO: Epoch: 16/30, Step: 31/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072729
2023-06-01 11:57:56,614:INFO: Epoch: 16/30, Step: 32/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064057
2023-06-01 11:57:56,679:INFO: Epoch: 16/30, Step: 33/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064341
2023-06-01 11:57:56,747:INFO: Epoch: 16/30, Step: 34/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067605
2023-06-01 11:57:56,814:INFO: Epoch: 16/30, Step: 35/64, Lr: 0.000981763, Loss: 0.000019, Step Loss: 0.000019, Time: 0.066623
2023-06-01 11:57:56,882:INFO: Epoch: 16/30, Step: 36/64, Lr: 0.000981763, Loss: 0.000277, Step Loss: 0.000277, Time: 0.067511
2023-06-01 11:57:56,949:INFO: Epoch: 16/30, Step: 37/64, Lr: 0.000981763, Loss: 0.000007, Step Loss: 0.000007, Time: 0.067505
2023-06-01 11:57:57,018:INFO: Epoch: 16/30, Step: 38/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067984
2023-06-01 11:57:57,083:INFO: Epoch: 16/30, Step: 39/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065206
2023-06-01 11:57:57,150:INFO: Epoch: 16/30, Step: 40/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066429
2023-06-01 11:57:57,212:INFO: Epoch: 16/30, Step: 41/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.061911
2023-06-01 11:57:57,283:INFO: Epoch: 16/30, Step: 42/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070413
2023-06-01 11:57:57,347:INFO: Epoch: 16/30, Step: 43/64, Lr: 0.000981763, Loss: 0.000312, Step Loss: 0.000312, Time: 0.064074
2023-06-01 11:57:57,417:INFO: Epoch: 16/30, Step: 44/64, Lr: 0.000981763, Loss: 0.014571, Step Loss: 0.014571, Time: 0.069939
2023-06-01 11:57:57,489:INFO: Epoch: 16/30, Step: 45/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071086
2023-06-01 11:57:57,555:INFO: Epoch: 16/30, Step: 46/64, Lr: 0.000981763, Loss: 0.000039, Step Loss: 0.000039, Time: 0.065932
2023-06-01 11:57:57,620:INFO: Epoch: 16/30, Step: 47/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064511
2023-06-01 11:57:57,686:INFO: Epoch: 16/30, Step: 48/64, Lr: 0.000981763, Loss: 0.000075, Step Loss: 0.000075, Time: 0.065994
2023-06-01 11:57:57,755:INFO: Epoch: 16/30, Step: 49/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069263
2023-06-01 11:57:57,825:INFO: Epoch: 16/30, Step: 50/64, Lr: 0.000981763, Loss: 0.000379, Step Loss: 0.000379, Time: 0.068955
2023-06-01 11:57:57,900:INFO: Epoch: 16/30, Step: 51/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075424
2023-06-01 11:57:57,969:INFO: Epoch: 16/30, Step: 52/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067989
2023-06-01 11:57:58,033:INFO: Epoch: 16/30, Step: 53/64, Lr: 0.000981763, Loss: 0.000222, Step Loss: 0.000222, Time: 0.063841
2023-06-01 11:57:58,092:INFO: Epoch: 16/30, Step: 54/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.058960
2023-06-01 11:57:58,157:INFO: Epoch: 16/30, Step: 55/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064353
2023-06-01 11:57:58,218:INFO: Epoch: 16/30, Step: 56/64, Lr: 0.000981763, Loss: 0.000016, Step Loss: 0.000016, Time: 0.060825
2023-06-01 11:57:58,297:INFO: Epoch: 16/30, Step: 57/64, Lr: 0.000981763, Loss: 0.002948, Step Loss: 0.002948, Time: 0.078543
2023-06-01 11:57:58,365:INFO: Epoch: 16/30, Step: 58/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067982
2023-06-01 11:57:58,431:INFO: Epoch: 16/30, Step: 59/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065947
2023-06-01 11:57:58,502:INFO: Epoch: 16/30, Step: 60/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070933
2023-06-01 11:57:58,567:INFO: Epoch: 16/30, Step: 61/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064809
2023-06-01 11:57:58,634:INFO: Epoch: 16/30, Step: 62/64, Lr: 0.000981763, Loss: 0.005983, Step Loss: 0.005983, Time: 0.066512
2023-06-01 11:57:58,709:INFO: Epoch: 16/30, Step: 63/64, Lr: 0.000981763, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074219
2023-06-01 11:57:58,775:INFO: Epoch: 16/30, Step: 64/64, Lr: 0.000981763, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065430
2023-06-01 11:57:58,935:INFO: Epoch 16/30 Finished, Train Loss: 0.007110
2023-06-01 11:58:06,719:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15
2023-06-01 11:58:09,879:INFO: Classfication Metrics:
2023-06-01 11:58:09,879:INFO: f1 score: 0.8898 - precision score: 0.8750 - recall score: 0.9052 - accuracy score: 0.911864
2023-06-01 11:58:09,879:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15, the F1 is: 0.8898
2023-06-01 11:58:10,935:INFO: Epoch: 17/30, Step: 1/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 1.047074
2023-06-01 11:58:11,010:INFO: Epoch: 17/30, Step: 2/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074603
2023-06-01 11:58:11,077:INFO: Epoch: 17/30, Step: 3/64, Lr: 0.000890536, Loss: 0.029465, Step Loss: 0.029465, Time: 0.066808
2023-06-01 11:58:11,141:INFO: Epoch: 17/30, Step: 4/64, Lr: 0.000890536, Loss: 0.000003, Step Loss: 0.000003, Time: 0.063167
2023-06-01 11:58:11,206:INFO: Epoch: 17/30, Step: 5/64, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065295
2023-06-01 11:58:11,273:INFO: Epoch: 17/30, Step: 6/64, Lr: 0.000890536, Loss: 0.000003, Step Loss: 0.000003, Time: 0.066751
2023-06-01 11:58:11,339:INFO: Epoch: 17/30, Step: 7/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065281
2023-06-01 11:58:11,408:INFO: Epoch: 17/30, Step: 8/64, Lr: 0.000890536, Loss: 0.014612, Step Loss: 0.014612, Time: 0.068383
2023-06-01 11:58:11,486:INFO: Epoch: 17/30, Step: 9/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078697
2023-06-01 11:58:11,559:INFO: Epoch: 17/30, Step: 10/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072032
2023-06-01 11:58:11,628:INFO: Epoch: 17/30, Step: 11/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068230
2023-06-01 11:58:11,694:INFO: Epoch: 17/30, Step: 12/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065853
2023-06-01 11:58:11,761:INFO: Epoch: 17/30, Step: 13/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067206
2023-06-01 11:58:11,830:INFO: Epoch: 17/30, Step: 14/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068609
2023-06-01 11:58:11,896:INFO: Epoch: 17/30, Step: 15/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064965
2023-06-01 11:58:11,961:INFO: Epoch: 17/30, Step: 16/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065325
2023-06-01 11:58:12,027:INFO: Epoch: 17/30, Step: 17/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064996
2023-06-01 11:58:12,110:INFO: Epoch: 17/30, Step: 18/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.082858
2023-06-01 11:58:12,175:INFO: Epoch: 17/30, Step: 19/64, Lr: 0.000890536, Loss: 0.000097, Step Loss: 0.000097, Time: 0.064714
2023-06-01 11:58:12,240:INFO: Epoch: 17/30, Step: 20/64, Lr: 0.000890536, Loss: 0.000008, Step Loss: 0.000008, Time: 0.065361
2023-06-01 11:58:12,310:INFO: Epoch: 17/30, Step: 21/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069713
2023-06-01 11:58:12,379:INFO: Epoch: 17/30, Step: 22/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068249
2023-06-01 11:58:12,445:INFO: Epoch: 17/30, Step: 23/64, Lr: 0.000890536, Loss: 0.000055, Step Loss: 0.000055, Time: 0.066025
2023-06-01 11:58:12,512:INFO: Epoch: 17/30, Step: 24/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065883
2023-06-01 11:58:12,577:INFO: Epoch: 17/30, Step: 25/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065302
2023-06-01 11:58:12,656:INFO: Epoch: 17/30, Step: 26/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078651
2023-06-01 11:58:12,722:INFO: Epoch: 17/30, Step: 27/64, Lr: 0.000890536, Loss: 0.111964, Step Loss: 0.111964, Time: 0.064908
2023-06-01 11:58:12,787:INFO: Epoch: 17/30, Step: 28/64, Lr: 0.000890536, Loss: 0.000012, Step Loss: 0.000012, Time: 0.064673
2023-06-01 11:58:12,854:INFO: Epoch: 17/30, Step: 29/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066722
2023-06-01 11:58:12,925:INFO: Epoch: 17/30, Step: 30/64, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071033
2023-06-01 11:58:13,002:INFO: Epoch: 17/30, Step: 31/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076950
2023-06-01 11:58:13,072:INFO: Epoch: 17/30, Step: 32/64, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068982
2023-06-01 11:58:13,138:INFO: Epoch: 17/30, Step: 33/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065897
2023-06-01 11:58:13,209:INFO: Epoch: 17/30, Step: 34/64, Lr: 0.000890536, Loss: 0.000003, Step Loss: 0.000003, Time: 0.070915
2023-06-01 11:58:13,278:INFO: Epoch: 17/30, Step: 35/64, Lr: 0.000890536, Loss: 0.004790, Step Loss: 0.004790, Time: 0.069104
2023-06-01 11:58:13,343:INFO: Epoch: 17/30, Step: 36/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064897
2023-06-01 11:58:13,412:INFO: Epoch: 17/30, Step: 37/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068313
2023-06-01 11:58:13,478:INFO: Epoch: 17/30, Step: 38/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065552
2023-06-01 11:58:13,548:INFO: Epoch: 17/30, Step: 39/64, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069921
2023-06-01 11:58:13,619:INFO: Epoch: 17/30, Step: 40/64, Lr: 0.000890536, Loss: 0.000052, Step Loss: 0.000052, Time: 0.070808
2023-06-01 11:58:13,687:INFO: Epoch: 17/30, Step: 41/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067099
2023-06-01 11:58:13,755:INFO: Epoch: 17/30, Step: 42/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067451
2023-06-01 11:58:13,822:INFO: Epoch: 17/30, Step: 43/64, Lr: 0.000890536, Loss: 0.000006, Step Loss: 0.000006, Time: 0.067423
2023-06-01 11:58:13,890:INFO: Epoch: 17/30, Step: 44/64, Lr: 0.000890536, Loss: 0.000099, Step Loss: 0.000099, Time: 0.067590
2023-06-01 11:58:13,961:INFO: Epoch: 17/30, Step: 45/64, Lr: 0.000890536, Loss: 0.000061, Step Loss: 0.000061, Time: 0.070457
2023-06-01 11:58:14,027:INFO: Epoch: 17/30, Step: 46/64, Lr: 0.000890536, Loss: 0.017337, Step Loss: 0.017337, Time: 0.065373
2023-06-01 11:58:14,094:INFO: Epoch: 17/30, Step: 47/64, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067260
2023-06-01 11:58:14,162:INFO: Epoch: 17/30, Step: 48/64, Lr: 0.000890536, Loss: 0.001553, Step Loss: 0.001553, Time: 0.067640
2023-06-01 11:58:14,239:INFO: Epoch: 17/30, Step: 49/64, Lr: 0.000890536, Loss: 0.148085, Step Loss: 0.148085, Time: 0.076844
2023-06-01 11:58:14,308:INFO: Epoch: 17/30, Step: 50/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068326
2023-06-01 11:58:14,382:INFO: Epoch: 17/30, Step: 51/64, Lr: 0.000890536, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073335
2023-06-01 11:58:14,447:INFO: Epoch: 17/30, Step: 52/64, Lr: 0.000890536, Loss: 0.000010, Step Loss: 0.000010, Time: 0.064760
2023-06-01 11:58:14,515:INFO: Epoch: 17/30, Step: 53/64, Lr: 0.000890536, Loss: 0.000060, Step Loss: 0.000060, Time: 0.068299
2023-06-01 11:58:14,586:INFO: Epoch: 17/30, Step: 54/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070758
2023-06-01 11:58:14,654:INFO: Epoch: 17/30, Step: 55/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067618
2023-06-01 11:58:14,722:INFO: Epoch: 17/30, Step: 56/64, Lr: 0.000890536, Loss: 0.000231, Step Loss: 0.000231, Time: 0.067573
2023-06-01 11:58:14,790:INFO: Epoch: 17/30, Step: 57/64, Lr: 0.000890536, Loss: 0.000002, Step Loss: 0.000002, Time: 0.067633
2023-06-01 11:58:14,858:INFO: Epoch: 17/30, Step: 58/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067558
2023-06-01 11:58:14,934:INFO: Epoch: 17/30, Step: 59/64, Lr: 0.000890536, Loss: 0.000699, Step Loss: 0.000699, Time: 0.075734
2023-06-01 11:58:14,999:INFO: Epoch: 17/30, Step: 60/64, Lr: 0.000890536, Loss: 0.000009, Step Loss: 0.000009, Time: 0.063966
2023-06-01 11:58:15,065:INFO: Epoch: 17/30, Step: 61/64, Lr: 0.000890536, Loss: 0.450973, Step Loss: 0.450973, Time: 0.065716
2023-06-01 11:58:15,131:INFO: Epoch: 17/30, Step: 62/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065469
2023-06-01 11:58:15,201:INFO: Epoch: 17/30, Step: 63/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070144
2023-06-01 11:58:15,270:INFO: Epoch: 17/30, Step: 64/64, Lr: 0.000890536, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068693
2023-06-01 11:58:15,434:INFO: Epoch 17/30 Finished, Train Loss: 0.012191
2023-06-01 11:58:21,905:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.16
2023-06-01 11:58:25,021:INFO: Classfication Metrics:
2023-06-01 11:58:25,021:INFO: f1 score: 0.8835 - precision score: 0.8271 - recall score: 0.9483 - accuracy score: 0.901695
2023-06-01 11:58:25,021:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15, the F1 is: 0.8898
2023-06-01 11:58:26,138:INFO: Epoch: 18/30, Step: 1/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 1.043320
2023-06-01 11:58:26,210:INFO: Epoch: 18/30, Step: 2/64, Lr: 0.000797093, Loss: 0.000005, Step Loss: 0.000005, Time: 0.071630
2023-06-01 11:58:26,287:INFO: Epoch: 18/30, Step: 3/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.077084
2023-06-01 11:58:26,351:INFO: Epoch: 18/30, Step: 4/64, Lr: 0.000797093, Loss: 0.000103, Step Loss: 0.000103, Time: 0.063975
2023-06-01 11:58:26,431:INFO: Epoch: 18/30, Step: 5/64, Lr: 0.000797093, Loss: 0.207192, Step Loss: 0.207192, Time: 0.079343
2023-06-01 11:58:26,497:INFO: Epoch: 18/30, Step: 6/64, Lr: 0.000797093, Loss: 0.000133, Step Loss: 0.000133, Time: 0.065865
2023-06-01 11:58:26,566:INFO: Epoch: 18/30, Step: 7/64, Lr: 0.000797093, Loss: 0.226226, Step Loss: 0.226226, Time: 0.068827
2023-06-01 11:58:26,630:INFO: Epoch: 18/30, Step: 8/64, Lr: 0.000797093, Loss: 0.125576, Step Loss: 0.125576, Time: 0.063783
2023-06-01 11:58:26,694:INFO: Epoch: 18/30, Step: 9/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063819
2023-06-01 11:58:26,758:INFO: Epoch: 18/30, Step: 10/64, Lr: 0.000797093, Loss: 0.000005, Step Loss: 0.000005, Time: 0.063620
2023-06-01 11:58:26,826:INFO: Epoch: 18/30, Step: 11/64, Lr: 0.000797093, Loss: 0.000279, Step Loss: 0.000279, Time: 0.067346
2023-06-01 11:58:26,890:INFO: Epoch: 18/30, Step: 12/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063671
2023-06-01 11:58:26,966:INFO: Epoch: 18/30, Step: 13/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075748
2023-06-01 11:58:27,030:INFO: Epoch: 18/30, Step: 14/64, Lr: 0.000797093, Loss: 0.004543, Step Loss: 0.004543, Time: 0.064092
2023-06-01 11:58:27,092:INFO: Epoch: 18/30, Step: 15/64, Lr: 0.000797093, Loss: 0.732054, Step Loss: 0.732054, Time: 0.061607
2023-06-01 11:58:27,155:INFO: Epoch: 18/30, Step: 16/64, Lr: 0.000797093, Loss: 0.000005, Step Loss: 0.000005, Time: 0.062701
2023-06-01 11:58:27,221:INFO: Epoch: 18/30, Step: 17/64, Lr: 0.000797093, Loss: 0.469009, Step Loss: 0.469009, Time: 0.065105
2023-06-01 11:58:27,285:INFO: Epoch: 18/30, Step: 18/64, Lr: 0.000797093, Loss: 0.047730, Step Loss: 0.047730, Time: 0.064467
2023-06-01 11:58:27,351:INFO: Epoch: 18/30, Step: 19/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065276
2023-06-01 11:58:27,415:INFO: Epoch: 18/30, Step: 20/64, Lr: 0.000797093, Loss: 0.000710, Step Loss: 0.000710, Time: 0.063451
2023-06-01 11:58:27,490:INFO: Epoch: 18/30, Step: 21/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075299
2023-06-01 11:58:27,566:INFO: Epoch: 18/30, Step: 22/64, Lr: 0.000797093, Loss: 0.000068, Step Loss: 0.000068, Time: 0.075180
2023-06-01 11:58:27,636:INFO: Epoch: 18/30, Step: 23/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070198
2023-06-01 11:58:27,703:INFO: Epoch: 18/30, Step: 24/64, Lr: 0.000797093, Loss: 0.459391, Step Loss: 0.459391, Time: 0.065904
2023-06-01 11:58:27,779:INFO: Epoch: 18/30, Step: 25/64, Lr: 0.000797093, Loss: 0.026014, Step Loss: 0.026014, Time: 0.076062
2023-06-01 11:58:27,850:INFO: Epoch: 18/30, Step: 26/64, Lr: 0.000797093, Loss: 0.108443, Step Loss: 0.108443, Time: 0.070981
2023-06-01 11:58:27,917:INFO: Epoch: 18/30, Step: 27/64, Lr: 0.000797093, Loss: 0.584839, Step Loss: 0.584839, Time: 0.066479
2023-06-01 11:58:27,991:INFO: Epoch: 18/30, Step: 28/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073092
2023-06-01 11:58:28,054:INFO: Epoch: 18/30, Step: 29/64, Lr: 0.000797093, Loss: 0.003242, Step Loss: 0.003242, Time: 0.063127
2023-06-01 11:58:28,121:INFO: Epoch: 18/30, Step: 30/64, Lr: 0.000797093, Loss: 0.000244, Step Loss: 0.000244, Time: 0.066946
2023-06-01 11:58:28,188:INFO: Epoch: 18/30, Step: 31/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066860
2023-06-01 11:58:28,261:INFO: Epoch: 18/30, Step: 32/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072601
2023-06-01 11:58:28,331:INFO: Epoch: 18/30, Step: 33/64, Lr: 0.000797093, Loss: 0.216001, Step Loss: 0.216001, Time: 0.069118
2023-06-01 11:58:28,407:INFO: Epoch: 18/30, Step: 34/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075846
2023-06-01 11:58:28,470:INFO: Epoch: 18/30, Step: 35/64, Lr: 0.000797093, Loss: 0.001899, Step Loss: 0.001899, Time: 0.062845
2023-06-01 11:58:28,534:INFO: Epoch: 18/30, Step: 36/64, Lr: 0.000797093, Loss: 0.000570, Step Loss: 0.000570, Time: 0.064073
2023-06-01 11:58:28,606:INFO: Epoch: 18/30, Step: 37/64, Lr: 0.000797093, Loss: 1.197361, Step Loss: 1.197361, Time: 0.071052
2023-06-01 11:58:28,671:INFO: Epoch: 18/30, Step: 38/64, Lr: 0.000797093, Loss: 0.009042, Step Loss: 0.009042, Time: 0.065423
2023-06-01 11:58:28,735:INFO: Epoch: 18/30, Step: 39/64, Lr: 0.000797093, Loss: 0.000028, Step Loss: 0.000028, Time: 0.062992
2023-06-01 11:58:28,807:INFO: Epoch: 18/30, Step: 40/64, Lr: 0.000797093, Loss: 0.122795, Step Loss: 0.122795, Time: 0.072311
2023-06-01 11:58:28,878:INFO: Epoch: 18/30, Step: 41/64, Lr: 0.000797093, Loss: 0.047932, Step Loss: 0.047932, Time: 0.070308
2023-06-01 11:58:28,947:INFO: Epoch: 18/30, Step: 42/64, Lr: 0.000797093, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068863
2023-06-01 11:58:29,010:INFO: Epoch: 18/30, Step: 43/64, Lr: 0.000797093, Loss: 0.000435, Step Loss: 0.000435, Time: 0.063149
2023-06-01 11:58:29,075:INFO: Epoch: 18/30, Step: 44/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064249
2023-06-01 11:58:29,142:INFO: Epoch: 18/30, Step: 45/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066566
2023-06-01 11:58:29,208:INFO: Epoch: 18/30, Step: 46/64, Lr: 0.000797093, Loss: 0.000002, Step Loss: 0.000002, Time: 0.065714
2023-06-01 11:58:29,279:INFO: Epoch: 18/30, Step: 47/64, Lr: 0.000797093, Loss: 0.000171, Step Loss: 0.000171, Time: 0.070763
2023-06-01 11:58:29,354:INFO: Epoch: 18/30, Step: 48/64, Lr: 0.000797093, Loss: 0.000002, Step Loss: 0.000002, Time: 0.074970
2023-06-01 11:58:29,423:INFO: Epoch: 18/30, Step: 49/64, Lr: 0.000797093, Loss: 0.000162, Step Loss: 0.000162, Time: 0.068438
2023-06-01 11:58:29,494:INFO: Epoch: 18/30, Step: 50/64, Lr: 0.000797093, Loss: 0.000066, Step Loss: 0.000066, Time: 0.070560
2023-06-01 11:58:29,566:INFO: Epoch: 18/30, Step: 51/64, Lr: 0.000797093, Loss: 0.547708, Step Loss: 0.547708, Time: 0.072216
2023-06-01 11:58:29,643:INFO: Epoch: 18/30, Step: 52/64, Lr: 0.000797093, Loss: 0.194070, Step Loss: 0.194070, Time: 0.076586
2023-06-01 11:58:29,706:INFO: Epoch: 18/30, Step: 53/64, Lr: 0.000797093, Loss: 0.096084, Step Loss: 0.096084, Time: 0.062841
2023-06-01 11:58:29,778:INFO: Epoch: 18/30, Step: 54/64, Lr: 0.000797093, Loss: 0.275867, Step Loss: 0.275867, Time: 0.071362
2023-06-01 11:58:29,850:INFO: Epoch: 18/30, Step: 55/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071640
2023-06-01 11:58:29,922:INFO: Epoch: 18/30, Step: 56/64, Lr: 0.000797093, Loss: 0.172623, Step Loss: 0.172623, Time: 0.071861
2023-06-01 11:58:29,984:INFO: Epoch: 18/30, Step: 57/64, Lr: 0.000797093, Loss: 0.000000, Step Loss: 0.000000, Time: 0.062066
2023-06-01 11:58:30,050:INFO: Epoch: 18/30, Step: 58/64, Lr: 0.000797093, Loss: 0.013430, Step Loss: 0.013430, Time: 0.065767
2023-06-01 11:58:30,122:INFO: Epoch: 18/30, Step: 59/64, Lr: 0.000797093, Loss: 0.188652, Step Loss: 0.188652, Time: 0.071291
2023-06-01 11:58:30,194:INFO: Epoch: 18/30, Step: 60/64, Lr: 0.000797093, Loss: 0.000156, Step Loss: 0.000156, Time: 0.071868
2023-06-01 11:58:30,262:INFO: Epoch: 18/30, Step: 61/64, Lr: 0.000797093, Loss: 0.815427, Step Loss: 0.815427, Time: 0.067155
2023-06-01 11:58:30,332:INFO: Epoch: 18/30, Step: 62/64, Lr: 0.000797093, Loss: 0.000077, Step Loss: 0.000077, Time: 0.069574
2023-06-01 11:58:30,405:INFO: Epoch: 18/30, Step: 63/64, Lr: 0.000797093, Loss: 0.000316, Step Loss: 0.000316, Time: 0.073323
2023-06-01 11:58:30,475:INFO: Epoch: 18/30, Step: 64/64, Lr: 0.000797093, Loss: 0.000003, Step Loss: 0.000003, Time: 0.069460
2023-06-01 11:58:30,630:INFO: Epoch 18/30 Finished, Train Loss: 0.107761
2023-06-01 11:58:42,182:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.17
2023-06-01 11:58:45,318:INFO: Classfication Metrics:
2023-06-01 11:58:45,318:INFO: f1 score: 0.8676 - precision score: 0.9223 - recall score: 0.8190 - accuracy score: 0.901695
2023-06-01 11:58:45,318:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15, the F1 is: 0.8898
2023-06-01 11:58:46,322:INFO: Epoch: 19/30, Step: 1/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.979743
2023-06-01 11:58:46,395:INFO: Epoch: 19/30, Step: 2/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072555
2023-06-01 11:58:46,471:INFO: Epoch: 19/30, Step: 3/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075201
2023-06-01 11:58:46,534:INFO: Epoch: 19/30, Step: 4/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063013
2023-06-01 11:58:46,604:INFO: Epoch: 19/30, Step: 5/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069342
2023-06-01 11:58:46,685:INFO: Epoch: 19/30, Step: 6/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.081351
2023-06-01 11:58:46,750:INFO: Epoch: 19/30, Step: 7/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064127
2023-06-01 11:58:46,814:INFO: Epoch: 19/30, Step: 8/64, Lr: 0.000702907, Loss: 0.000456, Step Loss: 0.000456, Time: 0.063692
2023-06-01 11:58:46,883:INFO: Epoch: 19/30, Step: 9/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068756
2023-06-01 11:58:46,955:INFO: Epoch: 19/30, Step: 10/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071854
2023-06-01 11:58:47,035:INFO: Epoch: 19/30, Step: 11/64, Lr: 0.000702907, Loss: 0.000016, Step Loss: 0.000016, Time: 0.079277
2023-06-01 11:58:47,103:INFO: Epoch: 19/30, Step: 12/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067657
2023-06-01 11:58:47,174:INFO: Epoch: 19/30, Step: 13/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070569
2023-06-01 11:58:47,247:INFO: Epoch: 19/30, Step: 14/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072203
2023-06-01 11:58:47,317:INFO: Epoch: 19/30, Step: 15/64, Lr: 0.000702907, Loss: 0.000458, Step Loss: 0.000458, Time: 0.070065
2023-06-01 11:58:47,387:INFO: Epoch: 19/30, Step: 16/64, Lr: 0.000702907, Loss: 0.888302, Step Loss: 0.888302, Time: 0.069133
2023-06-01 11:58:47,456:INFO: Epoch: 19/30, Step: 17/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068626
2023-06-01 11:58:47,524:INFO: Epoch: 19/30, Step: 18/64, Lr: 0.000702907, Loss: 0.000003, Step Loss: 0.000003, Time: 0.068177
2023-06-01 11:58:47,600:INFO: Epoch: 19/30, Step: 19/64, Lr: 0.000702907, Loss: 0.000512, Step Loss: 0.000512, Time: 0.075779
2023-06-01 11:58:47,670:INFO: Epoch: 19/30, Step: 20/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069454
2023-06-01 11:58:47,739:INFO: Epoch: 19/30, Step: 21/64, Lr: 0.000702907, Loss: 0.000013, Step Loss: 0.000013, Time: 0.068481
2023-06-01 11:58:47,814:INFO: Epoch: 19/30, Step: 22/64, Lr: 0.000702907, Loss: 0.000003, Step Loss: 0.000003, Time: 0.074615
2023-06-01 11:58:47,885:INFO: Epoch: 19/30, Step: 23/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070237
2023-06-01 11:58:47,953:INFO: Epoch: 19/30, Step: 24/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067992
2023-06-01 11:58:48,025:INFO: Epoch: 19/30, Step: 25/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071007
2023-06-01 11:58:48,099:INFO: Epoch: 19/30, Step: 26/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073440
2023-06-01 11:58:48,169:INFO: Epoch: 19/30, Step: 27/64, Lr: 0.000702907, Loss: 0.000102, Step Loss: 0.000102, Time: 0.069583
2023-06-01 11:58:48,238:INFO: Epoch: 19/30, Step: 28/64, Lr: 0.000702907, Loss: 0.173031, Step Loss: 0.173031, Time: 0.069283
2023-06-01 11:58:48,307:INFO: Epoch: 19/30, Step: 29/64, Lr: 0.000702907, Loss: 0.000002, Step Loss: 0.000002, Time: 0.067740
2023-06-01 11:58:48,371:INFO: Epoch: 19/30, Step: 30/64, Lr: 0.000702907, Loss: 0.013411, Step Loss: 0.013411, Time: 0.063732
2023-06-01 11:58:48,443:INFO: Epoch: 19/30, Step: 31/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072329
2023-06-01 11:58:48,523:INFO: Epoch: 19/30, Step: 32/64, Lr: 0.000702907, Loss: 0.000066, Step Loss: 0.000066, Time: 0.079496
2023-06-01 11:58:48,594:INFO: Epoch: 19/30, Step: 33/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070511
2023-06-01 11:58:48,669:INFO: Epoch: 19/30, Step: 34/64, Lr: 0.000702907, Loss: 0.000008, Step Loss: 0.000008, Time: 0.074538
2023-06-01 11:58:48,734:INFO: Epoch: 19/30, Step: 35/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064537
2023-06-01 11:58:48,803:INFO: Epoch: 19/30, Step: 36/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068884
2023-06-01 11:58:48,869:INFO: Epoch: 19/30, Step: 37/64, Lr: 0.000702907, Loss: 0.000006, Step Loss: 0.000006, Time: 0.064917
2023-06-01 11:58:48,942:INFO: Epoch: 19/30, Step: 38/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073225
2023-06-01 11:58:49,015:INFO: Epoch: 19/30, Step: 39/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071936
2023-06-01 11:58:49,090:INFO: Epoch: 19/30, Step: 40/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074929
2023-06-01 11:58:49,163:INFO: Epoch: 19/30, Step: 41/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072137
2023-06-01 11:58:49,235:INFO: Epoch: 19/30, Step: 42/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071962
2023-06-01 11:58:49,306:INFO: Epoch: 19/30, Step: 43/64, Lr: 0.000702907, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070517
2023-06-01 11:58:49,379:INFO: Epoch: 19/30, Step: 44/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072387
2023-06-01 11:58:49,451:INFO: Epoch: 19/30, Step: 45/64, Lr: 0.000702907, Loss: 0.508888, Step Loss: 0.508888, Time: 0.071722
2023-06-01 11:58:49,524:INFO: Epoch: 19/30, Step: 46/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072945
2023-06-01 11:58:49,608:INFO: Epoch: 19/30, Step: 47/64, Lr: 0.000702907, Loss: 0.000003, Step Loss: 0.000003, Time: 0.082843
2023-06-01 11:58:49,680:INFO: Epoch: 19/30, Step: 48/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072117
2023-06-01 11:58:49,751:INFO: Epoch: 19/30, Step: 49/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070100
2023-06-01 11:58:49,822:INFO: Epoch: 19/30, Step: 50/64, Lr: 0.000702907, Loss: 0.000021, Step Loss: 0.000021, Time: 0.071421
2023-06-01 11:58:49,891:INFO: Epoch: 19/30, Step: 51/64, Lr: 0.000702907, Loss: 0.000011, Step Loss: 0.000011, Time: 0.068638
2023-06-01 11:58:49,978:INFO: Epoch: 19/30, Step: 52/64, Lr: 0.000702907, Loss: 0.000020, Step Loss: 0.000020, Time: 0.085688
2023-06-01 11:58:50,054:INFO: Epoch: 19/30, Step: 53/64, Lr: 0.000702907, Loss: 0.001153, Step Loss: 0.001153, Time: 0.075785
2023-06-01 11:58:50,126:INFO: Epoch: 19/30, Step: 54/64, Lr: 0.000702907, Loss: 0.000080, Step Loss: 0.000080, Time: 0.071366
2023-06-01 11:58:50,199:INFO: Epoch: 19/30, Step: 55/64, Lr: 0.000702907, Loss: 0.000002, Step Loss: 0.000002, Time: 0.072204
2023-06-01 11:58:50,272:INFO: Epoch: 19/30, Step: 56/64, Lr: 0.000702907, Loss: 0.000714, Step Loss: 0.000714, Time: 0.073154
2023-06-01 11:58:50,344:INFO: Epoch: 19/30, Step: 57/64, Lr: 0.000702907, Loss: 0.001557, Step Loss: 0.001557, Time: 0.071181
2023-06-01 11:58:50,427:INFO: Epoch: 19/30, Step: 58/64, Lr: 0.000702907, Loss: 0.001413, Step Loss: 0.001413, Time: 0.083029
2023-06-01 11:58:50,502:INFO: Epoch: 19/30, Step: 59/64, Lr: 0.000702907, Loss: 0.000007, Step Loss: 0.000007, Time: 0.074438
2023-06-01 11:58:50,570:INFO: Epoch: 19/30, Step: 60/64, Lr: 0.000702907, Loss: 0.000018, Step Loss: 0.000018, Time: 0.067991
2023-06-01 11:58:50,643:INFO: Epoch: 19/30, Step: 61/64, Lr: 0.000702907, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072201
2023-06-01 11:58:50,720:INFO: Epoch: 19/30, Step: 62/64, Lr: 0.000702907, Loss: 0.000007, Step Loss: 0.000007, Time: 0.076202
2023-06-01 11:58:50,801:INFO: Epoch: 19/30, Step: 63/64, Lr: 0.000702907, Loss: 0.000068, Step Loss: 0.000068, Time: 0.080615
2023-06-01 11:58:50,875:INFO: Epoch: 19/30, Step: 64/64, Lr: 0.000702907, Loss: 0.010878, Step Loss: 0.010878, Time: 0.073507
2023-06-01 11:58:51,033:INFO: Epoch 19/30 Finished, Train Loss: 0.025019
2023-06-01 11:58:57,759:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.18
2023-06-01 11:59:00,912:INFO: Classfication Metrics:
2023-06-01 11:59:00,912:INFO: f1 score: 0.8571 - precision score: 0.9574 - recall score: 0.7759 - accuracy score: 0.898305
2023-06-01 11:59:00,913:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.15, the F1 is: 0.8898
2023-06-01 11:59:01,854:INFO: Epoch: 20/30, Step: 1/64, Lr: 0.000609464, Loss: 0.000027, Step Loss: 0.000027, Time: 0.934043
2023-06-01 11:59:02,071:INFO: Epoch: 20/30, Step: 2/64, Lr: 0.000609464, Loss: 0.002186, Step Loss: 0.002186, Time: 0.215716
2023-06-01 11:59:02,141:INFO: Epoch: 20/30, Step: 3/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070155
2023-06-01 11:59:02,207:INFO: Epoch: 20/30, Step: 4/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065825
2023-06-01 11:59:02,274:INFO: Epoch: 20/30, Step: 5/64, Lr: 0.000609464, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066703
2023-06-01 11:59:02,339:INFO: Epoch: 20/30, Step: 6/64, Lr: 0.000609464, Loss: 0.000303, Step Loss: 0.000303, Time: 0.064669
2023-06-01 11:59:02,411:INFO: Epoch: 20/30, Step: 7/64, Lr: 0.000609464, Loss: 0.001416, Step Loss: 0.001416, Time: 0.071712
2023-06-01 11:59:02,480:INFO: Epoch: 20/30, Step: 8/64, Lr: 0.000609464, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068999
2023-06-01 11:59:02,546:INFO: Epoch: 20/30, Step: 9/64, Lr: 0.000609464, Loss: 0.000766, Step Loss: 0.000766, Time: 0.065950
2023-06-01 11:59:02,623:INFO: Epoch: 20/30, Step: 10/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076515
2023-06-01 11:59:02,694:INFO: Epoch: 20/30, Step: 11/64, Lr: 0.000609464, Loss: 0.000239, Step Loss: 0.000239, Time: 0.070906
2023-06-01 11:59:02,762:INFO: Epoch: 20/30, Step: 12/64, Lr: 0.000609464, Loss: 0.003873, Step Loss: 0.003873, Time: 0.067307
2023-06-01 11:59:02,828:INFO: Epoch: 20/30, Step: 13/64, Lr: 0.000609464, Loss: 0.000096, Step Loss: 0.000096, Time: 0.065348
2023-06-01 11:59:02,894:INFO: Epoch: 20/30, Step: 14/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066462
2023-06-01 11:59:02,964:INFO: Epoch: 20/30, Step: 15/64, Lr: 0.000609464, Loss: 0.002477, Step Loss: 0.002477, Time: 0.069152
2023-06-01 11:59:03,035:INFO: Epoch: 20/30, Step: 16/64, Lr: 0.000609464, Loss: 0.003111, Step Loss: 0.003111, Time: 0.070739
2023-06-01 11:59:03,103:INFO: Epoch: 20/30, Step: 17/64, Lr: 0.000609464, Loss: 0.000197, Step Loss: 0.000197, Time: 0.067607
2023-06-01 11:59:03,174:INFO: Epoch: 20/30, Step: 18/64, Lr: 0.000609464, Loss: 0.000005, Step Loss: 0.000005, Time: 0.070568
2023-06-01 11:59:03,242:INFO: Epoch: 20/30, Step: 19/64, Lr: 0.000609464, Loss: 0.000003, Step Loss: 0.000003, Time: 0.067989
2023-06-01 11:59:03,308:INFO: Epoch: 20/30, Step: 20/64, Lr: 0.000609464, Loss: 0.000243, Step Loss: 0.000243, Time: 0.065256
2023-06-01 11:59:03,379:INFO: Epoch: 20/30, Step: 21/64, Lr: 0.000609464, Loss: 0.000055, Step Loss: 0.000055, Time: 0.071154
2023-06-01 11:59:03,450:INFO: Epoch: 20/30, Step: 22/64, Lr: 0.000609464, Loss: 0.000013, Step Loss: 0.000013, Time: 0.071006
2023-06-01 11:59:03,515:INFO: Epoch: 20/30, Step: 23/64, Lr: 0.000609464, Loss: 0.000068, Step Loss: 0.000068, Time: 0.064682
2023-06-01 11:59:03,586:INFO: Epoch: 20/30, Step: 24/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070533
2023-06-01 11:59:03,651:INFO: Epoch: 20/30, Step: 25/64, Lr: 0.000609464, Loss: 0.000301, Step Loss: 0.000301, Time: 0.065020
2023-06-01 11:59:03,727:INFO: Epoch: 20/30, Step: 26/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075744
2023-06-01 11:59:03,794:INFO: Epoch: 20/30, Step: 27/64, Lr: 0.000609464, Loss: 0.000012, Step Loss: 0.000012, Time: 0.066431
2023-06-01 11:59:03,862:INFO: Epoch: 20/30, Step: 28/64, Lr: 0.000609464, Loss: 0.000360, Step Loss: 0.000360, Time: 0.067596
2023-06-01 11:59:03,928:INFO: Epoch: 20/30, Step: 29/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065085
2023-06-01 11:59:03,998:INFO: Epoch: 20/30, Step: 30/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069859
2023-06-01 11:59:04,068:INFO: Epoch: 20/30, Step: 31/64, Lr: 0.000609464, Loss: 0.006856, Step Loss: 0.006856, Time: 0.069542
2023-06-01 11:59:04,138:INFO: Epoch: 20/30, Step: 32/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069931
2023-06-01 11:59:04,218:INFO: Epoch: 20/30, Step: 33/64, Lr: 0.000609464, Loss: 0.000006, Step Loss: 0.000006, Time: 0.080032
2023-06-01 11:59:04,287:INFO: Epoch: 20/30, Step: 34/64, Lr: 0.000609464, Loss: 0.059265, Step Loss: 0.059265, Time: 0.067990
2023-06-01 11:59:04,357:INFO: Epoch: 20/30, Step: 35/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070479
2023-06-01 11:59:04,424:INFO: Epoch: 20/30, Step: 36/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065786
2023-06-01 11:59:04,490:INFO: Epoch: 20/30, Step: 37/64, Lr: 0.000609464, Loss: 0.000039, Step Loss: 0.000039, Time: 0.066251
2023-06-01 11:59:04,563:INFO: Epoch: 20/30, Step: 38/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073031
2023-06-01 11:59:04,631:INFO: Epoch: 20/30, Step: 39/64, Lr: 0.000609464, Loss: 0.021050, Step Loss: 0.021050, Time: 0.067468
2023-06-01 11:59:04,699:INFO: Epoch: 20/30, Step: 40/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067803
2023-06-01 11:59:04,769:INFO: Epoch: 20/30, Step: 41/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069686
2023-06-01 11:59:04,838:INFO: Epoch: 20/30, Step: 42/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068499
2023-06-01 11:59:04,911:INFO: Epoch: 20/30, Step: 43/64, Lr: 0.000609464, Loss: 0.011193, Step Loss: 0.011193, Time: 0.073164
2023-06-01 11:59:04,989:INFO: Epoch: 20/30, Step: 44/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.077232
2023-06-01 11:59:05,057:INFO: Epoch: 20/30, Step: 45/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068019
2023-06-01 11:59:05,125:INFO: Epoch: 20/30, Step: 46/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067704
2023-06-01 11:59:05,195:INFO: Epoch: 20/30, Step: 47/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069177
2023-06-01 11:59:05,264:INFO: Epoch: 20/30, Step: 48/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068809
2023-06-01 11:59:05,334:INFO: Epoch: 20/30, Step: 49/64, Lr: 0.000609464, Loss: 0.001080, Step Loss: 0.001080, Time: 0.070292
2023-06-01 11:59:05,407:INFO: Epoch: 20/30, Step: 50/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072601
2023-06-01 11:59:05,478:INFO: Epoch: 20/30, Step: 51/64, Lr: 0.000609464, Loss: 0.000005, Step Loss: 0.000005, Time: 0.070139
2023-06-01 11:59:05,551:INFO: Epoch: 20/30, Step: 52/64, Lr: 0.000609464, Loss: 0.000002, Step Loss: 0.000002, Time: 0.073493
2023-06-01 11:59:05,618:INFO: Epoch: 20/30, Step: 53/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066535
2023-06-01 11:59:05,686:INFO: Epoch: 20/30, Step: 54/64, Lr: 0.000609464, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067100
2023-06-01 11:59:05,754:INFO: Epoch: 20/30, Step: 55/64, Lr: 0.000609464, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068222
2023-06-01 11:59:05,826:INFO: Epoch: 20/30, Step: 56/64, Lr: 0.000609464, Loss: 0.000029, Step Loss: 0.000029, Time: 0.071451
2023-06-01 11:59:05,895:INFO: Epoch: 20/30, Step: 57/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068322
2023-06-01 11:59:05,963:INFO: Epoch: 20/30, Step: 58/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067451
2023-06-01 11:59:06,029:INFO: Epoch: 20/30, Step: 59/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066054
2023-06-01 11:59:06,112:INFO: Epoch: 20/30, Step: 60/64, Lr: 0.000609464, Loss: 0.012144, Step Loss: 0.012144, Time: 0.082437
2023-06-01 11:59:06,177:INFO: Epoch: 20/30, Step: 61/64, Lr: 0.000609464, Loss: 0.000015, Step Loss: 0.000015, Time: 0.065361
2023-06-01 11:59:06,247:INFO: Epoch: 20/30, Step: 62/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069388
2023-06-01 11:59:06,318:INFO: Epoch: 20/30, Step: 63/64, Lr: 0.000609464, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071002
2023-06-01 11:59:06,386:INFO: Epoch: 20/30, Step: 64/64, Lr: 0.000609464, Loss: 0.000157, Step Loss: 0.000157, Time: 0.067666
2023-06-01 11:59:06,543:INFO: Epoch 20/30 Finished, Train Loss: 0.001994
2023-06-01 11:59:13,732:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19
2023-06-01 11:59:16,869:INFO: Classfication Metrics:
2023-06-01 11:59:16,870:INFO: f1 score: 0.9000 - precision score: 0.8710 - recall score: 0.9310 - accuracy score: 0.918644
2023-06-01 11:59:16,870:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 11:59:17,827:INFO: Epoch: 21/30, Step: 1/64, Lr: 0.000518237, Loss: 0.000176, Step Loss: 0.000176, Time: 0.948256
2023-06-01 11:59:17,898:INFO: Epoch: 21/30, Step: 2/64, Lr: 0.000518237, Loss: 0.000005, Step Loss: 0.000005, Time: 0.071339
2023-06-01 11:59:17,975:INFO: Epoch: 21/30, Step: 3/64, Lr: 0.000518237, Loss: 0.005032, Step Loss: 0.005032, Time: 0.075882
2023-06-01 11:59:18,046:INFO: Epoch: 21/30, Step: 4/64, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071561
2023-06-01 11:59:18,111:INFO: Epoch: 21/30, Step: 5/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064596
2023-06-01 11:59:18,176:INFO: Epoch: 21/30, Step: 6/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064233
2023-06-01 11:59:18,242:INFO: Epoch: 21/30, Step: 7/64, Lr: 0.000518237, Loss: 0.000574, Step Loss: 0.000574, Time: 0.065824
2023-06-01 11:59:18,305:INFO: Epoch: 21/30, Step: 8/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.062858
2023-06-01 11:59:18,373:INFO: Epoch: 21/30, Step: 9/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068216
2023-06-01 11:59:18,443:INFO: Epoch: 21/30, Step: 10/64, Lr: 0.000518237, Loss: 0.000016, Step Loss: 0.000016, Time: 0.069497
2023-06-01 11:59:18,510:INFO: Epoch: 21/30, Step: 11/64, Lr: 0.000518237, Loss: 0.035751, Step Loss: 0.035751, Time: 0.067070
2023-06-01 11:59:18,578:INFO: Epoch: 21/30, Step: 12/64, Lr: 0.000518237, Loss: 0.000016, Step Loss: 0.000016, Time: 0.066896
2023-06-01 11:59:18,643:INFO: Epoch: 21/30, Step: 13/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065083
2023-06-01 11:59:18,719:INFO: Epoch: 21/30, Step: 14/64, Lr: 0.000518237, Loss: 0.000011, Step Loss: 0.000011, Time: 0.076041
2023-06-01 11:59:18,786:INFO: Epoch: 21/30, Step: 15/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066399
2023-06-01 11:59:18,851:INFO: Epoch: 21/30, Step: 16/64, Lr: 0.000518237, Loss: 0.000938, Step Loss: 0.000938, Time: 0.064837
2023-06-01 11:59:18,920:INFO: Epoch: 21/30, Step: 17/64, Lr: 0.000518237, Loss: 0.000004, Step Loss: 0.000004, Time: 0.068454
2023-06-01 11:59:18,998:INFO: Epoch: 21/30, Step: 18/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078553
2023-06-01 11:59:19,065:INFO: Epoch: 21/30, Step: 19/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066638
2023-06-01 11:59:19,131:INFO: Epoch: 21/30, Step: 20/64, Lr: 0.000518237, Loss: 0.000127, Step Loss: 0.000127, Time: 0.065144
2023-06-01 11:59:19,195:INFO: Epoch: 21/30, Step: 21/64, Lr: 0.000518237, Loss: 0.000132, Step Loss: 0.000132, Time: 0.064530
2023-06-01 11:59:19,267:INFO: Epoch: 21/30, Step: 22/64, Lr: 0.000518237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.071488
2023-06-01 11:59:19,336:INFO: Epoch: 21/30, Step: 23/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068626
2023-06-01 11:59:19,402:INFO: Epoch: 21/30, Step: 24/64, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065751
2023-06-01 11:59:19,467:INFO: Epoch: 21/30, Step: 25/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064872
2023-06-01 11:59:19,539:INFO: Epoch: 21/30, Step: 26/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071313
2023-06-01 11:59:19,605:INFO: Epoch: 21/30, Step: 27/64, Lr: 0.000518237, Loss: 0.000016, Step Loss: 0.000016, Time: 0.066556
2023-06-01 11:59:19,673:INFO: Epoch: 21/30, Step: 28/64, Lr: 0.000518237, Loss: 0.000037, Step Loss: 0.000037, Time: 0.067095
2023-06-01 11:59:19,738:INFO: Epoch: 21/30, Step: 29/64, Lr: 0.000518237, Loss: 0.000032, Step Loss: 0.000032, Time: 0.065387
2023-06-01 11:59:19,812:INFO: Epoch: 21/30, Step: 30/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073270
2023-06-01 11:59:19,876:INFO: Epoch: 21/30, Step: 31/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063413
2023-06-01 11:59:19,944:INFO: Epoch: 21/30, Step: 32/64, Lr: 0.000518237, Loss: 0.000037, Step Loss: 0.000037, Time: 0.067838
2023-06-01 11:59:20,011:INFO: Epoch: 21/30, Step: 33/64, Lr: 0.000518237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.066775
2023-06-01 11:59:20,079:INFO: Epoch: 21/30, Step: 34/64, Lr: 0.000518237, Loss: 0.000310, Step Loss: 0.000310, Time: 0.068052
2023-06-01 11:59:20,144:INFO: Epoch: 21/30, Step: 35/64, Lr: 0.000518237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.064357
2023-06-01 11:59:20,211:INFO: Epoch: 21/30, Step: 36/64, Lr: 0.000518237, Loss: 0.000399, Step Loss: 0.000399, Time: 0.067401
2023-06-01 11:59:20,279:INFO: Epoch: 21/30, Step: 37/64, Lr: 0.000518237, Loss: 0.000005, Step Loss: 0.000005, Time: 0.067346
2023-06-01 11:59:20,346:INFO: Epoch: 21/30, Step: 38/64, Lr: 0.000518237, Loss: 0.000006, Step Loss: 0.000006, Time: 0.067259
2023-06-01 11:59:20,415:INFO: Epoch: 21/30, Step: 39/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068493
2023-06-01 11:59:20,482:INFO: Epoch: 21/30, Step: 40/64, Lr: 0.000518237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.066904
2023-06-01 11:59:20,546:INFO: Epoch: 21/30, Step: 41/64, Lr: 0.000518237, Loss: 0.000401, Step Loss: 0.000401, Time: 0.063649
2023-06-01 11:59:20,607:INFO: Epoch: 21/30, Step: 42/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.060146
2023-06-01 11:59:20,668:INFO: Epoch: 21/30, Step: 43/64, Lr: 0.000518237, Loss: 0.000030, Step Loss: 0.000030, Time: 0.061433
2023-06-01 11:59:20,732:INFO: Epoch: 21/30, Step: 44/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063232
2023-06-01 11:59:20,792:INFO: Epoch: 21/30, Step: 45/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.059902
2023-06-01 11:59:20,855:INFO: Epoch: 21/30, Step: 46/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063012
2023-06-01 11:59:20,917:INFO: Epoch: 21/30, Step: 47/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.061435
2023-06-01 11:59:20,982:INFO: Epoch: 21/30, Step: 48/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064797
2023-06-01 11:59:21,042:INFO: Epoch: 21/30, Step: 49/64, Lr: 0.000518237, Loss: 0.002537, Step Loss: 0.002537, Time: 0.059687
2023-06-01 11:59:21,102:INFO: Epoch: 21/30, Step: 50/64, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.059896
2023-06-01 11:59:21,171:INFO: Epoch: 21/30, Step: 51/64, Lr: 0.000518237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068224
2023-06-01 11:59:21,239:INFO: Epoch: 21/30, Step: 52/64, Lr: 0.000518237, Loss: 0.000028, Step Loss: 0.000028, Time: 0.067861
2023-06-01 11:59:21,319:INFO: Epoch: 21/30, Step: 53/64, Lr: 0.000518237, Loss: 0.000026, Step Loss: 0.000026, Time: 0.079570
2023-06-01 11:59:21,388:INFO: Epoch: 21/30, Step: 54/64, Lr: 0.000518237, Loss: 0.000038, Step Loss: 0.000038, Time: 0.069165
2023-06-01 11:59:21,454:INFO: Epoch: 21/30, Step: 55/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065972
2023-06-01 11:59:21,527:INFO: Epoch: 21/30, Step: 56/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072368
2023-06-01 11:59:21,599:INFO: Epoch: 21/30, Step: 57/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071575
2023-06-01 11:59:21,666:INFO: Epoch: 21/30, Step: 58/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066747
2023-06-01 11:59:21,734:INFO: Epoch: 21/30, Step: 59/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067717
2023-06-01 11:59:21,803:INFO: Epoch: 21/30, Step: 60/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069035
2023-06-01 11:59:21,876:INFO: Epoch: 21/30, Step: 61/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072173
2023-06-01 11:59:21,944:INFO: Epoch: 21/30, Step: 62/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067640
2023-06-01 11:59:22,014:INFO: Epoch: 21/30, Step: 63/64, Lr: 0.000518237, Loss: 0.000059, Step Loss: 0.000059, Time: 0.069659
2023-06-01 11:59:22,082:INFO: Epoch: 21/30, Step: 64/64, Lr: 0.000518237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068376
2023-06-01 11:59:22,238:INFO: Epoch 21/30 Finished, Train Loss: 0.000731
2023-06-01 11:59:33,280:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.20
2023-06-01 11:59:36,409:INFO: Classfication Metrics:
2023-06-01 11:59:36,409:INFO: f1 score: 0.8850 - precision score: 0.9091 - recall score: 0.8621 - accuracy score: 0.911864
2023-06-01 11:59:36,409:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 11:59:37,540:INFO: Epoch: 22/30, Step: 1/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 1.123235
2023-06-01 11:59:37,612:INFO: Epoch: 22/30, Step: 2/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070641
2023-06-01 11:59:37,678:INFO: Epoch: 22/30, Step: 3/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066199
2023-06-01 11:59:37,745:INFO: Epoch: 22/30, Step: 4/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067159
2023-06-01 11:59:37,814:INFO: Epoch: 22/30, Step: 5/64, Lr: 0.000430666, Loss: 0.000316, Step Loss: 0.000316, Time: 0.068756
2023-06-01 11:59:37,879:INFO: Epoch: 22/30, Step: 6/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064627
2023-06-01 11:59:37,943:INFO: Epoch: 22/30, Step: 7/64, Lr: 0.000430666, Loss: 0.000032, Step Loss: 0.000032, Time: 0.063812
2023-06-01 11:59:38,007:INFO: Epoch: 22/30, Step: 8/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063603
2023-06-01 11:59:38,079:INFO: Epoch: 22/30, Step: 9/64, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071665
2023-06-01 11:59:38,143:INFO: Epoch: 22/30, Step: 10/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064053
2023-06-01 11:59:38,215:INFO: Epoch: 22/30, Step: 11/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070683
2023-06-01 11:59:38,284:INFO: Epoch: 22/30, Step: 12/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068810
2023-06-01 11:59:38,353:INFO: Epoch: 22/30, Step: 13/64, Lr: 0.000430666, Loss: 0.000050, Step Loss: 0.000050, Time: 0.069080
2023-06-01 11:59:38,422:INFO: Epoch: 22/30, Step: 14/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068323
2023-06-01 11:59:38,486:INFO: Epoch: 22/30, Step: 15/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063370
2023-06-01 11:59:38,552:INFO: Epoch: 22/30, Step: 16/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065438
2023-06-01 11:59:38,619:INFO: Epoch: 22/30, Step: 17/64, Lr: 0.000430666, Loss: 0.000023, Step Loss: 0.000023, Time: 0.067648
2023-06-01 11:59:38,687:INFO: Epoch: 22/30, Step: 18/64, Lr: 0.000430666, Loss: 0.000002, Step Loss: 0.000002, Time: 0.067703
2023-06-01 11:59:38,761:INFO: Epoch: 22/30, Step: 19/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073181
2023-06-01 11:59:38,827:INFO: Epoch: 22/30, Step: 20/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066082
2023-06-01 11:59:38,896:INFO: Epoch: 22/30, Step: 21/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068096
2023-06-01 11:59:38,963:INFO: Epoch: 22/30, Step: 22/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066695
2023-06-01 11:59:39,031:INFO: Epoch: 22/30, Step: 23/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068300
2023-06-01 11:59:39,100:INFO: Epoch: 22/30, Step: 24/64, Lr: 0.000430666, Loss: 0.002004, Step Loss: 0.002004, Time: 0.068345
2023-06-01 11:59:39,174:INFO: Epoch: 22/30, Step: 25/64, Lr: 0.000430666, Loss: 0.000018, Step Loss: 0.000018, Time: 0.074209
2023-06-01 11:59:39,239:INFO: Epoch: 22/30, Step: 26/64, Lr: 0.000430666, Loss: 0.000207, Step Loss: 0.000207, Time: 0.064439
2023-06-01 11:59:39,312:INFO: Epoch: 22/30, Step: 27/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072513
2023-06-01 11:59:39,387:INFO: Epoch: 22/30, Step: 28/64, Lr: 0.000430666, Loss: 0.000312, Step Loss: 0.000312, Time: 0.075127
2023-06-01 11:59:39,456:INFO: Epoch: 22/30, Step: 29/64, Lr: 0.000430666, Loss: 0.000074, Step Loss: 0.000074, Time: 0.068438
2023-06-01 11:59:39,523:INFO: Epoch: 22/30, Step: 30/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066543
2023-06-01 11:59:39,594:INFO: Epoch: 22/30, Step: 31/64, Lr: 0.000430666, Loss: 0.000003, Step Loss: 0.000003, Time: 0.071134
2023-06-01 11:59:39,662:INFO: Epoch: 22/30, Step: 32/64, Lr: 0.000430666, Loss: 0.000035, Step Loss: 0.000035, Time: 0.068050
2023-06-01 11:59:39,731:INFO: Epoch: 22/30, Step: 33/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068543
2023-06-01 11:59:39,803:INFO: Epoch: 22/30, Step: 34/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071550
2023-06-01 11:59:39,870:INFO: Epoch: 22/30, Step: 35/64, Lr: 0.000430666, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066967
2023-06-01 11:59:39,939:INFO: Epoch: 22/30, Step: 36/64, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068246
2023-06-01 11:59:40,008:INFO: Epoch: 22/30, Step: 37/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068746
2023-06-01 11:59:40,078:INFO: Epoch: 22/30, Step: 38/64, Lr: 0.000430666, Loss: 0.000003, Step Loss: 0.000003, Time: 0.069525
2023-06-01 11:59:40,143:INFO: Epoch: 22/30, Step: 39/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065007
2023-06-01 11:59:40,216:INFO: Epoch: 22/30, Step: 40/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071828
2023-06-01 11:59:40,288:INFO: Epoch: 22/30, Step: 41/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072083
2023-06-01 11:59:40,356:INFO: Epoch: 22/30, Step: 42/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067632
2023-06-01 11:59:40,428:INFO: Epoch: 22/30, Step: 43/64, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.072258
2023-06-01 11:59:40,495:INFO: Epoch: 22/30, Step: 44/64, Lr: 0.000430666, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066455
2023-06-01 11:59:40,565:INFO: Epoch: 22/30, Step: 45/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069257
2023-06-01 11:59:40,635:INFO: Epoch: 22/30, Step: 46/64, Lr: 0.000430666, Loss: 0.000018, Step Loss: 0.000018, Time: 0.069660
2023-06-01 11:59:40,704:INFO: Epoch: 22/30, Step: 47/64, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068913
2023-06-01 11:59:40,775:INFO: Epoch: 22/30, Step: 48/64, Lr: 0.000430666, Loss: 0.000009, Step Loss: 0.000009, Time: 0.071031
2023-06-01 11:59:40,843:INFO: Epoch: 22/30, Step: 49/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067202
2023-06-01 11:59:40,911:INFO: Epoch: 22/30, Step: 50/64, Lr: 0.000430666, Loss: 0.000047, Step Loss: 0.000047, Time: 0.067720
2023-06-01 11:59:40,979:INFO: Epoch: 22/30, Step: 51/64, Lr: 0.000430666, Loss: 0.000009, Step Loss: 0.000009, Time: 0.067614
2023-06-01 11:59:41,054:INFO: Epoch: 22/30, Step: 52/64, Lr: 0.000430666, Loss: 0.000002, Step Loss: 0.000002, Time: 0.075303
2023-06-01 11:59:41,119:INFO: Epoch: 22/30, Step: 53/64, Lr: 0.000430666, Loss: 0.000072, Step Loss: 0.000072, Time: 0.064668
2023-06-01 11:59:41,184:INFO: Epoch: 22/30, Step: 54/64, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064168
2023-06-01 11:59:41,269:INFO: Epoch: 22/30, Step: 55/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.085101
2023-06-01 11:59:41,335:INFO: Epoch: 22/30, Step: 56/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065243
2023-06-01 11:59:41,406:INFO: Epoch: 22/30, Step: 57/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071333
2023-06-01 11:59:41,483:INFO: Epoch: 22/30, Step: 58/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076578
2023-06-01 11:59:41,557:INFO: Epoch: 22/30, Step: 59/64, Lr: 0.000430666, Loss: 0.000672, Step Loss: 0.000672, Time: 0.073909
2023-06-01 11:59:41,632:INFO: Epoch: 22/30, Step: 60/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074635
2023-06-01 11:59:41,703:INFO: Epoch: 22/30, Step: 61/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070260
2023-06-01 11:59:41,772:INFO: Epoch: 22/30, Step: 62/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069237
2023-06-01 11:59:41,842:INFO: Epoch: 22/30, Step: 63/64, Lr: 0.000430666, Loss: 0.000001, Step Loss: 0.000001, Time: 0.069871
2023-06-01 11:59:41,909:INFO: Epoch: 22/30, Step: 64/64, Lr: 0.000430666, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066688
2023-06-01 11:59:42,056:INFO: Epoch 22/30 Finished, Train Loss: 0.000061
2023-06-01 11:59:49,392:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.21
2023-06-01 11:59:52,486:INFO: Classfication Metrics:
2023-06-01 11:59:52,486:INFO: f1 score: 0.8860 - precision score: 0.9018 - recall score: 0.8707 - accuracy score: 0.911864
2023-06-01 11:59:52,486:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 11:59:53,474:INFO: Epoch: 23/30, Step: 1/64, Lr: 0.000348130, Loss: 0.001079, Step Loss: 0.001079, Time: 0.963029
2023-06-01 11:59:53,676:INFO: Epoch: 23/30, Step: 2/64, Lr: 0.000348130, Loss: 0.000006, Step Loss: 0.000006, Time: 0.201871
2023-06-01 11:59:53,751:INFO: Epoch: 23/30, Step: 3/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074402
2023-06-01 11:59:53,816:INFO: Epoch: 23/30, Step: 4/64, Lr: 0.000348130, Loss: 0.000002, Step Loss: 0.000002, Time: 0.064521
2023-06-01 11:59:53,891:INFO: Epoch: 23/30, Step: 5/64, Lr: 0.000348130, Loss: 0.000383, Step Loss: 0.000383, Time: 0.074461
2023-06-01 11:59:53,955:INFO: Epoch: 23/30, Step: 6/64, Lr: 0.000348130, Loss: 0.000043, Step Loss: 0.000043, Time: 0.064302
2023-06-01 11:59:54,025:INFO: Epoch: 23/30, Step: 7/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069470
2023-06-01 11:59:54,092:INFO: Epoch: 23/30, Step: 8/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066073
2023-06-01 11:59:54,158:INFO: Epoch: 23/30, Step: 9/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066143
2023-06-01 11:59:54,239:INFO: Epoch: 23/30, Step: 10/64, Lr: 0.000348130, Loss: 0.000166, Step Loss: 0.000166, Time: 0.080364
2023-06-01 11:59:54,306:INFO: Epoch: 23/30, Step: 11/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066576
2023-06-01 11:59:54,374:INFO: Epoch: 23/30, Step: 12/64, Lr: 0.000348130, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067113
2023-06-01 11:59:54,439:INFO: Epoch: 23/30, Step: 13/64, Lr: 0.000348130, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064883
2023-06-01 11:59:54,505:INFO: Epoch: 23/30, Step: 14/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065222
2023-06-01 11:59:54,574:INFO: Epoch: 23/30, Step: 15/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069303
2023-06-01 11:59:54,641:INFO: Epoch: 23/30, Step: 16/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066710
2023-06-01 11:59:54,707:INFO: Epoch: 23/30, Step: 17/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065502
2023-06-01 11:59:54,779:INFO: Epoch: 23/30, Step: 18/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071472
2023-06-01 11:59:54,847:INFO: Epoch: 23/30, Step: 19/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066842
2023-06-01 11:59:54,919:INFO: Epoch: 23/30, Step: 20/64, Lr: 0.000348130, Loss: 0.000002, Step Loss: 0.000002, Time: 0.071898
2023-06-01 11:59:54,984:INFO: Epoch: 23/30, Step: 21/64, Lr: 0.000348130, Loss: 0.183683, Step Loss: 0.183683, Time: 0.064308
2023-06-01 11:59:55,055:INFO: Epoch: 23/30, Step: 22/64, Lr: 0.000348130, Loss: 0.054677, Step Loss: 0.054677, Time: 0.070847
2023-06-01 11:59:55,118:INFO: Epoch: 23/30, Step: 23/64, Lr: 0.000348130, Loss: 0.000038, Step Loss: 0.000038, Time: 0.062986
2023-06-01 11:59:55,183:INFO: Epoch: 23/30, Step: 24/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064553
2023-06-01 11:59:55,246:INFO: Epoch: 23/30, Step: 25/64, Lr: 0.000348130, Loss: 0.000003, Step Loss: 0.000003, Time: 0.062714
2023-06-01 11:59:55,315:INFO: Epoch: 23/30, Step: 26/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067658
2023-06-01 11:59:55,383:INFO: Epoch: 23/30, Step: 27/64, Lr: 0.000348130, Loss: 0.000007, Step Loss: 0.000007, Time: 0.068168
2023-06-01 11:59:55,453:INFO: Epoch: 23/30, Step: 28/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069758
2023-06-01 11:59:55,522:INFO: Epoch: 23/30, Step: 29/64, Lr: 0.000348130, Loss: 0.000016, Step Loss: 0.000016, Time: 0.068562
2023-06-01 11:59:55,591:INFO: Epoch: 23/30, Step: 30/64, Lr: 0.000348130, Loss: 0.000025, Step Loss: 0.000025, Time: 0.068378
2023-06-01 11:59:55,660:INFO: Epoch: 23/30, Step: 31/64, Lr: 0.000348130, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068370
2023-06-01 11:59:55,731:INFO: Epoch: 23/30, Step: 32/64, Lr: 0.000348130, Loss: 0.000007, Step Loss: 0.000007, Time: 0.070090
2023-06-01 11:59:55,796:INFO: Epoch: 23/30, Step: 33/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064827
2023-06-01 11:59:55,867:INFO: Epoch: 23/30, Step: 34/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070887
2023-06-01 11:59:55,936:INFO: Epoch: 23/30, Step: 35/64, Lr: 0.000348130, Loss: 0.004815, Step Loss: 0.004815, Time: 0.068422
2023-06-01 11:59:56,002:INFO: Epoch: 23/30, Step: 36/64, Lr: 0.000348130, Loss: 0.000020, Step Loss: 0.000020, Time: 0.065772
2023-06-01 11:59:56,070:INFO: Epoch: 23/30, Step: 37/64, Lr: 0.000348130, Loss: 0.000016, Step Loss: 0.000016, Time: 0.067708
2023-06-01 11:59:56,138:INFO: Epoch: 23/30, Step: 38/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067799
2023-06-01 11:59:56,207:INFO: Epoch: 23/30, Step: 39/64, Lr: 0.000348130, Loss: 0.034160, Step Loss: 0.034160, Time: 0.068511
2023-06-01 11:59:56,272:INFO: Epoch: 23/30, Step: 40/64, Lr: 0.000348130, Loss: 0.000036, Step Loss: 0.000036, Time: 0.064230
2023-06-01 11:59:56,350:INFO: Epoch: 23/30, Step: 41/64, Lr: 0.000348130, Loss: 0.015916, Step Loss: 0.015916, Time: 0.076987
2023-06-01 11:59:56,415:INFO: Epoch: 23/30, Step: 42/64, Lr: 0.000348130, Loss: 0.054900, Step Loss: 0.054900, Time: 0.065250
2023-06-01 11:59:56,482:INFO: Epoch: 23/30, Step: 43/64, Lr: 0.000348130, Loss: 0.000010, Step Loss: 0.000010, Time: 0.066466
2023-06-01 11:59:56,551:INFO: Epoch: 23/30, Step: 44/64, Lr: 0.000348130, Loss: 0.001784, Step Loss: 0.001784, Time: 0.068238
2023-06-01 11:59:56,619:INFO: Epoch: 23/30, Step: 45/64, Lr: 0.000348130, Loss: 0.000014, Step Loss: 0.000014, Time: 0.067568
2023-06-01 11:59:56,687:INFO: Epoch: 23/30, Step: 46/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068006
2023-06-01 11:59:56,767:INFO: Epoch: 23/30, Step: 47/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079198
2023-06-01 11:59:56,834:INFO: Epoch: 23/30, Step: 48/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066898
2023-06-01 11:59:56,899:INFO: Epoch: 23/30, Step: 49/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064448
2023-06-01 11:59:56,963:INFO: Epoch: 23/30, Step: 50/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063551
2023-06-01 11:59:57,030:INFO: Epoch: 23/30, Step: 51/64, Lr: 0.000348130, Loss: 0.008734, Step Loss: 0.008734, Time: 0.066591
2023-06-01 11:59:57,099:INFO: Epoch: 23/30, Step: 52/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068167
2023-06-01 11:59:57,167:INFO: Epoch: 23/30, Step: 53/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067583
2023-06-01 11:59:57,235:INFO: Epoch: 23/30, Step: 54/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068069
2023-06-01 11:59:57,300:INFO: Epoch: 23/30, Step: 55/64, Lr: 0.000348130, Loss: 0.077777, Step Loss: 0.077777, Time: 0.064148
2023-06-01 11:59:57,371:INFO: Epoch: 23/30, Step: 56/64, Lr: 0.000348130, Loss: 0.000050, Step Loss: 0.000050, Time: 0.070817
2023-06-01 11:59:57,436:INFO: Epoch: 23/30, Step: 57/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064138
2023-06-01 11:59:57,503:INFO: Epoch: 23/30, Step: 58/64, Lr: 0.000348130, Loss: 0.001943, Step Loss: 0.001943, Time: 0.066591
2023-06-01 11:59:57,571:INFO: Epoch: 23/30, Step: 59/64, Lr: 0.000348130, Loss: 0.000474, Step Loss: 0.000474, Time: 0.067911
2023-06-01 11:59:57,639:INFO: Epoch: 23/30, Step: 60/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067603
2023-06-01 11:59:57,759:INFO: Epoch: 23/30, Step: 61/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072604
2023-06-01 11:59:57,827:INFO: Epoch: 23/30, Step: 62/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068226
2023-06-01 11:59:57,895:INFO: Epoch: 23/30, Step: 63/64, Lr: 0.000348130, Loss: 0.000416, Step Loss: 0.000416, Time: 0.067648
2023-06-01 11:59:57,962:INFO: Epoch: 23/30, Step: 64/64, Lr: 0.000348130, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066655
2023-06-01 11:59:58,114:INFO: Epoch 23/30 Finished, Train Loss: 0.006894
2023-06-01 12:00:06,449:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.22
2023-06-01 12:00:09,593:INFO: Classfication Metrics:
2023-06-01 12:00:09,593:INFO: f1 score: 0.8700 - precision score: 0.9065 - recall score: 0.8362 - accuracy score: 0.901695
2023-06-01 12:00:09,593:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:00:10,680:INFO: Epoch: 24/30, Step: 1/64, Lr: 0.000271932, Loss: 0.000004, Step Loss: 0.000004, Time: 1.077749
2023-06-01 12:00:10,751:INFO: Epoch: 24/30, Step: 2/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070694
2023-06-01 12:00:10,818:INFO: Epoch: 24/30, Step: 3/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066374
2023-06-01 12:00:10,887:INFO: Epoch: 24/30, Step: 4/64, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.068969
2023-06-01 12:00:10,954:INFO: Epoch: 24/30, Step: 5/64, Lr: 0.000271932, Loss: 0.000081, Step Loss: 0.000081, Time: 0.066393
2023-06-01 12:00:11,019:INFO: Epoch: 24/30, Step: 6/64, Lr: 0.000271932, Loss: 0.000526, Step Loss: 0.000526, Time: 0.065003
2023-06-01 12:00:11,083:INFO: Epoch: 24/30, Step: 7/64, Lr: 0.000271932, Loss: 0.000007, Step Loss: 0.000007, Time: 0.064431
2023-06-01 12:00:11,153:INFO: Epoch: 24/30, Step: 8/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069262
2023-06-01 12:00:11,243:INFO: Epoch: 24/30, Step: 9/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.089801
2023-06-01 12:00:11,316:INFO: Epoch: 24/30, Step: 10/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072788
2023-06-01 12:00:11,381:INFO: Epoch: 24/30, Step: 11/64, Lr: 0.000271932, Loss: 0.000002, Step Loss: 0.000002, Time: 0.065055
2023-06-01 12:00:11,444:INFO: Epoch: 24/30, Step: 12/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.062641
2023-06-01 12:00:11,510:INFO: Epoch: 24/30, Step: 13/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065074
2023-06-01 12:00:11,579:INFO: Epoch: 24/30, Step: 14/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069531
2023-06-01 12:00:11,644:INFO: Epoch: 24/30, Step: 15/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064422
2023-06-01 12:00:11,709:INFO: Epoch: 24/30, Step: 16/64, Lr: 0.000271932, Loss: 0.000014, Step Loss: 0.000014, Time: 0.065136
2023-06-01 12:00:11,782:INFO: Epoch: 24/30, Step: 17/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072495
2023-06-01 12:00:11,847:INFO: Epoch: 24/30, Step: 18/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064291
2023-06-01 12:00:11,915:INFO: Epoch: 24/30, Step: 19/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068155
2023-06-01 12:00:11,983:INFO: Epoch: 24/30, Step: 20/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067456
2023-06-01 12:00:12,048:INFO: Epoch: 24/30, Step: 21/64, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.064764
2023-06-01 12:00:12,116:INFO: Epoch: 24/30, Step: 22/64, Lr: 0.000271932, Loss: 0.000007, Step Loss: 0.000007, Time: 0.068286
2023-06-01 12:00:12,186:INFO: Epoch: 24/30, Step: 23/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069292
2023-06-01 12:00:12,254:INFO: Epoch: 24/30, Step: 24/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068141
2023-06-01 12:00:12,318:INFO: Epoch: 24/30, Step: 25/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.063492
2023-06-01 12:00:12,388:INFO: Epoch: 24/30, Step: 26/64, Lr: 0.000271932, Loss: 0.192059, Step Loss: 0.192059, Time: 0.069387
2023-06-01 12:00:12,453:INFO: Epoch: 24/30, Step: 27/64, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.065135
2023-06-01 12:00:12,518:INFO: Epoch: 24/30, Step: 28/64, Lr: 0.000271932, Loss: 0.000052, Step Loss: 0.000052, Time: 0.064119
2023-06-01 12:00:12,589:INFO: Epoch: 24/30, Step: 29/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071119
2023-06-01 12:00:12,658:INFO: Epoch: 24/30, Step: 30/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068063
2023-06-01 12:00:12,724:INFO: Epoch: 24/30, Step: 31/64, Lr: 0.000271932, Loss: 0.000006, Step Loss: 0.000006, Time: 0.065732
2023-06-01 12:00:12,801:INFO: Epoch: 24/30, Step: 32/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076948
2023-06-01 12:00:12,870:INFO: Epoch: 24/30, Step: 33/64, Lr: 0.000271932, Loss: 0.034642, Step Loss: 0.034642, Time: 0.069178
2023-06-01 12:00:12,938:INFO: Epoch: 24/30, Step: 34/64, Lr: 0.000271932, Loss: 0.000071, Step Loss: 0.000071, Time: 0.066989
2023-06-01 12:00:13,018:INFO: Epoch: 24/30, Step: 35/64, Lr: 0.000271932, Loss: 0.000529, Step Loss: 0.000529, Time: 0.079963
2023-06-01 12:00:13,086:INFO: Epoch: 24/30, Step: 36/64, Lr: 0.000271932, Loss: 0.000229, Step Loss: 0.000229, Time: 0.068063
2023-06-01 12:00:13,153:INFO: Epoch: 24/30, Step: 37/64, Lr: 0.000271932, Loss: 0.000103, Step Loss: 0.000103, Time: 0.066316
2023-06-01 12:00:13,219:INFO: Epoch: 24/30, Step: 38/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065746
2023-06-01 12:00:13,285:INFO: Epoch: 24/30, Step: 39/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066404
2023-06-01 12:00:13,362:INFO: Epoch: 24/30, Step: 40/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076038
2023-06-01 12:00:13,430:INFO: Epoch: 24/30, Step: 41/64, Lr: 0.000271932, Loss: 0.000345, Step Loss: 0.000345, Time: 0.067896
2023-06-01 12:00:13,498:INFO: Epoch: 24/30, Step: 42/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067822
2023-06-01 12:00:13,573:INFO: Epoch: 24/30, Step: 43/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074911
2023-06-01 12:00:13,638:INFO: Epoch: 24/30, Step: 44/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064200
2023-06-01 12:00:13,702:INFO: Epoch: 24/30, Step: 45/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064368
2023-06-01 12:00:13,771:INFO: Epoch: 24/30, Step: 46/64, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.068098
2023-06-01 12:00:13,843:INFO: Epoch: 24/30, Step: 47/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071655
2023-06-01 12:00:13,914:INFO: Epoch: 24/30, Step: 48/64, Lr: 0.000271932, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070836
2023-06-01 12:00:13,990:INFO: Epoch: 24/30, Step: 49/64, Lr: 0.000271932, Loss: 0.000011, Step Loss: 0.000011, Time: 0.076018
2023-06-01 12:00:14,066:INFO: Epoch: 24/30, Step: 50/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075281
2023-06-01 12:00:14,140:INFO: Epoch: 24/30, Step: 51/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074173
2023-06-01 12:00:14,207:INFO: Epoch: 24/30, Step: 52/64, Lr: 0.000271932, Loss: 0.000005, Step Loss: 0.000005, Time: 0.066149
2023-06-01 12:00:14,278:INFO: Epoch: 24/30, Step: 53/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071555
2023-06-01 12:00:14,346:INFO: Epoch: 24/30, Step: 54/64, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.067802
2023-06-01 12:00:14,418:INFO: Epoch: 24/30, Step: 55/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071150
2023-06-01 12:00:14,490:INFO: Epoch: 24/30, Step: 56/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072272
2023-06-01 12:00:14,565:INFO: Epoch: 24/30, Step: 57/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074217
2023-06-01 12:00:14,630:INFO: Epoch: 24/30, Step: 58/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064324
2023-06-01 12:00:14,706:INFO: Epoch: 24/30, Step: 59/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076368
2023-06-01 12:00:14,785:INFO: Epoch: 24/30, Step: 60/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078335
2023-06-01 12:00:14,851:INFO: Epoch: 24/30, Step: 61/64, Lr: 0.000271932, Loss: 0.000003, Step Loss: 0.000003, Time: 0.066248
2023-06-01 12:00:14,927:INFO: Epoch: 24/30, Step: 62/64, Lr: 0.000271932, Loss: 0.000503, Step Loss: 0.000503, Time: 0.075040
2023-06-01 12:00:15,002:INFO: Epoch: 24/30, Step: 63/64, Lr: 0.000271932, Loss: 0.000019, Step Loss: 0.000019, Time: 0.074550
2023-06-01 12:00:15,066:INFO: Epoch: 24/30, Step: 64/64, Lr: 0.000271932, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063555
2023-06-01 12:00:15,221:INFO: Epoch 24/30 Finished, Train Loss: 0.003582
2023-06-01 12:00:28,998:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.23
2023-06-01 12:00:32,086:INFO: Classfication Metrics:
2023-06-01 12:00:32,086:INFO: f1 score: 0.8750 - precision score: 0.9074 - recall score: 0.8448 - accuracy score: 0.905085
2023-06-01 12:00:32,086:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:00:33,090:INFO: Epoch: 25/30, Step: 1/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.980962
2023-06-01 12:00:33,254:INFO: Epoch: 25/30, Step: 2/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.163762
2023-06-01 12:00:33,319:INFO: Epoch: 25/30, Step: 3/64, Lr: 0.000203274, Loss: 0.000003, Step Loss: 0.000003, Time: 0.064566
2023-06-01 12:00:33,394:INFO: Epoch: 25/30, Step: 4/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074495
2023-06-01 12:00:33,462:INFO: Epoch: 25/30, Step: 5/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067868
2023-06-01 12:00:33,527:INFO: Epoch: 25/30, Step: 6/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063875
2023-06-01 12:00:33,594:INFO: Epoch: 25/30, Step: 7/64, Lr: 0.000203274, Loss: 0.007083, Step Loss: 0.007083, Time: 0.066625
2023-06-01 12:00:33,674:INFO: Epoch: 25/30, Step: 8/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.079946
2023-06-01 12:00:33,742:INFO: Epoch: 25/30, Step: 9/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067268
2023-06-01 12:00:33,818:INFO: Epoch: 25/30, Step: 10/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075513
2023-06-01 12:00:33,884:INFO: Epoch: 25/30, Step: 11/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065421
2023-06-01 12:00:33,951:INFO: Epoch: 25/30, Step: 12/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066689
2023-06-01 12:00:34,018:INFO: Epoch: 25/30, Step: 13/64, Lr: 0.000203274, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066810
2023-06-01 12:00:34,090:INFO: Epoch: 25/30, Step: 14/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071461
2023-06-01 12:00:34,158:INFO: Epoch: 25/30, Step: 15/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067447
2023-06-01 12:00:34,225:INFO: Epoch: 25/30, Step: 16/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066668
2023-06-01 12:00:34,290:INFO: Epoch: 25/30, Step: 17/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064259
2023-06-01 12:00:34,359:INFO: Epoch: 25/30, Step: 18/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068988
2023-06-01 12:00:34,425:INFO: Epoch: 25/30, Step: 19/64, Lr: 0.000203274, Loss: 0.000174, Step Loss: 0.000174, Time: 0.066057
2023-06-01 12:00:34,492:INFO: Epoch: 25/30, Step: 20/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066072
2023-06-01 12:00:34,559:INFO: Epoch: 25/30, Step: 21/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067276
2023-06-01 12:00:34,628:INFO: Epoch: 25/30, Step: 22/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067660
2023-06-01 12:00:34,694:INFO: Epoch: 25/30, Step: 23/64, Lr: 0.000203274, Loss: 0.000016, Step Loss: 0.000016, Time: 0.066335
2023-06-01 12:00:34,772:INFO: Epoch: 25/30, Step: 24/64, Lr: 0.000203274, Loss: 0.000080, Step Loss: 0.000080, Time: 0.077338
2023-06-01 12:00:34,840:INFO: Epoch: 25/30, Step: 25/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067419
2023-06-01 12:00:34,910:INFO: Epoch: 25/30, Step: 26/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069815
2023-06-01 12:00:34,977:INFO: Epoch: 25/30, Step: 27/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066183
2023-06-01 12:00:35,042:INFO: Epoch: 25/30, Step: 28/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065120
2023-06-01 12:00:35,118:INFO: Epoch: 25/30, Step: 29/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075818
2023-06-01 12:00:35,190:INFO: Epoch: 25/30, Step: 30/64, Lr: 0.000203274, Loss: 0.000027, Step Loss: 0.000027, Time: 0.071117
2023-06-01 12:00:35,258:INFO: Epoch: 25/30, Step: 31/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068294
2023-06-01 12:00:35,325:INFO: Epoch: 25/30, Step: 32/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066482
2023-06-01 12:00:35,391:INFO: Epoch: 25/30, Step: 33/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065280
2023-06-01 12:00:35,466:INFO: Epoch: 25/30, Step: 34/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074784
2023-06-01 12:00:35,535:INFO: Epoch: 25/30, Step: 35/64, Lr: 0.000203274, Loss: 0.203889, Step Loss: 0.203889, Time: 0.068445
2023-06-01 12:00:35,599:INFO: Epoch: 25/30, Step: 36/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.063675
2023-06-01 12:00:35,666:INFO: Epoch: 25/30, Step: 37/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067283
2023-06-01 12:00:35,734:INFO: Epoch: 25/30, Step: 38/64, Lr: 0.000203274, Loss: 0.000024, Step Loss: 0.000024, Time: 0.067908
2023-06-01 12:00:35,807:INFO: Epoch: 25/30, Step: 39/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072688
2023-06-01 12:00:35,874:INFO: Epoch: 25/30, Step: 40/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066096
2023-06-01 12:00:35,938:INFO: Epoch: 25/30, Step: 41/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063914
2023-06-01 12:00:36,006:INFO: Epoch: 25/30, Step: 42/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067529
2023-06-01 12:00:36,076:INFO: Epoch: 25/30, Step: 43/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069704
2023-06-01 12:00:36,142:INFO: Epoch: 25/30, Step: 44/64, Lr: 0.000203274, Loss: 0.000320, Step Loss: 0.000320, Time: 0.066090
2023-06-01 12:00:36,210:INFO: Epoch: 25/30, Step: 45/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067355
2023-06-01 12:00:36,277:INFO: Epoch: 25/30, Step: 46/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067283
2023-06-01 12:00:36,344:INFO: Epoch: 25/30, Step: 47/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066576
2023-06-01 12:00:36,411:INFO: Epoch: 25/30, Step: 48/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066139
2023-06-01 12:00:36,483:INFO: Epoch: 25/30, Step: 49/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072113
2023-06-01 12:00:36,550:INFO: Epoch: 25/30, Step: 50/64, Lr: 0.000203274, Loss: 0.000041, Step Loss: 0.000041, Time: 0.066373
2023-06-01 12:00:36,617:INFO: Epoch: 25/30, Step: 51/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067227
2023-06-01 12:00:36,692:INFO: Epoch: 25/30, Step: 52/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074362
2023-06-01 12:00:36,765:INFO: Epoch: 25/30, Step: 53/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072980
2023-06-01 12:00:36,834:INFO: Epoch: 25/30, Step: 54/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068816
2023-06-01 12:00:36,899:INFO: Epoch: 25/30, Step: 55/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064425
2023-06-01 12:00:36,963:INFO: Epoch: 25/30, Step: 56/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063502
2023-06-01 12:00:37,039:INFO: Epoch: 25/30, Step: 57/64, Lr: 0.000203274, Loss: 0.141322, Step Loss: 0.141322, Time: 0.076442
2023-06-01 12:00:37,104:INFO: Epoch: 25/30, Step: 58/64, Lr: 0.000203274, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064037
2023-06-01 12:00:37,169:INFO: Epoch: 25/30, Step: 59/64, Lr: 0.000203274, Loss: 0.000932, Step Loss: 0.000932, Time: 0.065665
2023-06-01 12:00:37,237:INFO: Epoch: 25/30, Step: 60/64, Lr: 0.000203274, Loss: 0.000003, Step Loss: 0.000003, Time: 0.067423
2023-06-01 12:00:37,300:INFO: Epoch: 25/30, Step: 61/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.062541
2023-06-01 12:00:37,375:INFO: Epoch: 25/30, Step: 62/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.074774
2023-06-01 12:00:37,438:INFO: Epoch: 25/30, Step: 63/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.063292
2023-06-01 12:00:37,511:INFO: Epoch: 25/30, Step: 64/64, Lr: 0.000203274, Loss: 0.000001, Step Loss: 0.000001, Time: 0.072064
2023-06-01 12:00:37,668:INFO: Epoch 25/30 Finished, Train Loss: 0.005530
2023-06-01 12:00:44,765:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.24
2023-06-01 12:00:47,823:INFO: Classfication Metrics:
2023-06-01 12:00:47,823:INFO: f1 score: 0.8772 - precision score: 0.8929 - recall score: 0.8621 - accuracy score: 0.905085
2023-06-01 12:00:47,823:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:00:49,124:INFO: Epoch: 26/30, Step: 1/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 1.291143
2023-06-01 12:00:49,190:INFO: Epoch: 26/30, Step: 2/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065395
2023-06-01 12:00:49,254:INFO: Epoch: 26/30, Step: 3/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063347
2023-06-01 12:00:49,319:INFO: Epoch: 26/30, Step: 4/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064957
2023-06-01 12:00:49,386:INFO: Epoch: 26/30, Step: 5/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066576
2023-06-01 12:00:49,453:INFO: Epoch: 26/30, Step: 6/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066946
2023-06-01 12:00:49,519:INFO: Epoch: 26/30, Step: 7/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065058
2023-06-01 12:00:49,585:INFO: Epoch: 26/30, Step: 8/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066559
2023-06-01 12:00:49,657:INFO: Epoch: 26/30, Step: 9/64, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070859
2023-06-01 12:00:49,723:INFO: Epoch: 26/30, Step: 10/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066154
2023-06-01 12:00:49,790:INFO: Epoch: 26/30, Step: 11/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066924
2023-06-01 12:00:49,854:INFO: Epoch: 26/30, Step: 12/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063589
2023-06-01 12:00:49,919:INFO: Epoch: 26/30, Step: 13/64, Lr: 0.000143237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.064803
2023-06-01 12:00:49,986:INFO: Epoch: 26/30, Step: 14/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065834
2023-06-01 12:00:50,051:INFO: Epoch: 26/30, Step: 15/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064943
2023-06-01 12:00:50,118:INFO: Epoch: 26/30, Step: 16/64, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066445
2023-06-01 12:00:50,190:INFO: Epoch: 26/30, Step: 17/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072219
2023-06-01 12:00:50,264:INFO: Epoch: 26/30, Step: 18/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072796
2023-06-01 12:00:50,337:INFO: Epoch: 26/30, Step: 19/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072503
2023-06-01 12:00:50,407:INFO: Epoch: 26/30, Step: 20/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069650
2023-06-01 12:00:50,472:INFO: Epoch: 26/30, Step: 21/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064492
2023-06-01 12:00:50,538:INFO: Epoch: 26/30, Step: 22/64, Lr: 0.000143237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.065724
2023-06-01 12:00:50,607:INFO: Epoch: 26/30, Step: 23/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068588
2023-06-01 12:00:50,677:INFO: Epoch: 26/30, Step: 24/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068989
2023-06-01 12:00:50,750:INFO: Epoch: 26/30, Step: 25/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072785
2023-06-01 12:00:50,819:INFO: Epoch: 26/30, Step: 26/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068332
2023-06-01 12:00:50,886:INFO: Epoch: 26/30, Step: 27/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066890
2023-06-01 12:00:50,961:INFO: Epoch: 26/30, Step: 28/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074431
2023-06-01 12:00:51,034:INFO: Epoch: 26/30, Step: 29/64, Lr: 0.000143237, Loss: 0.000003, Step Loss: 0.000003, Time: 0.073172
2023-06-01 12:00:51,110:INFO: Epoch: 26/30, Step: 30/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075235
2023-06-01 12:00:51,179:INFO: Epoch: 26/30, Step: 31/64, Lr: 0.000143237, Loss: 0.000100, Step Loss: 0.000100, Time: 0.068752
2023-06-01 12:00:51,251:INFO: Epoch: 26/30, Step: 32/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070738
2023-06-01 12:00:51,331:INFO: Epoch: 26/30, Step: 33/64, Lr: 0.000143237, Loss: 0.000019, Step Loss: 0.000019, Time: 0.079666
2023-06-01 12:00:51,398:INFO: Epoch: 26/30, Step: 34/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066981
2023-06-01 12:00:51,470:INFO: Epoch: 26/30, Step: 35/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071439
2023-06-01 12:00:51,547:INFO: Epoch: 26/30, Step: 36/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076185
2023-06-01 12:00:51,619:INFO: Epoch: 26/30, Step: 37/64, Lr: 0.000143237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.071977
2023-06-01 12:00:51,683:INFO: Epoch: 26/30, Step: 38/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063644
2023-06-01 12:00:51,751:INFO: Epoch: 26/30, Step: 39/64, Lr: 0.000143237, Loss: 0.000039, Step Loss: 0.000039, Time: 0.067580
2023-06-01 12:00:51,820:INFO: Epoch: 26/30, Step: 40/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068048
2023-06-01 12:00:51,891:INFO: Epoch: 26/30, Step: 41/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070472
2023-06-01 12:00:51,964:INFO: Epoch: 26/30, Step: 42/64, Lr: 0.000143237, Loss: 0.000049, Step Loss: 0.000049, Time: 0.072777
2023-06-01 12:00:52,031:INFO: Epoch: 26/30, Step: 43/64, Lr: 0.000143237, Loss: 0.000026, Step Loss: 0.000026, Time: 0.066351
2023-06-01 12:00:52,109:INFO: Epoch: 26/30, Step: 44/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078262
2023-06-01 12:00:52,176:INFO: Epoch: 26/30, Step: 45/64, Lr: 0.000143237, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066195
2023-06-01 12:00:52,242:INFO: Epoch: 26/30, Step: 46/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065582
2023-06-01 12:00:52,312:INFO: Epoch: 26/30, Step: 47/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069690
2023-06-01 12:00:52,381:INFO: Epoch: 26/30, Step: 48/64, Lr: 0.000143237, Loss: 0.043377, Step Loss: 0.043377, Time: 0.068905
2023-06-01 12:00:52,452:INFO: Epoch: 26/30, Step: 49/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070247
2023-06-01 12:00:52,518:INFO: Epoch: 26/30, Step: 50/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065721
2023-06-01 12:00:52,586:INFO: Epoch: 26/30, Step: 51/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067828
2023-06-01 12:00:52,658:INFO: Epoch: 26/30, Step: 52/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071539
2023-06-01 12:00:52,723:INFO: Epoch: 26/30, Step: 53/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064368
2023-06-01 12:00:52,789:INFO: Epoch: 26/30, Step: 54/64, Lr: 0.000143237, Loss: 0.000021, Step Loss: 0.000021, Time: 0.065367
2023-06-01 12:00:52,855:INFO: Epoch: 26/30, Step: 55/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065884
2023-06-01 12:00:52,923:INFO: Epoch: 26/30, Step: 56/64, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066899
2023-06-01 12:00:52,994:INFO: Epoch: 26/30, Step: 57/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070413
2023-06-01 12:00:53,059:INFO: Epoch: 26/30, Step: 58/64, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064523
2023-06-01 12:00:53,131:INFO: Epoch: 26/30, Step: 59/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071804
2023-06-01 12:00:53,203:INFO: Epoch: 26/30, Step: 60/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071566
2023-06-01 12:00:53,275:INFO: Epoch: 26/30, Step: 61/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071505
2023-06-01 12:00:53,349:INFO: Epoch: 26/30, Step: 62/64, Lr: 0.000143237, Loss: 0.000001, Step Loss: 0.000001, Time: 0.073681
2023-06-01 12:00:53,414:INFO: Epoch: 26/30, Step: 63/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065210
2023-06-01 12:00:53,480:INFO: Epoch: 26/30, Step: 64/64, Lr: 0.000143237, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064972
2023-06-01 12:00:53,638:INFO: Epoch 26/30 Finished, Train Loss: 0.000682
2023-06-01 12:01:00,842:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.25
2023-06-01 12:01:03,920:INFO: Classfication Metrics:
2023-06-01 12:01:03,920:INFO: f1 score: 0.8772 - precision score: 0.8929 - recall score: 0.8621 - accuracy score: 0.905085
2023-06-01 12:01:03,921:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:01:04,954:INFO: Epoch: 27/30, Step: 1/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 1.025639
2023-06-01 12:01:05,030:INFO: Epoch: 27/30, Step: 2/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075583
2023-06-01 12:01:05,099:INFO: Epoch: 27/30, Step: 3/64, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068731
2023-06-01 12:01:05,298:INFO: Epoch: 27/30, Step: 4/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.199157
2023-06-01 12:01:05,365:INFO: Epoch: 27/30, Step: 5/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066786
2023-06-01 12:01:05,432:INFO: Epoch: 27/30, Step: 6/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066167
2023-06-01 12:01:05,496:INFO: Epoch: 27/30, Step: 7/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064416
2023-06-01 12:01:05,562:INFO: Epoch: 27/30, Step: 8/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065663
2023-06-01 12:01:05,630:INFO: Epoch: 27/30, Step: 9/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067373
2023-06-01 12:01:05,699:INFO: Epoch: 27/30, Step: 10/64, Lr: 0.000092770, Loss: 0.000005, Step Loss: 0.000005, Time: 0.068447
2023-06-01 12:01:05,765:INFO: Epoch: 27/30, Step: 11/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065560
2023-06-01 12:01:05,840:INFO: Epoch: 27/30, Step: 12/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075275
2023-06-01 12:01:05,906:INFO: Epoch: 27/30, Step: 13/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065788
2023-06-01 12:01:05,973:INFO: Epoch: 27/30, Step: 14/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066858
2023-06-01 12:01:06,039:INFO: Epoch: 27/30, Step: 15/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065895
2023-06-01 12:01:06,104:INFO: Epoch: 27/30, Step: 16/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064613
2023-06-01 12:01:06,171:INFO: Epoch: 27/30, Step: 17/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066419
2023-06-01 12:01:06,245:INFO: Epoch: 27/30, Step: 18/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074321
2023-06-01 12:01:06,316:INFO: Epoch: 27/30, Step: 19/64, Lr: 0.000092770, Loss: 0.000346, Step Loss: 0.000346, Time: 0.070331
2023-06-01 12:01:06,388:INFO: Epoch: 27/30, Step: 20/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071681
2023-06-01 12:01:06,459:INFO: Epoch: 27/30, Step: 21/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070141
2023-06-01 12:01:06,530:INFO: Epoch: 27/30, Step: 22/64, Lr: 0.000092770, Loss: 0.000007, Step Loss: 0.000007, Time: 0.071027
2023-06-01 12:01:06,595:INFO: Epoch: 27/30, Step: 23/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064325
2023-06-01 12:01:06,662:INFO: Epoch: 27/30, Step: 24/64, Lr: 0.000092770, Loss: 0.000006, Step Loss: 0.000006, Time: 0.066922
2023-06-01 12:01:06,728:INFO: Epoch: 27/30, Step: 25/64, Lr: 0.000092770, Loss: 0.000007, Step Loss: 0.000007, Time: 0.065211
2023-06-01 12:01:06,799:INFO: Epoch: 27/30, Step: 26/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070943
2023-06-01 12:01:06,876:INFO: Epoch: 27/30, Step: 27/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076242
2023-06-01 12:01:06,949:INFO: Epoch: 27/30, Step: 28/64, Lr: 0.000092770, Loss: 0.000334, Step Loss: 0.000334, Time: 0.073296
2023-06-01 12:01:07,015:INFO: Epoch: 27/30, Step: 29/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064982
2023-06-01 12:01:07,079:INFO: Epoch: 27/30, Step: 30/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064398
2023-06-01 12:01:07,156:INFO: Epoch: 27/30, Step: 31/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075991
2023-06-01 12:01:07,219:INFO: Epoch: 27/30, Step: 32/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.062759
2023-06-01 12:01:07,287:INFO: Epoch: 27/30, Step: 33/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067862
2023-06-01 12:01:07,359:INFO: Epoch: 27/30, Step: 34/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071485
2023-06-01 12:01:07,428:INFO: Epoch: 27/30, Step: 35/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068528
2023-06-01 12:01:07,503:INFO: Epoch: 27/30, Step: 36/64, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.074991
2023-06-01 12:01:07,572:INFO: Epoch: 27/30, Step: 37/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069073
2023-06-01 12:01:07,642:INFO: Epoch: 27/30, Step: 38/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069764
2023-06-01 12:01:07,712:INFO: Epoch: 27/30, Step: 39/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069185
2023-06-01 12:01:07,785:INFO: Epoch: 27/30, Step: 40/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073112
2023-06-01 12:01:07,852:INFO: Epoch: 27/30, Step: 41/64, Lr: 0.000092770, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066041
2023-06-01 12:01:07,922:INFO: Epoch: 27/30, Step: 42/64, Lr: 0.000092770, Loss: 0.000334, Step Loss: 0.000334, Time: 0.070013
2023-06-01 12:01:07,989:INFO: Epoch: 27/30, Step: 43/64, Lr: 0.000092770, Loss: 0.000021, Step Loss: 0.000021, Time: 0.066829
2023-06-01 12:01:08,054:INFO: Epoch: 27/30, Step: 44/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064444
2023-06-01 12:01:08,126:INFO: Epoch: 27/30, Step: 45/64, Lr: 0.000092770, Loss: 0.000004, Step Loss: 0.000004, Time: 0.072168
2023-06-01 12:01:08,194:INFO: Epoch: 27/30, Step: 46/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067985
2023-06-01 12:01:08,262:INFO: Epoch: 27/30, Step: 47/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067562
2023-06-01 12:01:08,327:INFO: Epoch: 27/30, Step: 48/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064661
2023-06-01 12:01:08,394:INFO: Epoch: 27/30, Step: 49/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066884
2023-06-01 12:01:08,463:INFO: Epoch: 27/30, Step: 50/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068313
2023-06-01 12:01:08,527:INFO: Epoch: 27/30, Step: 51/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064134
2023-06-01 12:01:08,591:INFO: Epoch: 27/30, Step: 52/64, Lr: 0.000092770, Loss: 0.000001, Step Loss: 0.000001, Time: 0.062998
2023-06-01 12:01:08,663:INFO: Epoch: 27/30, Step: 53/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071597
2023-06-01 12:01:08,730:INFO: Epoch: 27/30, Step: 54/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067314
2023-06-01 12:01:08,795:INFO: Epoch: 27/30, Step: 55/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064568
2023-06-01 12:01:08,862:INFO: Epoch: 27/30, Step: 56/64, Lr: 0.000092770, Loss: 0.000013, Step Loss: 0.000013, Time: 0.067023
2023-06-01 12:01:08,931:INFO: Epoch: 27/30, Step: 57/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067786
2023-06-01 12:01:08,994:INFO: Epoch: 27/30, Step: 58/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063472
2023-06-01 12:01:09,062:INFO: Epoch: 27/30, Step: 59/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067766
2023-06-01 12:01:09,126:INFO: Epoch: 27/30, Step: 60/64, Lr: 0.000092770, Loss: 0.000005, Step Loss: 0.000005, Time: 0.063261
2023-06-01 12:01:09,196:INFO: Epoch: 27/30, Step: 61/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069376
2023-06-01 12:01:09,262:INFO: Epoch: 27/30, Step: 62/64, Lr: 0.000092770, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066027
2023-06-01 12:01:09,330:INFO: Epoch: 27/30, Step: 63/64, Lr: 0.000092770, Loss: 0.000006, Step Loss: 0.000006, Time: 0.067877
2023-06-01 12:01:09,401:INFO: Epoch: 27/30, Step: 64/64, Lr: 0.000092770, Loss: 0.000018, Step Loss: 0.000018, Time: 0.070634
2023-06-01 12:01:09,562:INFO: Epoch 27/30 Finished, Train Loss: 0.000018
2023-06-01 12:01:21,236:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.26
2023-06-01 12:01:24,366:INFO: Classfication Metrics:
2023-06-01 12:01:24,366:INFO: f1 score: 0.8821 - precision score: 0.8938 - recall score: 0.8707 - accuracy score: 0.908475
2023-06-01 12:01:24,366:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:01:25,369:INFO: Epoch: 28/30, Step: 1/64, Lr: 0.000052668, Loss: 0.000002, Step Loss: 0.000002, Time: 0.979674
2023-06-01 12:01:25,435:INFO: Epoch: 28/30, Step: 2/64, Lr: 0.000052668, Loss: 0.000052, Step Loss: 0.000052, Time: 0.066056
2023-06-01 12:01:25,504:INFO: Epoch: 28/30, Step: 3/64, Lr: 0.000052668, Loss: 0.000004, Step Loss: 0.000004, Time: 0.068627
2023-06-01 12:01:25,571:INFO: Epoch: 28/30, Step: 4/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066269
2023-06-01 12:01:25,643:INFO: Epoch: 28/30, Step: 5/64, Lr: 0.000052668, Loss: 0.000018, Step Loss: 0.000018, Time: 0.071739
2023-06-01 12:01:25,712:INFO: Epoch: 28/30, Step: 6/64, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.068937
2023-06-01 12:01:25,779:INFO: Epoch: 28/30, Step: 7/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066722
2023-06-01 12:01:25,861:INFO: Epoch: 28/30, Step: 8/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.082106
2023-06-01 12:01:25,929:INFO: Epoch: 28/30, Step: 9/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067517
2023-06-01 12:01:25,995:INFO: Epoch: 28/30, Step: 10/64, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065284
2023-06-01 12:01:26,063:INFO: Epoch: 28/30, Step: 11/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068608
2023-06-01 12:01:26,132:INFO: Epoch: 28/30, Step: 12/64, Lr: 0.000052668, Loss: 0.000012, Step Loss: 0.000012, Time: 0.068393
2023-06-01 12:01:26,202:INFO: Epoch: 28/30, Step: 13/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070077
2023-06-01 12:01:26,270:INFO: Epoch: 28/30, Step: 14/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066934
2023-06-01 12:01:26,337:INFO: Epoch: 28/30, Step: 15/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067467
2023-06-01 12:01:26,408:INFO: Epoch: 28/30, Step: 16/64, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070239
2023-06-01 12:01:26,474:INFO: Epoch: 28/30, Step: 17/64, Lr: 0.000052668, Loss: 0.000030, Step Loss: 0.000030, Time: 0.066376
2023-06-01 12:01:26,544:INFO: Epoch: 28/30, Step: 18/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069201
2023-06-01 12:01:26,610:INFO: Epoch: 28/30, Step: 19/64, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065828
2023-06-01 12:01:26,677:INFO: Epoch: 28/30, Step: 20/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066706
2023-06-01 12:01:26,743:INFO: Epoch: 28/30, Step: 21/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066099
2023-06-01 12:01:26,811:INFO: Epoch: 28/30, Step: 22/64, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067561
2023-06-01 12:01:26,886:INFO: Epoch: 28/30, Step: 23/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074357
2023-06-01 12:01:26,961:INFO: Epoch: 28/30, Step: 24/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075274
2023-06-01 12:01:27,030:INFO: Epoch: 28/30, Step: 25/64, Lr: 0.000052668, Loss: 0.000178, Step Loss: 0.000178, Time: 0.068760
2023-06-01 12:01:27,099:INFO: Epoch: 28/30, Step: 26/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068745
2023-06-01 12:01:27,163:INFO: Epoch: 28/30, Step: 27/64, Lr: 0.000052668, Loss: 0.000004, Step Loss: 0.000004, Time: 0.063723
2023-06-01 12:01:27,231:INFO: Epoch: 28/30, Step: 28/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066925
2023-06-01 12:01:27,298:INFO: Epoch: 28/30, Step: 29/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067370
2023-06-01 12:01:27,374:INFO: Epoch: 28/30, Step: 30/64, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.075353
2023-06-01 12:01:27,439:INFO: Epoch: 28/30, Step: 31/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064999
2023-06-01 12:01:27,526:INFO: Epoch: 28/30, Step: 32/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.086576
2023-06-01 12:01:27,595:INFO: Epoch: 28/30, Step: 33/64, Lr: 0.000052668, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067979
2023-06-01 12:01:27,661:INFO: Epoch: 28/30, Step: 34/64, Lr: 0.000052668, Loss: 0.000054, Step Loss: 0.000054, Time: 0.066487
2023-06-01 12:01:27,727:INFO: Epoch: 28/30, Step: 35/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065173
2023-06-01 12:01:27,803:INFO: Epoch: 28/30, Step: 36/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076355
2023-06-01 12:01:27,876:INFO: Epoch: 28/30, Step: 37/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072739
2023-06-01 12:01:27,953:INFO: Epoch: 28/30, Step: 38/64, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.076520
2023-06-01 12:01:28,028:INFO: Epoch: 28/30, Step: 39/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073991
2023-06-01 12:01:28,099:INFO: Epoch: 28/30, Step: 40/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071119
2023-06-01 12:01:28,170:INFO: Epoch: 28/30, Step: 41/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070692
2023-06-01 12:01:28,237:INFO: Epoch: 28/30, Step: 42/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066524
2023-06-01 12:01:28,310:INFO: Epoch: 28/30, Step: 43/64, Lr: 0.000052668, Loss: 0.000003, Step Loss: 0.000003, Time: 0.072812
2023-06-01 12:01:28,383:INFO: Epoch: 28/30, Step: 44/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072916
2023-06-01 12:01:28,459:INFO: Epoch: 28/30, Step: 45/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075376
2023-06-01 12:01:28,527:INFO: Epoch: 28/30, Step: 46/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068301
2023-06-01 12:01:28,601:INFO: Epoch: 28/30, Step: 47/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072984
2023-06-01 12:01:28,668:INFO: Epoch: 28/30, Step: 48/64, Lr: 0.000052668, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066597
2023-06-01 12:01:28,735:INFO: Epoch: 28/30, Step: 49/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067487
2023-06-01 12:01:28,811:INFO: Epoch: 28/30, Step: 50/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075243
2023-06-01 12:01:28,882:INFO: Epoch: 28/30, Step: 51/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070739
2023-06-01 12:01:28,949:INFO: Epoch: 28/30, Step: 52/64, Lr: 0.000052668, Loss: 0.000280, Step Loss: 0.000280, Time: 0.066163
2023-06-01 12:01:29,023:INFO: Epoch: 28/30, Step: 53/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073811
2023-06-01 12:01:29,087:INFO: Epoch: 28/30, Step: 54/64, Lr: 0.000052668, Loss: 0.000013, Step Loss: 0.000013, Time: 0.063945
2023-06-01 12:01:29,159:INFO: Epoch: 28/30, Step: 55/64, Lr: 0.000052668, Loss: 0.000004, Step Loss: 0.000004, Time: 0.071383
2023-06-01 12:01:29,234:INFO: Epoch: 28/30, Step: 56/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074832
2023-06-01 12:01:29,299:INFO: Epoch: 28/30, Step: 57/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064716
2023-06-01 12:01:29,370:INFO: Epoch: 28/30, Step: 58/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071541
2023-06-01 12:01:29,435:INFO: Epoch: 28/30, Step: 59/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064124
2023-06-01 12:01:29,503:INFO: Epoch: 28/30, Step: 60/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068178
2023-06-01 12:01:29,572:INFO: Epoch: 28/30, Step: 61/64, Lr: 0.000052668, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068033
2023-06-01 12:01:29,638:INFO: Epoch: 28/30, Step: 62/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066507
2023-06-01 12:01:29,706:INFO: Epoch: 28/30, Step: 63/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067304
2023-06-01 12:01:29,774:INFO: Epoch: 28/30, Step: 64/64, Lr: 0.000052668, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067881
2023-06-01 12:01:29,936:INFO: Epoch 28/30 Finished, Train Loss: 0.000010
2023-06-01 12:01:36,210:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.27
2023-06-01 12:01:39,314:INFO: Classfication Metrics:
2023-06-01 12:01:39,314:INFO: f1 score: 0.8821 - precision score: 0.8938 - recall score: 0.8707 - accuracy score: 0.908475
2023-06-01 12:01:39,314:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:01:40,298:INFO: Epoch: 29/30, Step: 1/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.975798
2023-06-01 12:01:40,565:INFO: Epoch: 29/30, Step: 2/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.267128
2023-06-01 12:01:40,631:INFO: Epoch: 29/30, Step: 3/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065026
2023-06-01 12:01:40,695:INFO: Epoch: 29/30, Step: 4/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064194
2023-06-01 12:01:40,763:INFO: Epoch: 29/30, Step: 5/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067370
2023-06-01 12:01:40,830:INFO: Epoch: 29/30, Step: 6/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066807
2023-06-01 12:01:40,895:INFO: Epoch: 29/30, Step: 7/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064814
2023-06-01 12:01:40,963:INFO: Epoch: 29/30, Step: 8/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067588
2023-06-01 12:01:41,027:INFO: Epoch: 29/30, Step: 9/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064328
2023-06-01 12:01:41,100:INFO: Epoch: 29/30, Step: 10/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072777
2023-06-01 12:01:41,166:INFO: Epoch: 29/30, Step: 11/64, Lr: 0.000023563, Loss: 0.000019, Step Loss: 0.000019, Time: 0.065204
2023-06-01 12:01:41,231:INFO: Epoch: 29/30, Step: 12/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064249
2023-06-01 12:01:41,295:INFO: Epoch: 29/30, Step: 13/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064151
2023-06-01 12:01:41,363:INFO: Epoch: 29/30, Step: 14/64, Lr: 0.000023563, Loss: 0.000003, Step Loss: 0.000003, Time: 0.067894
2023-06-01 12:01:41,432:INFO: Epoch: 29/30, Step: 15/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068132
2023-06-01 12:01:41,500:INFO: Epoch: 29/30, Step: 16/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068089
2023-06-01 12:01:41,566:INFO: Epoch: 29/30, Step: 17/64, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.065518
2023-06-01 12:01:41,646:INFO: Epoch: 29/30, Step: 18/64, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.080087
2023-06-01 12:01:41,714:INFO: Epoch: 29/30, Step: 19/64, Lr: 0.000023563, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066829
2023-06-01 12:01:41,781:INFO: Epoch: 29/30, Step: 20/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067438
2023-06-01 12:01:41,851:INFO: Epoch: 29/30, Step: 21/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069099
2023-06-01 12:01:41,914:INFO: Epoch: 29/30, Step: 22/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063070
2023-06-01 12:01:41,987:INFO: Epoch: 29/30, Step: 23/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072740
2023-06-01 12:01:42,058:INFO: Epoch: 29/30, Step: 24/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070309
2023-06-01 12:01:42,123:INFO: Epoch: 29/30, Step: 25/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064862
2023-06-01 12:01:42,190:INFO: Epoch: 29/30, Step: 26/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067339
2023-06-01 12:01:42,260:INFO: Epoch: 29/30, Step: 27/64, Lr: 0.000023563, Loss: 0.000175, Step Loss: 0.000175, Time: 0.069320
2023-06-01 12:01:42,331:INFO: Epoch: 29/30, Step: 28/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.070356
2023-06-01 12:01:42,399:INFO: Epoch: 29/30, Step: 29/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067554
2023-06-01 12:01:42,463:INFO: Epoch: 29/30, Step: 30/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.064270
2023-06-01 12:01:42,534:INFO: Epoch: 29/30, Step: 31/64, Lr: 0.000023563, Loss: 0.030444, Step Loss: 0.030444, Time: 0.070578
2023-06-01 12:01:42,601:INFO: Epoch: 29/30, Step: 32/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066534
2023-06-01 12:01:42,666:INFO: Epoch: 29/30, Step: 33/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064653
2023-06-01 12:01:42,743:INFO: Epoch: 29/30, Step: 34/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076010
2023-06-01 12:01:42,814:INFO: Epoch: 29/30, Step: 35/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071113
2023-06-01 12:01:42,879:INFO: Epoch: 29/30, Step: 36/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065151
2023-06-01 12:01:42,948:INFO: Epoch: 29/30, Step: 37/64, Lr: 0.000023563, Loss: 0.000052, Step Loss: 0.000052, Time: 0.068465
2023-06-01 12:01:43,014:INFO: Epoch: 29/30, Step: 38/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065925
2023-06-01 12:01:43,082:INFO: Epoch: 29/30, Step: 39/64, Lr: 0.000023563, Loss: 0.000001, Step Loss: 0.000001, Time: 0.067315
2023-06-01 12:01:43,153:INFO: Epoch: 29/30, Step: 40/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070754
2023-06-01 12:01:43,218:INFO: Epoch: 29/30, Step: 41/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065073
2023-06-01 12:01:43,286:INFO: Epoch: 29/30, Step: 42/64, Lr: 0.000023563, Loss: 0.000206, Step Loss: 0.000206, Time: 0.067249
2023-06-01 12:01:43,357:INFO: Epoch: 29/30, Step: 43/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070780
2023-06-01 12:01:43,427:INFO: Epoch: 29/30, Step: 44/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069070
2023-06-01 12:01:43,497:INFO: Epoch: 29/30, Step: 45/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069581
2023-06-01 12:01:43,566:INFO: Epoch: 29/30, Step: 46/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068843
2023-06-01 12:01:43,635:INFO: Epoch: 29/30, Step: 47/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068914
2023-06-01 12:01:43,704:INFO: Epoch: 29/30, Step: 48/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068531
2023-06-01 12:01:43,779:INFO: Epoch: 29/30, Step: 49/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.074692
2023-06-01 12:01:43,851:INFO: Epoch: 29/30, Step: 50/64, Lr: 0.000023563, Loss: 0.002959, Step Loss: 0.002959, Time: 0.071337
2023-06-01 12:01:43,916:INFO: Epoch: 29/30, Step: 51/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064938
2023-06-01 12:01:43,984:INFO: Epoch: 29/30, Step: 52/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067560
2023-06-01 12:01:44,055:INFO: Epoch: 29/30, Step: 53/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.071002
2023-06-01 12:01:44,121:INFO: Epoch: 29/30, Step: 54/64, Lr: 0.000023563, Loss: 0.000014, Step Loss: 0.000014, Time: 0.066100
2023-06-01 12:01:44,186:INFO: Epoch: 29/30, Step: 55/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065029
2023-06-01 12:01:44,257:INFO: Epoch: 29/30, Step: 56/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070359
2023-06-01 12:01:44,323:INFO: Epoch: 29/30, Step: 57/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065272
2023-06-01 12:01:44,399:INFO: Epoch: 29/30, Step: 58/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.075869
2023-06-01 12:01:44,466:INFO: Epoch: 29/30, Step: 59/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066216
2023-06-01 12:01:44,534:INFO: Epoch: 29/30, Step: 60/64, Lr: 0.000023563, Loss: 0.000030, Step Loss: 0.000030, Time: 0.068026
2023-06-01 12:01:44,602:INFO: Epoch: 29/30, Step: 61/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067967
2023-06-01 12:01:44,671:INFO: Epoch: 29/30, Step: 62/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067984
2023-06-01 12:01:44,740:INFO: Epoch: 29/30, Step: 63/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068700
2023-06-01 12:01:44,806:INFO: Epoch: 29/30, Step: 64/64, Lr: 0.000023563, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066182
2023-06-01 12:01:44,952:INFO: Epoch 29/30 Finished, Train Loss: 0.000530
2023-06-01 12:01:53,416:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.28
2023-06-01 12:01:56,476:INFO: Classfication Metrics:
2023-06-01 12:01:56,476:INFO: f1 score: 0.8772 - precision score: 0.8929 - recall score: 0.8621 - accuracy score: 0.905085
2023-06-01 12:01:56,477:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:01:57,424:INFO: Epoch: 30/30, Step: 1/64, Lr: 0.000005914, Loss: 0.000006, Step Loss: 0.000006, Time: 0.937167
2023-06-01 12:01:57,503:INFO: Epoch: 30/30, Step: 2/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.078028
2023-06-01 12:01:57,570:INFO: Epoch: 30/30, Step: 3/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066972
2023-06-01 12:01:57,634:INFO: Epoch: 30/30, Step: 4/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063472
2023-06-01 12:01:57,702:INFO: Epoch: 30/30, Step: 5/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068607
2023-06-01 12:01:57,775:INFO: Epoch: 30/30, Step: 6/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072113
2023-06-01 12:01:57,844:INFO: Epoch: 30/30, Step: 7/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068626
2023-06-01 12:01:57,911:INFO: Epoch: 30/30, Step: 8/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067262
2023-06-01 12:01:57,980:INFO: Epoch: 30/30, Step: 9/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067820
2023-06-01 12:01:58,057:INFO: Epoch: 30/30, Step: 10/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.076760
2023-06-01 12:01:58,123:INFO: Epoch: 30/30, Step: 11/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.065793
2023-06-01 12:01:58,188:INFO: Epoch: 30/30, Step: 12/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064626
2023-06-01 12:01:58,254:INFO: Epoch: 30/30, Step: 13/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066216
2023-06-01 12:01:58,321:INFO: Epoch: 30/30, Step: 14/64, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066690
2023-06-01 12:01:58,388:INFO: Epoch: 30/30, Step: 15/64, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.066362
2023-06-01 12:01:58,461:INFO: Epoch: 30/30, Step: 16/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073135
2023-06-01 12:01:58,526:INFO: Epoch: 30/30, Step: 17/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064517
2023-06-01 12:01:58,607:INFO: Epoch: 30/30, Step: 18/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.080330
2023-06-01 12:01:58,672:INFO: Epoch: 30/30, Step: 19/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064368
2023-06-01 12:01:58,743:INFO: Epoch: 30/30, Step: 20/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070749
2023-06-01 12:01:58,812:INFO: Epoch: 30/30, Step: 21/64, Lr: 0.000005914, Loss: 0.000003, Step Loss: 0.000003, Time: 0.068905
2023-06-01 12:01:58,878:INFO: Epoch: 30/30, Step: 22/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066263
2023-06-01 12:01:58,943:INFO: Epoch: 30/30, Step: 23/64, Lr: 0.000005914, Loss: 0.000016, Step Loss: 0.000016, Time: 0.064500
2023-06-01 12:01:59,011:INFO: Epoch: 30/30, Step: 24/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067211
2023-06-01 12:01:59,075:INFO: Epoch: 30/30, Step: 25/64, Lr: 0.000005914, Loss: 0.000065, Step Loss: 0.000065, Time: 0.064245
2023-06-01 12:01:59,148:INFO: Epoch: 30/30, Step: 26/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.072268
2023-06-01 12:01:59,218:INFO: Epoch: 30/30, Step: 27/64, Lr: 0.000005914, Loss: 0.000038, Step Loss: 0.000038, Time: 0.070188
2023-06-01 12:01:59,284:INFO: Epoch: 30/30, Step: 28/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064863
2023-06-01 12:01:59,350:INFO: Epoch: 30/30, Step: 29/64, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.066002
2023-06-01 12:01:59,419:INFO: Epoch: 30/30, Step: 30/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.069171
2023-06-01 12:01:59,487:INFO: Epoch: 30/30, Step: 31/64, Lr: 0.000005914, Loss: 0.000006, Step Loss: 0.000006, Time: 0.067139
2023-06-01 12:01:59,555:INFO: Epoch: 30/30, Step: 32/64, Lr: 0.000005914, Loss: 0.000011, Step Loss: 0.000011, Time: 0.067466
2023-06-01 12:01:59,627:INFO: Epoch: 30/30, Step: 33/64, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071253
2023-06-01 12:01:59,695:INFO: Epoch: 30/30, Step: 34/64, Lr: 0.000005914, Loss: 0.000025, Step Loss: 0.000025, Time: 0.067672
2023-06-01 12:01:59,760:INFO: Epoch: 30/30, Step: 35/64, Lr: 0.000005914, Loss: 0.000007, Step Loss: 0.000007, Time: 0.064551
2023-06-01 12:01:59,827:INFO: Epoch: 30/30, Step: 36/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067229
2023-06-01 12:01:59,895:INFO: Epoch: 30/30, Step: 37/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067490
2023-06-01 12:01:59,963:INFO: Epoch: 30/30, Step: 38/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067373
2023-06-01 12:02:00,034:INFO: Epoch: 30/30, Step: 39/64, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.071187
2023-06-01 12:02:00,103:INFO: Epoch: 30/30, Step: 40/64, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.068720
2023-06-01 12:02:00,168:INFO: Epoch: 30/30, Step: 41/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064192
2023-06-01 12:02:00,236:INFO: Epoch: 30/30, Step: 42/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067962
2023-06-01 12:02:00,305:INFO: Epoch: 30/30, Step: 43/64, Lr: 0.000005914, Loss: 0.000005, Step Loss: 0.000005, Time: 0.069160
2023-06-01 12:02:00,379:INFO: Epoch: 30/30, Step: 44/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.073171
2023-06-01 12:02:00,443:INFO: Epoch: 30/30, Step: 45/64, Lr: 0.000005914, Loss: 0.000008, Step Loss: 0.000008, Time: 0.063412
2023-06-01 12:02:00,508:INFO: Epoch: 30/30, Step: 46/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.064807
2023-06-01 12:02:00,574:INFO: Epoch: 30/30, Step: 47/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.066072
2023-06-01 12:02:00,643:INFO: Epoch: 30/30, Step: 48/64, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.068456
2023-06-01 12:02:00,714:INFO: Epoch: 30/30, Step: 49/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070442
2023-06-01 12:02:00,779:INFO: Epoch: 30/30, Step: 50/64, Lr: 0.000005914, Loss: 0.000001, Step Loss: 0.000001, Time: 0.065066
2023-06-01 12:02:00,847:INFO: Epoch: 30/30, Step: 51/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067812
2023-06-01 12:02:00,915:INFO: Epoch: 30/30, Step: 52/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067379
2023-06-01 12:02:00,983:INFO: Epoch: 30/30, Step: 53/64, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.067682
2023-06-01 12:02:01,051:INFO: Epoch: 30/30, Step: 54/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067464
2023-06-01 12:02:01,119:INFO: Epoch: 30/30, Step: 55/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.067483
2023-06-01 12:02:01,189:INFO: Epoch: 30/30, Step: 56/64, Lr: 0.000005914, Loss: 0.000014, Step Loss: 0.000014, Time: 0.070419
2023-06-01 12:02:01,260:INFO: Epoch: 30/30, Step: 57/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070473
2023-06-01 12:02:01,331:INFO: Epoch: 30/30, Step: 58/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.070556
2023-06-01 12:02:01,399:INFO: Epoch: 30/30, Step: 59/64, Lr: 0.000005914, Loss: 0.000005, Step Loss: 0.000005, Time: 0.067361
2023-06-01 12:02:01,470:INFO: Epoch: 30/30, Step: 60/64, Lr: 0.000005914, Loss: 0.000002, Step Loss: 0.000002, Time: 0.071287
2023-06-01 12:02:01,552:INFO: Epoch: 30/30, Step: 61/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.081581
2023-06-01 12:02:01,618:INFO: Epoch: 30/30, Step: 62/64, Lr: 0.000005914, Loss: 0.000577, Step Loss: 0.000577, Time: 0.065325
2023-06-01 12:02:01,687:INFO: Epoch: 30/30, Step: 63/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.068606
2023-06-01 12:02:01,751:INFO: Epoch: 30/30, Step: 64/64, Lr: 0.000005914, Loss: 0.000000, Step Loss: 0.000000, Time: 0.063880
2023-06-01 12:02:01,913:INFO: Epoch 30/30 Finished, Train Loss: 0.000013
2023-06-01 12:02:08,163:INFO: Model saved to experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.29
2023-06-01 12:02:11,288:INFO: Classfication Metrics:
2023-06-01 12:02:11,288:INFO: f1 score: 0.8772 - precision score: 0.8929 - recall score: 0.8621 - accuracy score: 0.905085
2023-06-01 12:02:11,288:INFO: The best model is: experiments/weibo/train_weibo_clip_bert_bilinear_more/pytorch_model.bin.19, the F1 is: 0.9000
2023-06-01 12:02:11,288:INFO: ***** Running testing *****
2023-06-01 12:02:11,288:INFO:   Num examples = 295
2023-06-01 12:02:11,288:INFO:   Batch size = 128
2023-06-01 12:02:15,130:INFO: Classfication Metrics:
2023-06-01 12:02:15,130:INFO: f1 score: 0.9000 - precision score: 0.8710 - recall score: 0.9310 - accuracy score: 0.918644